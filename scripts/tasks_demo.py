#!/usr/bin/env python3
"""
Demo script showing how to use the unified Task and Tasks system.

This script demonstrates:
1. Loading tasks with integrated molecule, protein, and metadata data
2. Computing combined features from multiple data types
3. Distance computation across tasks
4. Task feature caching and persistence
5. Multi-modal task analysis

Run from project root:
    python scripts/tasks_demo.py
"""

import sys
import tempfile
from pathlib import Path

import numpy as np
from sklearn.metrics.pairwise import cosine_distances

# Add project root to Python path
sys.path.insert(0, str(Path(__file__).parent.parent))

import logging

from themap.data.protein_datasets import DataFold
from themap.data.tasks import Tasks
from themap.utils.logging import get_logger

# Configure logging to show INFO level messages
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logger = get_logger(__name__)


def demo_individual_task():
    """Demonstrate individual Task functionality."""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ¯ DEMO 1: Individual Task Operations")
    logger.info("=" * 60)

    # Note: This demo focuses on the API structure since we don't have actual data loaded
    logger.info("ğŸ“‹ Task API Capabilities:")
    logger.info("1. ğŸ§ª Task(task_id, molecule_dataset, protein_dataset, metadata_datasets)")
    logger.info("2. âš—ï¸ task.get_molecule_features(featurizer_name)")
    logger.info("3. ğŸ§¬ task.get_protein_features(featurizer_name, layer)")
    logger.info("4. ğŸ“Š task.get_metadata_features(metadata_type, featurizer_name)")
    logger.info("5. ğŸ”— task.get_combined_features(molecule_featurizer, protein_featurizer, metadata_configs)")

    # Example task creation (would work with real data)
    logger.info("\nğŸ“ Example Task creation pattern:")
    logger.info("""
    task = Task(
        task_id="CHEMBL2219236",
        molecule_dataset=loaded_molecule_dataset,  # âš—ï¸ Molecules
        protein_dataset=loaded_protein_dataset,    # ğŸ§¬ Protein
        metadata_datasets={                        # ğŸ“Š Metadata
            "assay_description": text_metadata_dataset,
            "bioactivity": numerical_metadata_dataset
        }
    )
    """)

    logger.info("\nğŸ”§ Example combined feature extraction:")
    logger.info("""
    combined_features = task.get_combined_features(
        molecule_featurizer="ecfp",     # âš—ï¸ Molecular features
        protein_featurizer="esm2_t33_650M_UR50D",     # ğŸ§¬ Protein features
        metadata_configs={                             # ğŸ“Š Metadata features
            "assay_description": {"featurizer_name": "sentence-transformers"},
            "bioactivity": {"featurizer_name": "standardize"}
        },
        combination_method="concatenate"               # ğŸ”— Fusion strategy
    )
    """)


def demo_tasks_from_directory():
    """Demonstrate Tasks.from_directory functionality."""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“‚ DEMO 2: Loading Tasks from Directory")
    logger.info("=" * 60)

    try:
        # Try to load tasks from the actual datasets directory
        logger.info("ğŸ” Attempting to load tasks from datasets/ directory...")

        tasks = Tasks.from_directory(
            directory="datasets/",
            task_list_file="datasets/sample_tasks_list.json",
            load_molecules=True,
            load_proteins=True,
            load_metadata=False,  # Skip metadata for now since it may not exist
            cache_dir="cache/",
        )

        logger.info(f"âœ… Successfully loaded tasks: {tasks}")

        # Show task distribution
        logger.info("\nğŸ“Š Task distribution by fold:")
        for fold in [DataFold.TRAIN, DataFold.VALIDATION, DataFold.TEST]:
            num_tasks = tasks.get_num_fold_tasks(fold)
            task_ids = tasks.get_task_ids(fold)
            fold_name = {DataFold.TRAIN: "train", DataFold.VALIDATION: "validation", DataFold.TEST: "test"}[
                fold
            ]
            fold_emoji = {"train": "ğŸ‹ï¸", "validation": "ğŸ”", "test": "ğŸ§ª"}[fold_name]
            logger.info(f"{fold_emoji} {fold_name.title()} tasks ({num_tasks}): {task_ids}")

        # Show sample task details
        train_tasks = tasks.get_tasks(DataFold.TRAIN)
        if train_tasks:
            sample_task = train_tasks[0]
            logger.info(f"\nğŸ”¬ Sample task: {sample_task}")

            # Test individual feature extraction (if data is available)
            try:
                if sample_task.molecule_dataset:
                    logger.info("âœ… âš—ï¸ Molecule dataset available for feature extraction")
                if sample_task.protein_dataset:
                    logger.info("âœ… ğŸ§¬ Protein dataset available for feature extraction")
                if sample_task.metadata_datasets:
                    logger.info(f"âœ… ğŸ“Š Metadata available: {list(sample_task.metadata_datasets.keys())}")
            except Exception as e:
                logger.warning(f"âš ï¸ Could not access task data: {e}")

        return tasks

    except Exception as e:
        logger.warning(f"âŒ Could not load tasks from directory: {e}")
        logger.info("ğŸ’¡ This is expected if datasets/ directory is not set up")
        return None


def demo_combined_feature_computation(tasks):
    """Demonstrate combined feature computation across tasks."""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ§® DEMO 3: Combined Feature Computation")
    logger.info("=" * 60)

    if tasks is None:
        logger.info("â­ï¸ Skipping combined feature computation - no tasks loaded")
        return None

    try:
        logger.info("ğŸ”„ Computing combined features for all tasks...")

        # Example configuration for combined features
        metadata_configs = {
            "assay_description": {
                "featurizer_name": "sentence-transformers",
                "kwargs": {"model_name": "all-MiniLM-L6-v2"},
            },
            "bioactivity": {"featurizer_name": "standardize", "kwargs": {}},
        }

        logger.info("ğŸ›ï¸ Feature extraction configuration:")
        logger.info("   âš—ï¸ Molecules: morgan_fingerprints")
        logger.info("   ğŸ§¬ Proteins: esm2_t33_650M_UR50D")
        logger.info("   ğŸ“Š Metadata: sentence-transformers + standardization")
        logger.info("   ğŸ”— Combination: concatenate")

        # Compute features (this may take time with real data)
        all_features = tasks.compute_all_task_features(
            molecule_featurizer="ecfp",
            protein_featurizer="esm2_t33_650M_UR50D",
            metadata_configs=metadata_configs,
            combination_method="concatenate",
            folds=[DataFold.TRAIN, DataFold.TEST],  # Focus on train and test
        )

        logger.info(f"âœ… Computed features for {len(all_features)} tasks")

        # Show feature shapes
        logger.info("\nğŸ“ Sample feature shapes:")
        for name, features in list(all_features.items())[:3]:
            logger.info(f"  ğŸ¯ {name}: feature shape {features.shape}")

        return all_features

    except Exception as e:
        logger.error(f"âŒ Failed to compute combined features: {e}")
        logger.info("ğŸ’¡ This is expected if the required data/models are not available")
        return None


def demo_distance_computation(tasks):
    """Demonstrate distance computation between tasks."""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“ DEMO 4: Task Distance Computation")
    logger.info("=" * 60)

    if tasks is None:
        logger.info("â­ï¸ Skipping distance computation - no tasks loaded")
        return

    try:
        logger.info("ğŸ”§ Preparing features for distance computation...")

        # Get features organized for NÃ—M distance matrix
        source_features, target_features, source_names, target_names = (
            tasks.get_distance_computation_ready_features(
                molecule_featurizer="ecfp",
                protein_featurizer="esm2_t33_650M_UR50D",
                combination_method="concatenate",
                source_fold=DataFold.TRAIN,
                target_folds=[DataFold.TEST],
            )
        )

        logger.info(f"ğŸ‹ï¸ Source tasks: {source_names}")
        logger.info(f"ğŸ§ª Target tasks: {target_names}")

        if source_features and target_features:
            logger.info("\nğŸ“Š Computing task distance matrix...")

            # Stack features for vectorized computation
            source_matrix = np.stack(source_features)  # (N, D)
            target_matrix = np.stack(target_features)  # (M, D)

            logger.info(f"ğŸ“ Source matrix shape: {source_matrix.shape}")
            logger.info(f"ğŸ“ Target matrix shape: {target_matrix.shape}")

            # Compute cosine distances
            distance_matrix = cosine_distances(source_matrix, target_matrix)

            logger.info(f"ğŸ¯ Distance matrix shape: {distance_matrix.shape}")
            logger.info(f"ğŸ“Š Sample distances:\n{distance_matrix}")

            # Find most similar task pairs
            min_indices = np.unravel_index(np.argmin(distance_matrix), distance_matrix.shape)
            logger.info(
                f"ğŸ”— Most similar pair: {source_names[min_indices[0]]} <-> {target_names[min_indices[1]]}"
            )
            logger.info(f"ğŸ“ Distance: {distance_matrix[min_indices]:.4f}")

            # Analyze task similarities
            analyze_task_similarities(distance_matrix, source_names, target_names)
        else:
            logger.warning("âš ï¸ No features available for distance computation")

    except Exception as e:
        logger.error(f"âŒ Failed to compute task distances: {e}")
        logger.info("ğŸ’¡ This is expected if the required data/models are not available")


def analyze_task_similarities(distance_matrix, source_names, target_names):
    """Analyze task similarity patterns."""
    logger.info("\nğŸ” --- Task Similarity Analysis ---")

    # Find nearest neighbors for each source task
    logger.info("ğŸ¯ Nearest neighbors for each source task:")
    for i, source_name in enumerate(source_names):
        distances = distance_matrix[i]
        nearest_idx = np.argmin(distances)
        nearest_name = target_names[nearest_idx]
        nearest_distance = distances[nearest_idx]

        logger.info(f"  ğŸ‹ï¸ {source_name} â†’ ğŸ§ª {nearest_name} (ğŸ“ distance: {nearest_distance:.4f})")

    # Overall statistics
    mean_distance = np.mean(distance_matrix)
    std_distance = np.std(distance_matrix)
    min_distance = np.min(distance_matrix)
    max_distance = np.max(distance_matrix)

    logger.info("\nğŸ“Š Distance statistics:")
    logger.info(f"  ğŸ“ˆ Mean: {mean_distance:.4f}")
    logger.info(f"  ğŸ“ Std:  {std_distance:.4f}")
    logger.info(f"  ğŸ”½ Min:  {min_distance:.4f}")
    logger.info(f"  ğŸ”¼ Max:  {max_distance:.4f}")


def demo_feature_persistence(tasks):
    """Demonstrate feature saving and loading."""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ’¾ DEMO 5: Feature Persistence")
    logger.info("=" * 60)

    if tasks is None:
        logger.info("â­ï¸ Skipping feature persistence - no tasks loaded")
        return

    try:
        # Create temporary directory for demo
        with tempfile.TemporaryDirectory() as temp_dir:
            feature_file = Path(temp_dir) / "task_features.pkl"

            logger.info(f"ğŸ’¾ Saving task features to {feature_file}")

            # Save features
            tasks.save_task_features_to_file(
                output_path=feature_file,
                molecule_featurizer="ecfp",
                protein_featurizer="esm2_t33_650M_UR50D",
                combination_method="concatenate",
                folds=[DataFold.TRAIN, DataFold.TEST],
            )

            # Load features
            logger.info("ğŸ“‚ Loading task features from file...")
            loaded_features = Tasks.load_task_features_from_file(feature_file)

            logger.info(f"âœ… Loaded {len(loaded_features)} task features")

            # Verify consistency
            logger.info("ğŸ” Verifying loaded features:")
            for name, features in list(loaded_features.items())[:2]:
                logger.info(f"  ğŸ¯ {name}: loaded feature shape {features.shape}")

    except Exception as e:
        logger.error(f"âŒ Failed to save/load features: {e}")


def demo_cache_statistics(tasks):
    """Demonstrate cache statistics."""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“ˆ DEMO 6: Cache Statistics")
    logger.info("=" * 60)

    if tasks is None:
        logger.info("â­ï¸ No tasks loaded - cannot show cache statistics")
        return

    cache_stats = tasks.get_cache_stats()
    logger.info("ğŸ“Š Cache statistics:")
    for key, value in cache_stats.items():
        if "cache" in key.lower():
            emoji = "ğŸ—„ï¸"
        elif "dir" in key.lower():
            emoji = "ğŸ“‚"
        else:
            emoji = "ğŸ“ˆ"
        logger.info(f"  {emoji} {key}: {value}")


def demo_multi_modal_analysis():
    """Demonstrate multi-modal analysis concepts."""
    logger.info("\n" + "=" * 60)
    logger.info("ğŸŒ DEMO 7: Multi-Modal Analysis Concepts")
    logger.info("=" * 60)

    logger.info("ğŸ­ Multi-modal task analysis enables:")

    logger.info("\n1. ğŸ”— Feature Fusion Strategies:")
    logger.info("   ğŸ“ concatenate: [mol_features | protein_features | metadata_features]")
    logger.info("   ğŸ“Š average: element-wise average of padded features")
    logger.info("   âš–ï¸ weighted_average: importance-weighted combination")

    logger.info("\n2. ğŸ” Similarity Analysis:")
    logger.info("   ğŸ¯ Task-to-task similarity based on combined representations")
    logger.info("   ğŸ”„ Cross-modal analysis (molecule vs protein vs metadata contributions)")
    logger.info("   ğŸ’ª Hardness prediction based on multi-modal features")

    logger.info("\n3. ğŸš€ Transfer Learning Applications:")
    logger.info("   ğŸ¯ Find similar tasks for few-shot learning")
    logger.info("   ğŸ§  Identify task relationships for meta-learning")
    logger.info("   ğŸŒ‰ Cross-domain knowledge transfer")

    logger.info("\n4. ğŸ“Š Data Integration Patterns:")
    logger.info("   âš—ï¸ Molecules: structural and chemical properties")
    logger.info("   ğŸ§¬ Proteins: sequence and structural features")
    logger.info("   ğŸ“‹ Metadata: experimental conditions, assay descriptions")


def main():
    """Run all task system demos."""
    logger.info("ğŸš€ Starting Task and Tasks System Demo")

    # Demo individual task functionality
    demo_individual_task()

    # Try to load actual tasks
    tasks = demo_tasks_from_directory()

    # Demo feature computation (if tasks loaded)
    all_features = demo_combined_feature_computation(tasks)

    # Demo distance computation
    demo_distance_computation(tasks)

    # Demo feature persistence
    demo_feature_persistence(tasks)

    # Demo cache statistics
    demo_cache_statistics(tasks)

    # Demo multi-modal concepts
    demo_multi_modal_analysis()

    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“‹ SUMMARY: Task System Capabilities")
    logger.info("=" * 60)

    summary = """
ğŸ‰ The Task and Tasks system provides:

1. ğŸ§ª UNIFIED TASK REPRESENTATION:
   â€¢ Single Task objects containing molecules, proteins, and metadata
   â€¢ Flexible data combinations (any subset can be present)
   â€¢ Backward compatibility with legacy metadata

2. ğŸ”— MULTI-MODAL FEATURE EXTRACTION:
   â€¢ Individual feature extraction per data type
   â€¢ Combined feature computation with multiple strategies
   â€¢ Configurable featurizer parameters per modality

3. ğŸ“‚ COLLECTION MANAGEMENT:
   â€¢ Load tasks from organized directory structures
   â€¢ Fold-based organization (train/validation/test)
   â€¢ Task filtering via task list files

4. ğŸ“ DISTANCE COMPUTATION:
   â€¢ NÃ—M distance matrices between task sets
   â€¢ Multi-modal similarity analysis
   â€¢ Efficient feature organization for batch computation

5. âš¡ PERFORMANCE OPTIMIZATIONS:
   â€¢ Feature caching for expensive computations
   â€¢ Persistent storage for computed features
   â€¢ Lazy loading and efficient memory usage

6. ğŸ”Œ INTEGRATION READY:
   â€¢ Works with existing MoleculeDatasets and ProteinDatasets
   â€¢ Supports new MetadataDatasets system
   â€¢ Extensible for additional data types

ğŸ’¡ Usage Pattern:
```python
# ğŸ“‚ Load integrated tasks
tasks = Tasks.from_directory(
    directory="datasets/",
    task_list_file="datasets/sample_tasks_list.json",
    load_molecules=True,
    load_proteins=True,
    load_metadata=True
)

# ğŸ§® Compute multi-modal features
features = tasks.compute_all_task_features(
    molecule_featurizer="morgan_fingerprints",     # âš—ï¸
    protein_featurizer="esm2_t33_650M_UR50D",     # ğŸ§¬
    metadata_configs={                             # ğŸ“Š
        "assay_description": {"featurizer_name": "sentence-transformers"}
    }
)

# ğŸ“ Compute task distances
source_features, target_features, source_names, target_names = (
    tasks.get_distance_computation_ready_features(...)
)
```

ğŸ¯ This system is now ready for production use with your 1000+ tasks! ğŸš€
    """

    logger.info(summary)


if __name__ == "__main__":
    main()
