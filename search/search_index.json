{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"THEMAP: Task Hardness Estimation for Molecular Activity Prediction","text":"<p>THEMAP is a comprehensive Python library designed to aid drug discovery by providing powerful methods for estimating task hardness and computing transferability maps for bioactivity prediction tasks. It enables researchers and chemists to efficiently determine the similarity between molecular datasets and make informed decisions about transfer learning strategies.</p> <ul> <li> <p>:material-rocket-launch-outline: Quick Start</p> <p>Get up and running with THEMAP in minutes</p> <p>:octicons-arrow-right-24: Getting started</p> </li> <li> <p>:material-book-open-variant: Tutorials</p> <p>Step-by-step guides for common workflows</p> <p>:octicons-arrow-right-24: View tutorials</p> </li> <li> <p>:material-code-braces: API Reference</p> <p>Detailed documentation for all modules</p> <p>:octicons-arrow-right-24: API docs</p> </li> <li> <p>:material-script-text-outline: Examples</p> <p>Ready-to-use code examples and scripts</p> <p>:octicons-arrow-right-24: Browse examples</p> </li> </ul>"},{"location":"index.html#key-features","title":"Key Features","text":""},{"location":"index.html#multi-modal-distance-computation","title":"\ud83e\uddea Multi-Modal Distance Computation","text":"<ul> <li>Molecular datasets: OTDD, Euclidean, and Cosine distances</li> <li>Protein sequences: ESM2-based embeddings and similarity metrics</li> <li>Metadata integration: Assay descriptions and experimental conditions</li> <li>Combined analysis: Multi-modal fusion strategies</li> </ul>"},{"location":"index.html#task-hardness-estimation","title":"\ud83c\udfaf Task Hardness Estimation","text":"<ul> <li>Transfer learning guidance: Identify similar tasks for knowledge transfer</li> <li>Difficulty quantification: Estimate prediction task complexity</li> <li>Resource optimization: Prioritize computational resources effectively</li> </ul>"},{"location":"index.html#production-ready-framework","title":"\u26a1 Production-Ready Framework","text":"<ul> <li>Scalable architecture: Handle large-scale dataset comparisons</li> <li>Caching system: Efficient feature storage and reuse</li> <li>Error handling: Robust validation and error recovery</li> <li>GPU acceleration: CUDA support for intensive computations</li> </ul>"},{"location":"index.html#unified-task-system","title":"\ud83d\udd2c Unified Task System","text":"<ul> <li>Integrated data management: Molecules, proteins, and metadata in one framework</li> <li>Flexible organization: Train/validation/test fold management</li> <li>Feature extraction: Unified API for multi-modal featurization</li> </ul>"},{"location":"index.html#installation","title":"Installation","text":"Basic InstallationWith All FeaturesDevelopment Setup <pre><code># Clone repository\ngit clone https://github.com/HFooladi/THEMAP.git\ncd THEMAP\n\n# Create conda environment\nconda env create -f environment.yml\nconda activate themap\n\n# Install THEMAP\npip install --no-deps -e .\n</code></pre> <pre><code># Install with all optional dependencies\npip install -e \".[all]\"\n</code></pre> <pre><code># Install development dependencies\npip install -e \".[dev,test]\"\n\n# Run tests\npython run_tests.py\n</code></pre>"},{"location":"index.html#quick-examples","title":"Quick Examples","text":""},{"location":"index.html#molecular-dataset-distance","title":"Molecular Dataset Distance","text":"<p>Compute distances between molecular datasets to understand chemical space similarity:</p> <pre><code>from themap.data.tasks import Tasks\nfrom themap.distance import MoleculeDatasetDistance\n\n# Load tasks from directory structure\ntasks = Tasks.from_directory(\n    directory=\"datasets/\",\n    task_list_file=\"datasets/sample_tasks_list.json\",\n    load_molecules=True,\n    load_proteins=True\n)\n\n# Compute molecular distances using OTDD\nmol_distance = MoleculeDatasetDistance(\n    tasks=tasks,\n    molecule_method=\"otdd\"\n)\n\ndistances = mol_distance.get_distance()\nprint(distances)\n# {'CHEMBL2219358': {'CHEMBL1023359': 7.074}}\n</code></pre>"},{"location":"index.html#unified-multi-modal-analysis","title":"Unified Multi-Modal Analysis","text":"<p>Combine molecular, protein, and metadata information for comprehensive task comparison:</p> <pre><code>from themap.distance import TaskDistance\n\n# Compute combined distances from multiple modalities\ntask_distance = TaskDistance(\n    tasks=tasks,\n    molecule_method=\"cosine\",\n    protein_method=\"euclidean\"\n)\n\n# Get all distance types\nall_distances = task_distance.compute_all_distances(\n    combination_strategy=\"weighted_average\",\n    molecule_weight=0.7,\n    protein_weight=0.3\n)\n\nprint(f\"Molecule distances: {len(all_distances['molecule'])} tasks\")\nprint(f\"Protein distances: {len(all_distances['protein'])} tasks\")\nprint(f\"Combined distances: {len(all_distances['combined'])} tasks\")\n</code></pre>"},{"location":"index.html#protein-similarity-analysis","title":"Protein Similarity Analysis","text":"<p>Analyze protein similarity using advanced sequence embeddings:</p> <pre><code>from themap.distance import ProteinDatasetDistance\n\n# Compute protein distances using ESM2 embeddings\nprot_distance = ProteinDatasetDistance(\n    tasks=tasks,\n    protein_method=\"euclidean\"\n)\n\ndistances = prot_distance.get_distance()\n# Organized as {target_task: {source_task: distance, ...}, ...}\n</code></pre>"},{"location":"index.html#use-cases","title":"Use Cases","text":""},{"location":"index.html#drug-discovery-workflows","title":"Drug Discovery Workflows","text":"<ul> <li>Target identification: Find similar protein targets for drug repurposing</li> <li>Chemical space analysis: Understand molecular diversity across datasets</li> <li>Assay development: Identify related bioactivity assays</li> </ul>"},{"location":"index.html#transfer-learning-applications","title":"Transfer Learning Applications","text":"<ul> <li>Source task selection: Choose optimal training data for new targets</li> <li>Model adaptation: Quantify domain shift between datasets</li> <li>Performance prediction: Estimate model performance on new tasks</li> </ul>"},{"location":"index.html#computational-biology","title":"Computational Biology","text":"<ul> <li>Protein function prediction: Leverage sequence similarity for annotation</li> <li>Chemical-protein interaction: Model molecular-target relationships</li> <li>Multi-omics integration: Combine molecular and protein data</li> </ul>"},{"location":"index.html#performance","title":"Performance","text":"<p>THEMAP is optimized for both accuracy and computational efficiency:</p> Method Speed Memory Accuracy Best For OTDD Slower High Highest Small-medium datasets Euclidean Fast Low Good Large datasets Cosine Fast Low Good High-dimensional features"},{"location":"index.html#scalability-features","title":"Scalability Features","text":"<ul> <li>Parallel processing: Multi-core distance computations</li> <li>Memory management: Efficient handling of large datasets</li> <li>Caching system: Reuse expensive feature computations</li> <li>Batch processing: Handle thousands of dataset comparisons</li> </ul>"},{"location":"index.html#citation","title":"Citation","text":"<p>If you use THEMAP in your research, please cite:</p> <pre><code>@article{fooladi2024quantifying,\n  title={Quantifying the hardness of bioactivity prediction tasks for transfer learning},\n  author={Fooladi, Hosein and Hirte, Steffen and Kirchmair, Johannes},\n  journal={Journal of Chemical Information and Modeling},\n  volume={64},\n  number={10},\n  pages={4031-4046},\n  year={2024},\n  publisher={ACS Publications}\n}\n</code></pre>"},{"location":"index.html#community-and-support","title":"Community and Support","text":""},{"location":"index.html#get-help","title":"Get Help","text":"<ul> <li>Documentation: Comprehensive guides and API reference</li> <li>GitHub Issues: Bug reports and feature requests</li> <li>Discussions: Community Q&amp;A and best practices</li> </ul>"},{"location":"index.html#contributing","title":"Contributing","text":"<p>We welcome contributions! See our contribution guidelines for: - Code contributions - Documentation improvements - Bug reports and feature requests - Example workflows and tutorials</p>"},{"location":"index.html#license","title":"License","text":"<p>THEMAP is released under the MIT License. See LICENSE for details.</p>"},{"location":"index.html#whats-next","title":"What's Next?","text":"<ul> <li> <p>New to THEMAP?</p> <p>Start with our comprehensive getting started guide</p> <p>:octicons-arrow-right-24: Getting started</p> </li> <li> <p>Want to compute distances?</p> <p>Learn about all available distance computation methods</p> <p>:octicons-arrow-right-24: Distance computation</p> </li> <li> <p>Working with real data?</p> <p>Understand the unified task system for multi-modal data</p> <p>:octicons-arrow-right-24: Task system</p> </li> <li> <p>Need inspiration?</p> <p>Browse our collection of examples and use cases</p> <p>:octicons-arrow-right-24: Examples</p> </li> </ul>"},{"location":"PIPELINE_GUIDE.html","title":"THEMAP Pipeline System","text":"<p>The THEMAP pipeline system provides a configuration-driven approach to running large-scale distance computation benchmarks across molecular and protein datasets. This system allows you to define complex benchmarking workflows through simple YAML or JSON configuration files.</p>"},{"location":"PIPELINE_GUIDE.html#quick-start","title":"Quick Start","text":""},{"location":"PIPELINE_GUIDE.html#1-install-dependencies","title":"1. Install Dependencies","text":"<pre><code># Activate conda environment\neval \"$(conda shell.bash hook)\" &amp;&amp; conda activate themap\n\n# Ensure pipeline dependencies are available\npip install pyyaml pandas numpy\n</code></pre>"},{"location":"PIPELINE_GUIDE.html#2-run-a-simple-example","title":"2. Run a Simple Example","text":"<pre><code># List available example configurations\npython -m themap.pipeline --list-examples\n\n# Run a quick test\npython -m themap.pipeline configs/examples/quick_test.yaml\n\n# Run with custom settings\npython -m themap.pipeline configs/examples/simple_molecule_benchmark.yaml --log-level DEBUG\n</code></pre>"},{"location":"PIPELINE_GUIDE.html#3-create-your-own-configuration","title":"3. Create Your Own Configuration","text":"<pre><code># my_benchmark.yaml\nname: \"my_custom_benchmark\"\ndescription: \"Custom molecular distance benchmark\"\n\nmolecule:\n  datasets:\n    - name: \"CHEMBL1963831\"\n      source_fold: \"TRAIN\"\n      target_folds: [\"TEST\"]\n    - name: \"CHEMBL2219236\"\n      source_fold: \"TRAIN\"\n      target_folds: [\"TEST\"]\n  featurizers: [\"ecfp\", \"maccs\"]\n  distance_methods: [\"euclidean\", \"cosine\"]\n\noutput:\n  directory: \"my_results\"\n  formats: [\"json\", \"csv\"]\n\ncompute:\n  sample_size: 500  # For faster testing\n</code></pre>"},{"location":"PIPELINE_GUIDE.html#configuration-schema","title":"Configuration Schema","text":""},{"location":"PIPELINE_GUIDE.html#pipeline-structure","title":"Pipeline Structure","text":"<pre><code>name: \"pipeline_name\"           # Required: Pipeline identifier\ndescription: \"Description\"      # Optional: Pipeline description\n\nmolecule:                       # Optional: Molecular data configuration\n  datasets: [...]              # List of molecular datasets\n  featurizers: [...]           # Molecular featurization methods\n  distance_methods: [...]      # Distance computation methods\n\nprotein:                        # Optional: Protein data configuration\n  datasets: [...]              # List of protein datasets\n  featurizers: [...]           # Protein featurization methods\n  distance_methods: [...]      # Distance computation methods\n\nmetadata:                       # Optional: Metadata configuration\n  datasets: [...]              # List of metadata datasets\n  features: [...]              # Custom metadata features\n  distance_methods: [...]      # Distance computation methods\n\ntask_distance:                  # Optional: Combined task distance\n  combination_strategy: \"...\"   # How to combine modalities\n  weights: {...}               # Weights for each modality\n\noutput:                         # Output configuration\n  directory: \"results\"         # Output directory\n  formats: [\"json\", \"csv\"]     # Output formats\n  save_intermediate: true      # Save intermediate results\n  save_matrices: false        # Save full distance matrices\n\ncompute:                        # Computation configuration\n  max_workers: 4               # Parallel workers\n  cache_features: true         # Cache computed features\n  gpu_if_available: true       # Use GPU if available\n  sample_size: null            # Sample size (null = full dataset)\n  seed: 42                     # Random seed\n</code></pre>"},{"location":"PIPELINE_GUIDE.html#dataset-configuration","title":"Dataset Configuration","text":"<p>Each dataset is specified with:</p> <pre><code>- name: \"CHEMBL123456\"          # Dataset identifier (matches filename)\n  source_fold: \"TRAIN\"          # Source data fold: TRAIN, TEST, VALIDATION\n  target_folds: [\"TEST\"]        # Target folds for comparison\n  path: null                    # Optional: Custom file path override\n</code></pre>"},{"location":"PIPELINE_GUIDE.html#available-options","title":"Available Options","text":"<p>Molecular Featurizers: - <code>ecfp</code>: Extended Connectivity Fingerprints - <code>maccs</code>: MACCS Keys - <code>desc2D</code>: 2D molecular descriptors - <code>mordred</code>: Mordred descriptors - Neural embeddings: <code>ChemBERTa-77M-MLM</code>, <code>MolT5</code>, etc.</p> <p>Protein Featurizers: - <code>esm</code>: ESM protein language model embeddings - <code>esm2</code>: ESM-2 embeddings</p> <p>Distance Methods: - <code>euclidean</code>: Euclidean distance - <code>cosine</code>: Cosine distance - <code>otdd</code>: Optimal Transport Dataset Distance (molecules only)</p> <p>Output Formats: - <code>json</code>: JSON format - <code>csv</code>: CSV format - <code>parquet</code>: Parquet format - <code>pickle</code>: Python pickle format</p>"},{"location":"PIPELINE_GUIDE.html#command-line-interface","title":"Command Line Interface","text":""},{"location":"PIPELINE_GUIDE.html#basic-usage","title":"Basic Usage","text":"<pre><code># Run pipeline with configuration file\npython -m themap.pipeline config.yaml\n\n# Specify custom data path\npython -m themap.pipeline config.yaml --data-path /path/to/datasets\n\n# Override output directory\npython -m themap.pipeline config.yaml --output-dir custom_results\n\n# Set logging level\npython -m themap.pipeline config.yaml --log-level DEBUG\n</code></pre>"},{"location":"PIPELINE_GUIDE.html#validation-and-testing","title":"Validation and Testing","text":"<pre><code># Validate configuration without running\npython -m themap.pipeline config.yaml --validate-only\n\n# Dry run to see what would be computed\npython -m themap.pipeline config.yaml --dry-run\n\n# Override sample size for testing\npython -m themap.pipeline config.yaml --sample-size 100\n</code></pre>"},{"location":"PIPELINE_GUIDE.html#advanced-options","title":"Advanced Options","text":"<pre><code># Override max workers\npython -m themap.pipeline config.yaml --max-workers 8\n\n# List available examples\npython -m themap.pipeline --list-examples\n</code></pre>"},{"location":"PIPELINE_GUIDE.html#example-configurations","title":"Example Configurations","text":""},{"location":"PIPELINE_GUIDE.html#1-simple-molecular-benchmark","title":"1. Simple Molecular Benchmark","text":"<pre><code>name: \"simple_molecule_benchmark\"\ndescription: \"Basic molecular distance computation\"\n\nmolecule:\n  datasets:\n    - name: \"CHEMBL1963831\"\n      source_fold: \"TRAIN\"\n      target_folds: [\"TEST\"]\n    - name: \"CHEMBL2219236\"\n      source_fold: \"TRAIN\"\n      target_folds: [\"TEST\"]\n  featurizers: [\"ecfp\"]\n  distance_methods: [\"euclidean\"]\n\noutput:\n  directory: \"results/simple\"\n  formats: [\"json\", \"csv\"]\n\ncompute:\n  sample_size: 1000\n</code></pre>"},{"location":"PIPELINE_GUIDE.html#2-comprehensive-multi-modal","title":"2. Comprehensive Multi-Modal","text":"<pre><code>name: \"comprehensive_benchmark\"\ndescription: \"Full multi-modal benchmarking\"\n\nmolecule:\n  datasets:\n    - name: \"CHEMBL1963831\"\n      source_fold: \"TRAIN\"\n      target_folds: [\"TEST\"]\n    - name: \"CHEMBL2219236\"\n      source_fold: \"TRAIN\"\n      target_folds: [\"TEST\"]\n  featurizers: [\"ecfp\", \"maccs\", \"desc2D\"]\n  distance_methods: [\"euclidean\", \"cosine\"]\n\nprotein:\n  datasets:\n    - name: \"CHEMBL1963831\"\n      source_fold: \"TRAIN\"\n      target_folds: [\"TEST\"]\n    - name: \"CHEMBL2219236\"\n      source_fold: \"TRAIN\"\n      target_folds: [\"TEST\"]\n  featurizers: [\"esm\"]\n  distance_methods: [\"euclidean\", \"cosine\"]\n\ntask_distance:\n  combination_strategy: \"weighted_average\"\n  weights:\n    molecule: 0.7\n    protein: 0.3\n\noutput:\n  directory: \"results/comprehensive\"\n  formats: [\"json\", \"csv\", \"parquet\"]\n  save_intermediate: true\n  save_matrices: true\n</code></pre>"},{"location":"PIPELINE_GUIDE.html#3-high-throughput-screening","title":"3. High-Throughput Screening","text":"<pre><code>name: \"high_throughput_benchmark\"\ndescription: \"Large-scale benchmarking with multiple methods\"\n\nmolecule:\n  datasets:\n    - name: \"CHEMBL1006005\"\n      source_fold: \"TRAIN\"\n      target_folds: [\"TEST\"]\n    - name: \"CHEMBL1119333\"\n      source_fold: \"TRAIN\"\n      target_folds: [\"TEST\"]\n    - name: \"CHEMBL1243967\"\n      source_fold: \"TRAIN\"\n      target_folds: [\"TEST\"]\n    # ... more datasets\n  featurizers: [\"ecfp\", \"maccs\", \"desc2D\", \"mordred\"]\n  distance_methods: [\"euclidean\", \"cosine\", \"otdd\"]\n\noutput:\n  directory: \"results/high_throughput\"\n  formats: [\"json\", \"parquet\"]\n  save_intermediate: false\n  save_matrices: true\n\ncompute:\n  max_workers: 8\n  gpu_if_available: true\n</code></pre>"},{"location":"PIPELINE_GUIDE.html#output-structure","title":"Output Structure","text":""},{"location":"PIPELINE_GUIDE.html#results-directory","title":"Results Directory","text":"<pre><code>results/\n\u251c\u2500\u2500 pipeline_results_20240117_143022.json    # Main results file\n\u251c\u2500\u2500 pipeline_results_20240117_143022.csv     # CSV format results\n\u251c\u2500\u2500 pipeline_summary_20240117_143022.json    # Execution summary\n\u251c\u2500\u2500 distance_matrix_20240117_143022.csv      # Distance matrices (if enabled)\n\u2514\u2500\u2500 intermediate_*/                           # Intermediate results (if enabled)\n    \u251c\u2500\u2500 molecule_distance_*.json\n    \u251c\u2500\u2500 protein_distance_*.json\n    \u2514\u2500\u2500 task_distance_*.json\n</code></pre>"},{"location":"PIPELINE_GUIDE.html#results-format","title":"Results Format","text":"<p>Main Results JSON: <pre><code>{\n  \"config\": {...},                    // Pipeline configuration\n  \"datasets_info\": [...],             // Information about loaded datasets\n  \"distance_results\": [               // Distance computation results\n    {\n      \"source_dataset\": \"CHEMBL123456\",\n      \"target_dataset\": \"CHEMBL789012\",\n      \"modality\": \"molecule\",\n      \"featurizer\": \"ecfp\",\n      \"method\": \"euclidean\",\n      \"distance\": 0.753,\n      \"computation_time\": 1.23\n    }\n  ],\n  \"runtime_seconds\": 45.67,\n  \"errors\": []                        // Any errors encountered\n}\n</code></pre></p> <p>Summary Report: <pre><code>{\n  \"pipeline_name\": \"my_benchmark\",\n  \"execution_timestamp\": \"20240117_143022\",\n  \"total_runtime_seconds\": 45.67,\n  \"datasets_processed\": {\n    \"total_datasets\": 5,\n    \"molecule_datasets\": 3,\n    \"protein_datasets\": 2\n  },\n  \"distance_computations\": {\n    \"total_computations\": 15,\n    \"by_modality\": {\"molecule\": 10, \"protein\": 5},\n    \"by_method\": {\"euclidean\": 8, \"cosine\": 7},\n    \"average_computation_time\": 2.34\n  },\n  \"files_generated\": [...],\n  \"config\": {...},\n  \"errors\": []\n}\n</code></pre></p>"},{"location":"PIPELINE_GUIDE.html#programming-interface","title":"Programming Interface","text":""},{"location":"PIPELINE_GUIDE.html#python-api","title":"Python API","text":"<pre><code>from themap.pipeline import PipelineConfig, PipelineRunner\n\n# Load configuration\nconfig = PipelineConfig.from_file(\"my_config.yaml\")\n\n# Create and run pipeline\nrunner = PipelineRunner(config)\nresults = runner.run(base_data_path=\"datasets\")\n\n# Access results\nprint(f\"Computed {len(results['distance_results'])} distances\")\nprint(f\"Runtime: {results['runtime_seconds']:.2f} seconds\")\n</code></pre>"},{"location":"PIPELINE_GUIDE.html#custom-configuration","title":"Custom Configuration","text":"<pre><code>from themap.pipeline.config import (\n    PipelineConfig, MoleculeConfig, DatasetConfig\n)\n\n# Create configuration programmatically\nmolecule_config = MoleculeConfig(\n    datasets=[\n        DatasetConfig(\"CHEMBL123456\", \"TRAIN\", [\"TEST\"]),\n        DatasetConfig(\"CHEMBL789012\", \"TRAIN\", [\"TEST\"])\n    ],\n    featurizers=[\"ecfp\", \"maccs\"],\n    distance_methods=[\"euclidean\", \"cosine\"]\n)\n\nconfig = PipelineConfig(\n    name=\"programmatic_pipeline\",\n    molecule=molecule_config\n)\n\n# Save configuration\nconfig.save(\"my_config.yaml\")\n</code></pre>"},{"location":"PIPELINE_GUIDE.html#best-practices","title":"Best Practices","text":""},{"location":"PIPELINE_GUIDE.html#performance-optimization","title":"Performance Optimization","text":"<ol> <li> <p>Use Sampling for Development: <pre><code>compute:\n  sample_size: 100  # Use small samples during development\n</code></pre></p> </li> <li> <p>Enable Feature Caching: <pre><code>compute:\n  cache_features: true  # Cache expensive feature computations\n</code></pre></p> </li> <li> <p>Parallel Processing: <pre><code>compute:\n  max_workers: 8  # Use multiple workers for distance computation\n</code></pre></p> </li> <li> <p>GPU Utilization: <pre><code>compute:\n  gpu_if_available: true  # Use GPU for protein embeddings\n</code></pre></p> </li> </ol>"},{"location":"PIPELINE_GUIDE.html#memory-management","title":"Memory Management","text":"<ol> <li> <p>Disable Matrix Saving for Large Benchmarks: <pre><code>output:\n  save_matrices: false  # Avoid large matrix files\n</code></pre></p> </li> <li> <p>Selective Intermediate Saving: <pre><code>output:\n  save_intermediate: false  # Disable for production runs\n</code></pre></p> </li> </ol>"},{"location":"PIPELINE_GUIDE.html#error-handling","title":"Error Handling","text":"<ul> <li>Pipeline continues execution even if some distances fail to compute</li> <li>All errors are logged and included in final results</li> <li>Use <code>--validate-only</code> to check configuration before running</li> <li>Use <code>--dry-run</code> to preview computations</li> </ul>"},{"location":"PIPELINE_GUIDE.html#reproducibility","title":"Reproducibility","text":"<pre><code>compute:\n  seed: 42              # Set random seed\n  sample_size: 1000     # Fix sample size\n</code></pre>"},{"location":"PIPELINE_GUIDE.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"PIPELINE_GUIDE.html#common-issues","title":"Common Issues","text":"<ol> <li>Dataset Not Found: <pre><code>FileNotFoundError: Molecule dataset not found: datasets/train/CHEMBL123456.jsonl.gz\n</code></pre></li> <li>Check dataset files exist in correct directories</li> <li> <p>Verify dataset names match configuration</p> </li> <li> <p>Invalid Featurizer: <pre><code>ValueError: Unknown featurizer: invalid_featurizer\n</code></pre></p> </li> <li>Check available featurizers in documentation</li> <li> <p>Ensure required dependencies are installed</p> </li> <li> <p>Memory Issues:</p> </li> <li>Reduce <code>sample_size</code></li> <li>Disable <code>save_matrices</code></li> <li> <p>Reduce <code>max_workers</code></p> </li> <li> <p>GPU Issues: <pre><code>compute:\n  gpu_if_available: false  # Disable GPU usage\n</code></pre></p> </li> </ol>"},{"location":"PIPELINE_GUIDE.html#debug-mode","title":"Debug Mode","text":"<pre><code># Enable detailed logging\npython -m themap.pipeline config.yaml --log-level DEBUG\n\n# Validate configuration\npython -m themap.pipeline config.yaml --validate-only\n\n# Preview computations\npython -m themap.pipeline config.yaml --dry-run\n</code></pre>"},{"location":"PIPELINE_GUIDE.html#contributing","title":"Contributing","text":"<p>The pipeline system is designed to be extensible:</p> <ol> <li>New Featurizers: Add to <code>featurizer_utils.py</code></li> <li>New Distance Methods: Extend distance classes</li> <li>New Output Formats: Extend <code>OutputManager</code></li> <li>New Combination Strategies: Extend <code>TaskDistance</code></li> </ol> <p>See the main project documentation for detailed contribution guidelines.</p>"},{"location":"README_PIPELINE_SCRIPTS.html","title":"THEMAP Pipeline Runner Scripts","text":"<p>This directory contains convenient scripts to run the THEMAP pipeline with configuration files. You can choose between a bash script or a Python script based on your preference.</p>"},{"location":"README_PIPELINE_SCRIPTS.html#quick-start","title":"Quick Start","text":""},{"location":"README_PIPELINE_SCRIPTS.html#option-1-bash-script-recommended","title":"Option 1: Bash Script (Recommended)","text":"<pre><code># Make the script executable (if not already)\nchmod +x run_pipeline.sh\n\n# Run a simple pipeline\n./run_pipeline.sh configs/examples/simple_directory_discovery.yaml\n\n# Run with custom settings\n./run_pipeline.sh --data-path /path/to/data --sample-size 100 configs/my_config.yaml\n</code></pre>"},{"location":"README_PIPELINE_SCRIPTS.html#option-2-python-script","title":"Option 2: Python Script","text":"<pre><code># Run a simple pipeline\npython run_pipeline.py configs/examples/simple_directory_discovery.yaml\n\n# Run with custom settings\npython run_pipeline.py --data-path /path/to/data --sample-size 100 configs/my_config.yaml\n</code></pre>"},{"location":"README_PIPELINE_SCRIPTS.html#available-options","title":"Available Options","text":"<p>Both scripts support the same options:</p> Option Description Example <code>--data-path PATH</code> Base path to dataset files <code>--data-path /path/to/datasets</code> <code>--output-dir PATH</code> Override output directory <code>--output-dir results/my_experiment</code> <code>--log-level LEVEL</code> Logging level (DEBUG, INFO, WARNING, ERROR) <code>--log-level DEBUG</code> <code>--sample-size N</code> Use only N samples (for testing) <code>--sample-size 100</code> <code>--max-workers N</code> Number of parallel workers <code>--max-workers 8</code> <code>--validate-only</code> Only validate config without running <code>--validate-only</code> <code>--dry-run</code> Show what would be computed <code>--dry-run</code> <code>--list-examples</code> List available example configs <code>--list-examples</code> <code>--help</code> Show help message <code>--help</code>"},{"location":"README_PIPELINE_SCRIPTS.html#example-usage","title":"Example Usage","text":""},{"location":"README_PIPELINE_SCRIPTS.html#1-basic-pipeline-run","title":"1. Basic Pipeline Run","text":"<pre><code># Using the new directory-based discovery\n./run_pipeline.sh configs/examples/simple_directory_discovery.yaml\n</code></pre>"},{"location":"README_PIPELINE_SCRIPTS.html#2-testing-with-small-sample","title":"2. Testing with Small Sample","text":"<pre><code># Test with just 50 samples and debug logging\n./run_pipeline.sh --sample-size 50 --log-level DEBUG configs/examples/comprehensive_multimodal.yaml\n</code></pre>"},{"location":"README_PIPELINE_SCRIPTS.html#3-custom-data-location","title":"3. Custom Data Location","text":"<pre><code># Run with data in a different location\n./run_pipeline.sh --data-path /mnt/my_datasets configs/my_config.yaml\n</code></pre>"},{"location":"README_PIPELINE_SCRIPTS.html#4-validation-and-planning","title":"4. Validation and Planning","text":"<pre><code># Check if your config is valid\n./run_pipeline.sh --validate-only configs/my_config.yaml\n\n# See what computations would be performed\n./run_pipeline.sh --dry-run configs/my_config.yaml\n</code></pre>"},{"location":"README_PIPELINE_SCRIPTS.html#5-production-run-with-custom-output","title":"5. Production Run with Custom Output","text":"<pre><code># Full run with custom output directory\n./run_pipeline.sh --output-dir results/experiment_2025_01 --max-workers 8 configs/production_config.yaml\n</code></pre>"},{"location":"README_PIPELINE_SCRIPTS.html#configuration-files","title":"Configuration Files","text":"<p>The scripts work with both the old explicit dataset format and the new directory-based discovery format:</p>"},{"location":"README_PIPELINE_SCRIPTS.html#directory-based-recommended-for-many-datasets","title":"Directory-Based (Recommended for many datasets)","text":"<pre><code>name: \"my_pipeline\"\ndescription: \"Automatic dataset discovery\"\n\nmolecule:\n  directory:\n    root_path: \"datasets\"\n    task_list_file: \"sample_tasks_list.json\"\n    load_molecules: true\n    load_proteins: false\n    load_metadata: true\n  featurizers: [\"ecfp\", \"maccs\"]\n  distance_methods: [\"euclidean\", \"cosine\"]\n\noutput:\n  directory: \"results/my_experiment\"\n  formats: [\"json\", \"csv\"]\n\ncompute:\n  max_workers: 4\n  sample_size: null  # Use all data\n</code></pre>"},{"location":"README_PIPELINE_SCRIPTS.html#explicit-dataset-format-still-supported","title":"Explicit Dataset Format (Still supported)","text":"<pre><code>name: \"my_pipeline\"\ndescription: \"Explicit dataset specification\"\n\nmolecule:\n  datasets:\n    - name: \"CHEMBL123\"\n      source_fold: \"TRAIN\"\n      target_folds: [\"TEST\"]\n    - name: \"CHEMBL456\"\n      source_fold: \"TRAIN\"\n      target_folds: [\"TEST\"]\n  featurizers: [\"ecfp\"]\n  distance_methods: [\"euclidean\"]\n</code></pre>"},{"location":"README_PIPELINE_SCRIPTS.html#environment-setup","title":"Environment Setup","text":"<p>The bash script automatically handles conda environment activation. Make sure you have:</p> <ol> <li>Conda environment named 'themap' with THEMAP installed</li> <li>Datasets in the expected directory structure</li> <li>Task list file (for directory-based configs)</li> </ol>"},{"location":"README_PIPELINE_SCRIPTS.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"README_PIPELINE_SCRIPTS.html#common-issues","title":"Common Issues","text":"<ol> <li>\"Conda environment 'themap' not found\"</li> <li>Create the environment: <code>conda create -n themap python=3.10</code></li> <li> <p>Install THEMAP in the environment</p> </li> <li> <p>\"Configuration file not found\"</p> </li> <li>Check the path to your config file</li> <li> <p>Use absolute paths if needed</p> </li> <li> <p>\"Dataset validation failed\"</p> </li> <li>Check if your datasets directory exists</li> <li>Verify the task list file format</li> <li> <p>Use <code>--validate-only</code> to debug</p> </li> <li> <p>Python script fails but bash script works</p> </li> <li>Make sure you're in the correct conda environment</li> <li>Use the bash script which handles environment activation automatically</li> </ol>"},{"location":"README_PIPELINE_SCRIPTS.html#getting-help","title":"Getting Help","text":"<pre><code># Show detailed help\n./run_pipeline.sh --help\npython run_pipeline.py --help\n\n# List available example configurations\n./run_pipeline.sh --list-examples\n\n# Check what would be computed without running\n./run_pipeline.sh --dry-run configs/my_config.yaml\n</code></pre>"},{"location":"README_PIPELINE_SCRIPTS.html#script-differences","title":"Script Differences","text":"Feature Bash Script Python Script Environment handling Automatic conda activation Manual environment required Error handling Comprehensive with colored output Basic error reporting Platform support Linux/macOS Cross-platform Dependencies Requires conda Requires THEMAP installed <p>Choose the bash script for automatic environment handling, or the Python script if you prefer to manage environments manually.</p>"},{"location":"UNIFIED_TASK_SYSTEM.html","title":"Unified Task System Documentation","text":"<p>This document provides a comprehensive overview of the unified task system that integrates molecular data, protein data, and metadata into a cohesive framework for multi-modal machine learning workflows.</p>"},{"location":"UNIFIED_TASK_SYSTEM.html#system-overview","title":"System Overview","text":"<p>The unified task system consists of several interconnected components:</p> <ol> <li><code>Task</code> - Individual task representation containing all data modalities</li> <li><code>Tasks</code> - Collection management across train/validation/test folds</li> <li><code>MoleculeDatasets</code> - Molecular data management</li> <li><code>ProteinMetadataDatasets</code> - Protein sequence and feature management</li> <li><code>MetadataDatasets</code> - Flexible metadata management blueprint</li> <li>Unified feature extraction and distance computation</li> </ol>"},{"location":"UNIFIED_TASK_SYSTEM.html#demo-results","title":"Demo Results","text":"<p>Running <code>python scripts/tasks_demo.py</code> successfully demonstrated:</p> <pre><code>INFO: Successfully loaded tasks: Tasks(train=10, valid=0, test=3)\nINFO: Train tasks (10): ['CHEMBL894522', 'CHEMBL1023359', 'CHEMBL1613776', ...]\nINFO: Test tasks (3): ['CHEMBL1963831', 'CHEMBL2219236', 'CHEMBL2219358']\nINFO: Sample task: Task(task_id=CHEMBL894522, molecules=34, protein=1, hardness=None)\n\nINFO: Computed 10\u00d73 distance matrix between train and test tasks\nINFO: Feature caching working with 2 cache entries\nINFO: Successfully saved and loaded task features\n</code></pre>"},{"location":"UNIFIED_TASK_SYSTEM.html#core-components","title":"Core Components","text":""},{"location":"UNIFIED_TASK_SYSTEM.html#1-task-class","title":"1. Task Class","text":"<pre><code>@dataclass\nclass Task:\n    \"\"\"Complete molecular property prediction problem representation.\"\"\"\n    task_id: str\n    molecule_dataset: Optional[MoleculeDataset] = None\n    protein_dataset: Optional[ProteinMetadataDataset] = None\n    metadata_datasets: Optional[Dict[str, Any]] = None\n    legacy_metadata: Optional[MetaData] = None\n    hardness: Optional[float] = None\n</code></pre> <p>Key Methods: - <code>get_molecule_features(featurizer_name, **kwargs)</code> - Extract molecular features - <code>get_protein_features(featurizer_name, layer, **kwargs)</code> - Extract protein features - <code>get_metadata_features(metadata_type, featurizer_name, **kwargs)</code> - Extract metadata features - <code>get_combined_features(...)</code> - Multi-modal feature fusion</p>"},{"location":"UNIFIED_TASK_SYSTEM.html#2-tasks-collection-class","title":"2. Tasks Collection Class","text":"<pre><code>class Tasks:\n    \"\"\"Collection of tasks across train/validation/test folds.\"\"\"\n</code></pre> <p>Key Methods: - <code>from_directory(directory, task_list_file, load_molecules, load_proteins, load_metadata)</code> - Load from organized structure - <code>compute_all_task_features(molecule_featurizer, protein_featurizer, metadata_configs)</code> - Batch feature computation - <code>get_distance_computation_ready_features(...)</code> - Prepare N\u00d7M distance matrices - <code>save_task_features_to_file()</code> / <code>load_task_features_from_file()</code> - Persistence</p>"},{"location":"UNIFIED_TASK_SYSTEM.html#data-integration-architecture","title":"Data Integration Architecture","text":"<pre><code>Task (CHEMBL123)\n\u251c\u2500\u2500 MoleculeDataset (34 molecules)\n\u2502   \u251c\u2500\u2500 SMILES strings\n\u2502   \u251c\u2500\u2500 Molecular features (Morgan, MACCS, etc.)\n\u2502   \u2514\u2500\u2500 Activity labels\n\u251c\u2500\u2500 ProteinMetadataDataset (1 protein)\n\u2502   \u251c\u2500\u2500 UniProt ID: P53779\n\u2502   \u251c\u2500\u2500 FASTA sequence\n\u2502   \u2514\u2500\u2500 Protein features (ESM2, etc.)\n\u2514\u2500\u2500 MetadataDatasets (optional)\n    \u251c\u2500\u2500 Assay descriptions (text)\n    \u251c\u2500\u2500 Bioactivity values (numerical)\n    \u2514\u2500\u2500 Target information (categorical)\n</code></pre>"},{"location":"UNIFIED_TASK_SYSTEM.html#directory-structure","title":"Directory Structure","text":"<pre><code>datasets/\n\u251c\u2500\u2500 sample_tasks_list.json          # Task organization by fold\n\u251c\u2500\u2500 uniprot_mapping.csv             # CHEMBL \u2192 UniProt mapping\n\u251c\u2500\u2500 train/\n\u2502   \u251c\u2500\u2500 CHEMBL894522.jsonl.gz       # Molecular data\n\u2502   \u251c\u2500\u2500 CHEMBL894522.fasta          # Protein sequence\n\u2502   \u251c\u2500\u2500 CHEMBL894522_assay.json     # Assay metadata (optional)\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 valid/\n\u2514\u2500\u2500 test/\n    \u251c\u2500\u2500 CHEMBL1963831.jsonl.gz\n    \u251c\u2500\u2500 CHEMBL1963831.fasta\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"UNIFIED_TASK_SYSTEM.html#multi-modal-feature-extraction","title":"Multi-Modal Feature Extraction","text":""},{"location":"UNIFIED_TASK_SYSTEM.html#individual-modality-features","title":"Individual Modality Features","text":"<pre><code># Molecular features\nmol_features = task.get_molecule_features(\"morgan_fingerprints\")\n\n# Protein features\nprot_features = task.get_protein_features(\"esm2_t33_650M_UR50D\", layer=33)\n\n# Metadata features\nassay_features = task.get_metadata_features(\"assay_description\", \"sentence-transformers\")\n</code></pre>"},{"location":"UNIFIED_TASK_SYSTEM.html#combined-feature-fusion","title":"Combined Feature Fusion","text":"<pre><code>combined_features = task.get_combined_features(\n    molecule_featurizer=\"morgan_fingerprints\",\n    protein_featurizer=\"esm2_t33_650M_UR50D\",\n    metadata_configs={\n        \"assay_description\": {\"featurizer_name\": \"sentence-transformers\"},\n        \"bioactivity\": {\"featurizer_name\": \"standardize\"}\n    },\n    combination_method=\"concatenate\"  # or \"average\"\n)\n</code></pre>"},{"location":"UNIFIED_TASK_SYSTEM.html#batch-operations","title":"Batch Operations","text":""},{"location":"UNIFIED_TASK_SYSTEM.html#load-all-tasks","title":"Load All Tasks","text":"<pre><code>tasks = Tasks.from_directory(\n    directory=\"datasets/\",\n    task_list_file=\"datasets/sample_tasks_list.json\",\n    load_molecules=True,\n    load_proteins=True,\n    load_metadata=True,\n    metadata_types=[\"assay_description\", \"bioactivity\"],\n    cache_dir=\"cache/\"\n)\n</code></pre>"},{"location":"UNIFIED_TASK_SYSTEM.html#compute-features-for-all-tasks","title":"Compute Features for All Tasks","text":"<pre><code>all_features = tasks.compute_all_task_features(\n    molecule_featurizer=\"morgan_fingerprints\",\n    protein_featurizer=\"esm2_t33_650M_UR50D\",\n    metadata_configs={\n        \"assay_description\": {\"featurizer_name\": \"sentence-transformers\"}\n    },\n    combination_method=\"concatenate\",\n    folds=[DataFold.TRAIN, DataFold.TEST]\n)\n</code></pre>"},{"location":"UNIFIED_TASK_SYSTEM.html#distance-matrix-computation","title":"Distance Matrix Computation","text":"<pre><code>source_features, target_features, source_names, target_names = (\n    tasks.get_distance_computation_ready_features(\n        molecule_featurizer=\"morgan_fingerprints\",\n        protein_featurizer=\"esm2_t33_650M_UR50D\",\n        source_fold=DataFold.TRAIN,\n        target_folds=[DataFold.TEST]\n    )\n)\n\n# Compute 10\u00d73 distance matrix\nfrom sklearn.metrics.pairwise import cosine_distances\nsource_matrix = np.stack(source_features)  # (10, D)\ntarget_matrix = np.stack(target_features)  # (3, D)\ndistance_matrix = cosine_distances(source_matrix, target_matrix)  # (10, 3)\n</code></pre>"},{"location":"UNIFIED_TASK_SYSTEM.html#performance-features","title":"Performance Features","text":""},{"location":"UNIFIED_TASK_SYSTEM.html#1-deduplication","title":"1. Deduplication","text":"<ul> <li>Molecular: Canonical SMILES deduplication across datasets</li> <li>Protein: UniProt ID deduplication across tasks</li> <li>Metadata: Content hash deduplication for repeated metadata</li> </ul>"},{"location":"UNIFIED_TASK_SYSTEM.html#2-caching","title":"2. Caching","text":"<ul> <li>Memory caching: Computed features cached per session</li> <li>Persistent caching: Features saved/loaded from disk</li> <li>Global caching: Shared cache across molecule/protein systems</li> </ul>"},{"location":"UNIFIED_TASK_SYSTEM.html#3-efficient-loading","title":"3. Efficient Loading","text":"<ul> <li>Lazy loading: Data loaded only when needed</li> <li>Batch processing: Vectorized operations where possible</li> <li>Memory management: Automatic cleanup and optimization</li> </ul>"},{"location":"UNIFIED_TASK_SYSTEM.html#use-cases","title":"Use Cases","text":""},{"location":"UNIFIED_TASK_SYSTEM.html#1-task-similarity-analysis","title":"1. Task Similarity Analysis","text":"<pre><code># Find most similar tasks for transfer learning\ndistance_matrix = compute_task_distances(train_tasks, test_tasks)\nnearest_neighbors = find_k_nearest_tasks(distance_matrix, k=3)\n</code></pre>"},{"location":"UNIFIED_TASK_SYSTEM.html#2-multi-modal-meta-learning","title":"2. Multi-Modal Meta-Learning","text":"<pre><code># Use combined features for few-shot learning\ncombined_features = extract_combined_task_features(support_tasks)\nmeta_model.adapt(combined_features, support_labels)\npredictions = meta_model.predict(query_features)\n</code></pre>"},{"location":"UNIFIED_TASK_SYSTEM.html#3-task-hardness-prediction","title":"3. Task Hardness Prediction","text":"<pre><code># Predict task difficulty from multi-modal features\ntask_features = task.get_combined_features(...)\nhardness_score = hardness_predictor.predict(task_features)\n</code></pre>"},{"location":"UNIFIED_TASK_SYSTEM.html#4-cross-modal-analysis","title":"4. Cross-Modal Analysis","text":"<pre><code># Analyze contribution of different modalities\nmol_only = task.get_molecule_features(\"morgan_fingerprints\")\nprot_only = task.get_protein_features(\"esm2_t33_650M_UR50D\")\nmetadata_only = task.get_metadata_features(\"assay_description\", \"sentence-transformers\")\n\n# Compare performance with different modality combinations\n</code></pre>"},{"location":"UNIFIED_TASK_SYSTEM.html#extension-points","title":"Extension Points","text":""},{"location":"UNIFIED_TASK_SYSTEM.html#1-new-data-types","title":"1. New Data Types","text":"<pre><code># Add new data modality to Task class\n@dataclass\nclass Task:\n    # ... existing fields ...\n    molecular_dynamics: Optional[MDDataset] = None\n\n    def get_md_features(self, featurizer_name, **kwargs):\n        # Implement MD feature extraction\n        pass\n</code></pre>"},{"location":"UNIFIED_TASK_SYSTEM.html#2-new-featurizers","title":"2. New Featurizers","text":"<pre><code># Add custom featurizer to any modality\ndef custom_protein_featurizer(sequences):\n    # Implement custom feature extraction\n    return features\n\n# Register with protein utils\nregister_protein_featurizer(\"custom_featurizer\", custom_protein_featurizer)\n</code></pre>"},{"location":"UNIFIED_TASK_SYSTEM.html#3-new-combination-methods","title":"3. New Combination Methods","text":"<pre><code># Add new feature fusion strategy\ndef weighted_fusion(feature_components, weights):\n    # Implement weighted combination\n    return combined_features\n\n# Use in get_combined_features\ncombined = task.get_combined_features(combination_method=\"weighted_fusion\", weights=[0.5, 0.3, 0.2])\n</code></pre>"},{"location":"UNIFIED_TASK_SYSTEM.html#production-deployment","title":"Production Deployment","text":""},{"location":"UNIFIED_TASK_SYSTEM.html#1-data-preparation","title":"1. Data Preparation","text":"<pre><code># Organize your data following the structure\ndatasets/\n\u251c\u2500\u2500 sample_tasks_list.json\n\u251c\u2500\u2500 uniprot_mapping.csv\n\u2514\u2500\u2500 {train,valid,test}/\n    \u251c\u2500\u2500 {TASK_ID}.jsonl.gz\n    \u251c\u2500\u2500 {TASK_ID}.fasta\n    \u2514\u2500\u2500 {TASK_ID}_metadata.json\n</code></pre>"},{"location":"UNIFIED_TASK_SYSTEM.html#2-feature-precomputation","title":"2. Feature Precomputation","text":"<pre><code># Precompute and cache features for 1000+ tasks\ntasks = Tasks.from_directory(\"datasets/\", cache_dir=\"production_cache/\")\nall_features = tasks.compute_all_task_features(\n    molecule_featurizer=\"morgan_fingerprints\",\n    protein_featurizer=\"esm2_t33_650M_UR50D\"\n)\ntasks.save_task_features_to_file(\"precomputed_features.pkl\")\n</code></pre>"},{"location":"UNIFIED_TASK_SYSTEM.html#3-distance-matrix-computation","title":"3. Distance Matrix Computation","text":"<pre><code># Compute task similarity matrices\ntrain_features, test_features, train_names, test_names = (\n    tasks.get_distance_computation_ready_features(...)\n)\nsimilarity_matrix = compute_similarity_matrix(train_features, test_features)\nsave_similarity_matrix(similarity_matrix, train_names, test_names)\n</code></pre>"},{"location":"UNIFIED_TASK_SYSTEM.html#current-status","title":"Current Status","text":"<p>\u2705 Complete and Working: - Task and Tasks classes with full multi-modal support - Integration with MoleculeDatasets and ProteinMetadataDatasets - MetadataDatasets blueprint system - Feature extraction and combination - Distance computation workflows - Caching and persistence - Demo verification with real data (10 train + 3 test tasks)</p> <p>\u2705 Production Ready: - Type-safe with mypy --strict compliance - Comprehensive error handling and logging - Memory-efficient with cleanup mechanisms - Scalable to 1000+ tasks - Extensible architecture for new data types</p>"},{"location":"UNIFIED_TASK_SYSTEM.html#next-steps","title":"Next Steps","text":"<ol> <li>Add Real Featurizers: Implement production molecular featurizers (Morgan fingerprints, etc.)</li> <li>Metadata Collection: Gather and organize metadata files for your tasks</li> <li>Feature Engineering: Experiment with different combination methods and featurizers</li> <li>Performance Optimization: Profile and optimize for your specific dataset sizes</li> <li>Model Integration: Connect the unified features to your meta-learning models</li> </ol> <p>The unified task system provides a robust, scalable foundation for multi-modal molecular property prediction workflows that can handle your current 13 tasks and scale to 1000+ tasks seamlessly.</p>"},{"location":"api/data.html","title":"<code>themap.data</code>","text":""},{"location":"api/data.html#themap.data","title":"themap.data","text":""},{"location":"api/data.html#themap.data.MoleculeDatapoint","title":"MoleculeDatapoint  <code>dataclass</code>","text":"<p>Data structure holding information for a single molecule and associated features.</p> <p>This class represents a single molecule datapoint with its associated features and labels. It provides methods to compute molecular fingerprints and features, and includes various molecular properties as properties.</p> <p>Attributes:</p> Name Type Description <code>task_id</code> <code>str</code> <p>String describing the task this datapoint is taken from.</p> <code>smiles</code> <code>str</code> <p>SMILES string describing the molecule this datapoint corresponds to.</p> <code>bool_label</code> <code>bool</code> <p>bool classification label, usually derived from the numeric label using a threshold.</p> <code>numeric_label</code> <code>Optional[float]</code> <p>numerical label (e.g., activity), usually measured in the lab</p> <code>_rdkit_mol</code> <code>Optional[Mol]</code> <p>cached RDKit molecule object</p> Properties <p>number_of_atoms (int): Number of heavy atoms in the molecule number_of_bonds (int): Number of bonds in the molecule molecular_weight (float): Molecular weight in atomic mass units logp (float): Octanol-water partition coefficient (LogP) num_rotatable_bonds (int): Number of rotatable bonds in the molecule smiles_canonical (str): Canonical SMILES representation rdkit_mol (Chem.Mol): RDKit molecule object (lazy loaded)</p> <p>Methods:</p> Name Description <code>from_dict</code> <p>Create datapoint from dictionary (class method)</p> <code>to_dict</code> <p>Convert datapoint to dictionary</p> <code>get_fingerprint</code> <p>Computes and returns the Morgan fingerprint for the molecule</p> <code>get_features</code> <p>Computes and returns molecular features using specified featurizer</p> Notes <p>By design, if the SMILES is invalid and can not be parsed with RDKit, it will result in a InvalidSMILESError. So make sure to validate and sanitize your SMILES strings before creating a MoleculeDatapoint.</p> Example"},{"location":"api/data.html#themap.data.MoleculeDatapoint--create-a-molecule-datapoint","title":"Create a molecule datapoint","text":"<p>datapoint = MoleculeDatapoint( ...     task_id=\"toxicity_prediction\", ...     smiles=\"CCCO\",  # propanol ...     bool_label=True, ...     numeric_label=0.8 ... )</p>"},{"location":"api/data.html#themap.data.MoleculeDatapoint--access-molecular-properties","title":"Access molecular properties","text":"<p>print(f\"Number of heavy atoms: {datapoint.number_of_atoms}\")</p>"},{"location":"api/data.html#themap.data.MoleculeDatapoint--number-of-heavy-atoms-4","title":"Number of heavy atoms: 4","text":"<p>print(f\"Molecular weight: {datapoint.molecular_weight:.2f}\")</p>"},{"location":"api/data.html#themap.data.MoleculeDatapoint--molecular-weight-6006","title":"Molecular weight: 60.06","text":"<p>print(f\"LogP: {datapoint.logp:.2f}\")</p>"},{"location":"api/data.html#themap.data.MoleculeDatapoint--logp-039","title":"LogP: 0.39","text":"<p>print(f\"Number of rotatable bonds: {datapoint.num_rotatable_bonds}\")</p>"},{"location":"api/data.html#themap.data.MoleculeDatapoint--number-of-rotatable-bonds-1","title":"Number of rotatable bonds: 1","text":"<p>print(f\"SMILES canonical: {datapoint.smiles_canonical}\")</p>"},{"location":"api/data.html#themap.data.MoleculeDatapoint--smiles-canonical-ccco","title":"SMILES canonical: CCCO","text":""},{"location":"api/data.html#themap.data.MoleculeDatapoint--get-molecular-features","title":"Get molecular features","text":"<p>fingerprint = datapoint.get_fingerprint() print(f\"Fingerprint shape: {fingerprint.shape if fingerprint is not None else None}\")</p>"},{"location":"api/data.html#themap.data.MoleculeDatapoint--fingerprint-shape-2048","title":"Fingerprint shape: (2048,)","text":"<p>features = datapoint.get_features(featurizer_name=\"ecfp\") print(f\"Features shape: {features.shape if features is not None else None}\")</p>"},{"location":"api/data.html#themap.data.MoleculeDatapoint--features-shape-2048","title":"Features shape: (2048,)","text":""},{"location":"api/data.html#themap.data.MoleculeDatapoint.rdkit_mol","title":"rdkit_mol  <code>property</code>","text":"<pre><code>rdkit_mol: Optional[Mol]\n</code></pre> <p>Get the RDKit molecule object.</p> <p>This property lazily initializes the RDKit molecule if it hasn't been created yet. The molecule is cached to avoid recreating it multiple times.</p> <p>Returns:</p> Type Description <code>Optional[Mol]</code> <p>Optional[Chem.Mol]: RDKit molecule object. Returns None if molecule creation fails.</p>"},{"location":"api/data.html#themap.data.MoleculeDatapoint.number_of_atoms","title":"number_of_atoms  <code>property</code>","text":"<pre><code>number_of_atoms: int\n</code></pre> <p>Get the number of heavy atoms in the molecule.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of heavy atoms in the molecule.</p> <p>Raises:     ValueError: If the molecule cannot be created.</p>"},{"location":"api/data.html#themap.data.MoleculeDatapoint.number_of_bonds","title":"number_of_bonds  <code>property</code>","text":"<pre><code>number_of_bonds: int\n</code></pre> <p>Get the number of bonds in the molecule.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of bonds in the molecule.</p> <p>Raises:     ValueError: If the molecule cannot be created.</p>"},{"location":"api/data.html#themap.data.MoleculeDatapoint.molecular_weight","title":"molecular_weight  <code>property</code>","text":"<pre><code>molecular_weight: float\n</code></pre> <p>Get the molecular weight of the molecule.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Molecular weight of the molecule in atomic mass units.</p> <p>Raises:     ValueError: If the molecule cannot be created.</p>"},{"location":"api/data.html#themap.data.MoleculeDatapoint.logp","title":"logp  <code>property</code>","text":"<pre><code>logp: float\n</code></pre> <p>Calculate octanol-water partition coefficient.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>LogP value of the molecule.</p> <p>Raises:     ValueError: If the molecule cannot be created.</p>"},{"location":"api/data.html#themap.data.MoleculeDatapoint.num_rotatable_bonds","title":"num_rotatable_bonds  <code>property</code>","text":"<pre><code>num_rotatable_bonds: int\n</code></pre> <p>Get number of rotatable bonds.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of rotatable bonds in the molecule.</p> <p>Raises:     ValueError: If the molecule cannot be created.</p>"},{"location":"api/data.html#themap.data.MoleculeDatapoint.smiles_canonical","title":"smiles_canonical  <code>property</code>","text":"<pre><code>smiles_canonical: str\n</code></pre> <p>Get canonical SMILES representation.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Canonical SMILES string for the molecule.</p> <p>Raises:     ValueError: If the molecule cannot be created.</p>"},{"location":"api/data.html#themap.data.MoleculeDatapoint.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__() -&gt; None\n</code></pre> <p>Validate initialization data.</p>"},{"location":"api/data.html#themap.data.MoleculeDatapoint.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict\n</code></pre> <p>Convert datapoint to dictionary for serialization.</p>"},{"location":"api/data.html#themap.data.MoleculeDatapoint.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data: dict) -&gt; MoleculeDatapoint\n</code></pre> <p>Create datapoint from dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Dictionary containing the datapoint data.</p> required <p>Returns:</p> Name Type Description <code>MoleculeDatapoint</code> <code>MoleculeDatapoint</code> <p>Datapoint object.</p> Example <p>datapoint = MoleculeDatapoint.from_dict({ ...     \"task_id\": \"toxicity_prediction\", ...     \"smiles\": \"CCCO\", ...     \"bool_label\": True, ...     \"numeric_label\": 0.8 ... }) print(datapoint)</p>"},{"location":"api/data.html#themap.data.MoleculeDatapoint.from_dict--moleculedatapointtask_idtoxicity_prediction-smilesccco-bool_labeltrue-numeric_label08","title":"MoleculeDatapoint(task_id=toxicity_prediction, smiles=CCCO, bool_label=True, numeric_label=0.8)","text":""},{"location":"api/data.html#themap.data.MoleculeDatapoint.get_fingerprint","title":"get_fingerprint","text":"<pre><code>get_fingerprint(force_recompute: bool = False) -&gt; Optional[np.ndarray]\n</code></pre> <p>Get the Morgan fingerprint for a molecule.</p> <p>This method computes the Extended-Connectivity Fingerprint (ECFP) for the molecule using RDKit's Morgan fingerprint generator. Features are cached globally to avoid recomputation across different instances.</p> <p>Parameters:</p> Name Type Description Default <code>force_recompute</code> <code>bool</code> <p>If True, the fingerprint is recomputed even if cached.</p> <code>False</code> <p>Returns:</p> Type Description <code>Optional[ndarray]</code> <p>Optional[np.ndarray]: Morgan fingerprint for the molecule (r=2, nbits=2048). The fingerprint is a binary vector representing the molecular structure. Returns None if fingerprint generation fails.</p> <p>Raises:</p> Type Description <code>FeaturizationError</code> <p>If computing fingerprint for molecule fails.</p> Note <p>dtype of the fingerprint is np.uint8.</p>"},{"location":"api/data.html#themap.data.MoleculeDatapoint.get_features","title":"get_features","text":"<pre><code>get_features(\n    featurizer_name: Optional[str] = \"ecfp\", force_recompute: bool = False\n) -&gt; Optional[np.ndarray]\n</code></pre> <p>Get features for a molecule using a featurizer model.</p> <p>This method computes molecular features using the specified featurizer model. Features are cached globally to avoid recomputation across different instances.</p> <p>Parameters:</p> Name Type Description Default <code>featurizer_name</code> <code>Optional[str]</code> <p>Name of the featurizer model to use. Defaults to \"ecfp\". If None, returns None.</p> <code>'ecfp'</code> <code>force_recompute</code> <code>bool</code> <p>If True, features are recomputed even if cached.</p> <code>False</code> <p>Returns:</p> Type Description <code>Optional[ndarray]</code> <p>Optional[np.ndarray]: Features for the molecule. The shape and content depend on the featurizer used. Returns None if feature generation fails or featurizer_name is None.</p> Note <p>dtype of the features is different for different featurizers. For example, ecfp and fcfp dtype is np.uint8, while mordred dtype is np.float64.</p> <p>Raises:</p> Type Description <code>FeaturizationError</code> <p>If computing features for molecule fails.</p>"},{"location":"api/data.html#themap.data.MoleculeDataset","title":"MoleculeDataset  <code>dataclass</code>","text":"<p>Data structure holding information for a dataset of molecules.</p> <p>This class represents a collection of molecule datapoints, providing methods for dataset manipulation, feature computation, and statistical analysis.</p> <p>Attributes:</p> Name Type Description <code>task_id</code> <code>str</code> <p>String describing the task this dataset is taken from.</p> <code>data</code> <code>List[MoleculeDatapoint]</code> <p>List of MoleculeDatapoint objects.</p> <code>_current_featurizer</code> <code>Optional[str]</code> <p>Name of the current featurizer.</p> <code>_cache_info</code> <code>Dict[str, Any]</code> <p>Information about the feature caching.</p> <code>_persistent_cache</code> <code>Optional[PersistentFeatureCache]</code> <p>Persistent feature cache.</p> Properties <p>computed_features (Optional[NDArray[np.float32]]): Get the cached features for the dataset. labels (List[bool]): Get the labels for the dataset. smiles (List[str]): Get the SMILES for the dataset. ratio (float): Get the ratio of positive to negative labels.</p> <p>Methods:</p> Name Description <code>load_from_file</code> <p>Load dataset from a file</p> <code>get_features</code> <p>Get the features for the entire dataset using a featurizer</p> <code>get_prototype</code> <p>Get the prototype of the dataset</p> <code>get_statistics</code> <p>Get the statistics of the dataset</p> <code>filter</code> <p>Filter the dataset</p> <code>clear_cache</code> <p>Clear the cache</p> <code>enable_persistent_cache</code> <p>Enable persistent caching for this dataset</p> <code>get_persistent_cache_stats</code> <p>Get statistics about the persistent cache</p> <code>get_cache_info</code> <p>Get information about the current cache state</p> <code>get_memory_usage</code> <p>Get memory usage statistics for the dataset</p> <code>optimize_memory</code> <p>Optimize memory usage by cleaning up unnecessary data</p> <code>validate_dataset_integrity</code> <p>Validate the integrity of the dataset</p> <p>Examples:</p>"},{"location":"api/data.html#themap.data.MoleculeDataset--load-a-dataset-from-a-file","title":"Load a dataset from a file:","text":"<p>dataset = MoleculeDataset.load_from_file(\"datasets/test/CHEMBL2219358.jsonl.gz\") print(dataset)</p>"},{"location":"api/data.html#themap.data.MoleculeDataset--moleculedatasettask_idchembl2219358-task_size157","title":"MoleculeDataset(task_id=CHEMBL2219358, task_size=157)","text":""},{"location":"api/data.html#themap.data.MoleculeDataset--compute-the-dataset-embedding","title":"compute the dataset embedding:","text":"<p>dataset.get_features(featurizer_name=\"fcfp\", n_jobs=1)</p>"},{"location":"api/data.html#themap.data.MoleculeDataset--compute-the-prototype","title":"compute the prototype:","text":"<p>dataset.get_prototype(featurizer_name=\"fcfp\")</p>"},{"location":"api/data.html#themap.data.MoleculeDataset--compute-the-dataset-statistics","title":"compute the dataset statistics:","text":"<p>dataset.get_statistics()</p>"},{"location":"api/data.html#themap.data.MoleculeDataset--filter-the-dataset","title":"filter the dataset:","text":"<p>dataset.filter(lambda x: x.bool_label == 1)</p>"},{"location":"api/data.html#themap.data.MoleculeDataset--enable-persistent-caching","title":"enable persistent caching:","text":"<p>dataset.enable_persistent_cache(\"cache/\")</p>"},{"location":"api/data.html#themap.data.MoleculeDataset--get-statistics-about-the-persistent-cache","title":"get statistics about the persistent cache:","text":"<p>dataset.get_persistent_cache_stats()</p>"},{"location":"api/data.html#themap.data.MoleculeDataset--get-information-about-the-current-cache-state","title":"get information about the current cache state:","text":"<p>dataset.get_cache_info()</p>"},{"location":"api/data.html#themap.data.MoleculeDataset--get-memory-usage-statistics-for-the-dataset","title":"get memory usage statistics for the dataset:","text":"<p>dataset.get_memory_usage()</p>"},{"location":"api/data.html#themap.data.MoleculeDataset--optimize-memory-usage-by-cleaning-up-unnecessary-data","title":"optimize memory usage by cleaning up unnecessary data:","text":"<p>dataset.optimize_memory()</p>"},{"location":"api/data.html#themap.data.MoleculeDataset--validate-the-integrity-of-the-dataset","title":"validate the integrity of the dataset:","text":"<p>dataset.validate_dataset_integrity()</p>"},{"location":"api/data.html#themap.data.MoleculeDataset.computed_features","title":"computed_features  <code>property</code>","text":"<pre><code>computed_features: Optional[NDArray[float32]]\n</code></pre> <p>Get the cached features for the dataset.</p> <p>Returns:</p> Type Description <code>Optional[NDArray[float32]]</code> <p>Optional[NDArray[np.float32]]: Cached features for the dataset if available, None otherwise.</p>"},{"location":"api/data.html#themap.data.MoleculeDataset.labels","title":"labels  <code>property</code>","text":"<pre><code>labels: NDArray[int32]\n</code></pre> <p>Get the boolean labels for all molecules in the dataset.</p> <p>Returns:</p> Type Description <code>NDArray[int32]</code> <p>Array of boolean labels converted to integers (0/1)</p>"},{"location":"api/data.html#themap.data.MoleculeDataset.smiles","title":"smiles  <code>property</code>","text":"<pre><code>smiles: List[str]\n</code></pre> <p>Get the SMILES strings for all molecules in the dataset.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of SMILES strings</p>"},{"location":"api/data.html#themap.data.MoleculeDataset.positive_ratio","title":"positive_ratio  <code>property</code>","text":"<pre><code>positive_ratio: float\n</code></pre> <p>Get the ratio of positive to negative examples in the dataset.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Ratio of positive to negative examples in the dataset.</p>"},{"location":"api/data.html#themap.data.MoleculeDataset.get_computed_features","title":"get_computed_features  <code>property</code>","text":"<pre><code>get_computed_features: NDArray[float32]\n</code></pre> <p>Deprecated: Use 'computed_features' property instead.</p>"},{"location":"api/data.html#themap.data.MoleculeDataset.get_labels","title":"get_labels  <code>property</code>","text":"<pre><code>get_labels: NDArray[int32]\n</code></pre> <p>Deprecated: Use 'labels' property instead.</p>"},{"location":"api/data.html#themap.data.MoleculeDataset.get_smiles","title":"get_smiles  <code>property</code>","text":"<pre><code>get_smiles: List[str]\n</code></pre> <p>Deprecated: Use 'smiles' property instead.</p>"},{"location":"api/data.html#themap.data.MoleculeDataset.get_ratio","title":"get_ratio  <code>property</code>","text":"<pre><code>get_ratio: float\n</code></pre> <p>Deprecated: Use 'positive_ratio' property instead.</p>"},{"location":"api/data.html#themap.data.MoleculeDataset.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__() -&gt; None\n</code></pre> <p>Validate dataset initialization.</p>"},{"location":"api/data.html#themap.data.MoleculeDataset.get_features","title":"get_features","text":"<pre><code>get_features(\n    featurizer_name: str,\n    n_jobs: Optional[int] = DEFAULT_N_JOBS,\n    force_recompute: bool = False,\n    batch_size: int = DEFAULT_BATCH_SIZE,\n) -&gt; np.ndarray\n</code></pre> <p>Get the features for the entire dataset using a featurizer.</p> <p>Efficiently computes features for all molecules in the dataset using the specified featurizer, taking advantage of the featurizer's built-in parallelization capabilities and maintaining a two-level cache strategy.</p> <p>Parameters:</p> Name Type Description Default <code>featurizer_name</code> <code>str</code> <p>Name of the featurizer to use</p> required <code>n_jobs</code> <code>Optional[int]</code> <p>Number of parallel jobs. If provided, temporarily                 overrides the featurizer's own setting</p> <code>DEFAULT_N_JOBS</code> <code>force_recompute</code> <code>bool</code> <p>Whether to force recomputation even if cached</p> <code>False</code> <code>batch_size</code> <code>int</code> <p>Batch size for processing, used for memory efficiency             when handling large datasets</p> <code>DEFAULT_BATCH_SIZE</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Features for the entire dataset, shape (n_samples, n_features)</p> <code>ndarray</code> <p>if the features are already computed, they are loaded from the cache.</p> <code>ndarray</code> <p>if the features are not computed, they are computed and cached.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the generated features length doesn't match the dataset length</p> <code>TypeError</code> <p>If featurizer_name is not a string</p> <code>RuntimeError</code> <p>If featurization fails</p> <code>IndexError</code> <p>If dataset is empty</p> Notes <ul> <li>Output dtype is different for each featurizer.</li> </ul>"},{"location":"api/data.html#themap.data.MoleculeDataset.validate_dataset_integrity","title":"validate_dataset_integrity","text":"<pre><code>validate_dataset_integrity() -&gt; bool\n</code></pre> <p>Validate the integrity of the dataset.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if dataset is valid, False otherwise</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If critical integrity issues are found</p>"},{"location":"api/data.html#themap.data.MoleculeDataset.get_memory_usage","title":"get_memory_usage","text":"<pre><code>get_memory_usage() -&gt; Dict[str, float]\n</code></pre> <p>Get memory usage statistics for the dataset.</p> <p>Returns:</p> Type Description <code>Dict[str, float]</code> <p>Dictionary with memory usage in MB for different components</p>"},{"location":"api/data.html#themap.data.MoleculeDataset.optimize_memory","title":"optimize_memory","text":"<pre><code>optimize_memory() -&gt; Dict[str, Any]\n</code></pre> <p>Optimize memory usage by cleaning up unnecessary data.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary with optimization results</p>"},{"location":"api/data.html#themap.data.MoleculeDataset.clear_cache","title":"clear_cache","text":"<pre><code>clear_cache() -&gt; None\n</code></pre> <p>Clear cached features for this dataset from global cache.</p>"},{"location":"api/data.html#themap.data.MoleculeDataset.enable_persistent_cache","title":"enable_persistent_cache","text":"<pre><code>enable_persistent_cache(cache_dir: Union[str, Path]) -&gt; None\n</code></pre> <p>Enable persistent caching for this dataset.</p> <p>Parameters:</p> Name Type Description Default <code>cache_dir</code> <code>Union[str, Path]</code> <p>Directory for storing cached features</p> required"},{"location":"api/data.html#themap.data.MoleculeDataset.get_features_with_persistent_cache","title":"get_features_with_persistent_cache","text":"<pre><code>get_features_with_persistent_cache(\n    featurizer_name: str,\n    cache_dir: Optional[Union[str, Path]] = None,\n    n_jobs: Optional[int] = None,\n    force_recompute: bool = False,\n    batch_size: int = 1000,\n) -&gt; NDArray[np.float32]\n</code></pre> <p>Get dataset features with persistent caching enabled.</p> <p>This method provides the same functionality as get_features but with persistent disk caching to avoid recomputation across sessions.</p> <p>Parameters:</p> Name Type Description Default <code>featurizer_name</code> <code>str</code> <p>Name of the featurizer to use</p> required <code>cache_dir</code> <code>Optional[Union[str, Path]]</code> <p>Directory for persistent cache (if None, uses existing cache)</p> <code>None</code> <code>n_jobs</code> <code>Optional[int]</code> <p>Number of parallel jobs</p> <code>None</code> <code>force_recompute</code> <code>bool</code> <p>Whether to force recomputation even if cached</p> <code>False</code> <code>batch_size</code> <code>int</code> <p>Batch size for processing</p> <code>1000</code> <p>Returns:</p> Type Description <code>NDArray[float32]</code> <p>Features for the entire dataset</p>"},{"location":"api/data.html#themap.data.MoleculeDataset.get_persistent_cache_stats","title":"get_persistent_cache_stats","text":"<pre><code>get_persistent_cache_stats() -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Get statistics about the persistent cache.</p> <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>Cache statistics if persistent cache is enabled, None otherwise</p>"},{"location":"api/data.html#themap.data.MoleculeDataset.get_cache_info","title":"get_cache_info","text":"<pre><code>get_cache_info() -&gt; Dict[str, Any]\n</code></pre> <p>Get information about the current cache state.</p>"},{"location":"api/data.html#themap.data.MoleculeDataset.get_prototype","title":"get_prototype","text":"<pre><code>get_prototype(\n    featurizer_name: str,\n) -&gt; Tuple[NDArray[np.float32], NDArray[np.float32]]\n</code></pre> <p>Get the prototype of the dataset.</p> <p>This method calculates the mean feature vector of positive and negative examples in the dataset using the specified featurizer.</p> <p>Parameters:</p> Name Type Description Default <code>featurizer_name</code> <code>str</code> <p>Name of the featurizer to use.</p> required <p>Returns:</p> Type Description <code>Tuple[NDArray[float32], NDArray[float32]]</code> <p>Tuple[NDArray[np.float32], NDArray[np.float32]]: Tuple containing: - positive_prototype: Mean feature vector of positive examples - negative_prototype: Mean feature vector of negative examples</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there are no positive or negative examples in the dataset</p> <code>TypeError</code> <p>If featurizer_name is not a string</p> <code>RuntimeError</code> <p>If feature computation fails</p> Notes <ul> <li>It assumes there are two positive and two negative examples in the dataset.</li> <li>Output dtype is different for each featurizer.</li> </ul>"},{"location":"api/data.html#themap.data.MoleculeDataset.load_from_file","title":"load_from_file  <code>staticmethod</code>","text":"<pre><code>load_from_file(path: Union[str, RichPath]) -&gt; MoleculeDataset\n</code></pre> <p>Load dataset from a JSONL.GZ file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, RichPath]</code> <p>Path to the JSONL.GZ file.</p> required <p>Returns:</p> Name Type Description <code>MoleculeDataset</code> <code>MoleculeDataset</code> <p>Loaded dataset.</p>"},{"location":"api/data.html#themap.data.MoleculeDataset.filter","title":"filter","text":"<pre><code>filter(condition: Callable[[MoleculeDatapoint], bool]) -&gt; MoleculeDataset\n</code></pre> <p>Filter dataset based on a condition.</p> <p>Parameters:</p> Name Type Description Default <code>condition</code> <code>Callable[[MoleculeDatapoint], bool]</code> <p>Function that returns True/False for each datapoint.</p> required <p>Returns:</p> Name Type Description <code>MoleculeDataset</code> <code>MoleculeDataset</code> <p>New dataset containing only the filtered datapoints.</p>"},{"location":"api/data.html#themap.data.MoleculeDataset.get_statistics","title":"get_statistics","text":"<pre><code>get_statistics() -&gt; DatasetStats\n</code></pre> <p>Get statistics about the dataset.</p> <p>Returns:</p> Name Type Description <code>DatasetStats</code> <code>DatasetStats</code> <p>Dictionary containing: - size: Total number of datapoints - positive_ratio: Ratio of positive to negative examples - avg_molecular_weight: Average molecular weight - avg_atoms: Average number of atoms - avg_bonds: Average number of bonds</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the dataset is empty</p>"},{"location":"api/data.html#themap.data.DataFold","title":"DataFold","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enum for data fold types.</p> <p>This enum represents the different data splits used in machine learning: - TRAIN (0): Training/source tasks - VALIDATION (1): Validation/development tasks - TEST (2): Test/target tasks</p> <p>By inheriting from IntEnum, each fold type is assigned an integer value which allows for easy indexing and comparison operations.</p>"},{"location":"api/data.html#themap.data.MoleculeDatasets","title":"MoleculeDatasets","text":"<p>Dataset of related tasks, provided as individual files split into meta-train, meta-valid and meta-test sets.</p> <p>Attributes:</p> Name Type Description <code>_fold_to_data_paths</code> <code>Dict[DataFold, List[RichPath]]</code> <p>Dictionary mapping data folds to their respective data paths.</p> <code>_num_workers</code> <code>Optional[int]</code> <p>Number of workers for data loading.</p> <code>_cache_dir</code> <code>Optional[Union[str, Path]]</code> <p>Directory for persistent caching.</p> <code>_global_cache</code> <code>Optional[GlobalMoleculeCache]</code> <p>Global molecule cache.</p> <code>_loaded_datasets</code> <code>Dict[str, MoleculeDataset]</code> <p>Dictionary mapping dataset names to their respective loaded datasets.</p> Properties <p>get_num_fold_tasks (int): Get the number of tasks in a specific fold. get_task_names (List[str]): Get the list of task names in a specific fold. load_datasets (Dict[str, MoleculeDataset]): Load all datasets from specified folds. compute_all_features_with_deduplication (Dict[str, np.ndarray]): Compute features for all datasets with global SMILES deduplication. get_distance_computation_ready_features (Tuple[List[np.ndarray], List[np.ndarray], List[str], List[str]]): Get features organized for efficient N\u00d7M distance matrix computation. get_global_cache_stats (Optional[Dict]): Get statistics about the global cache usage.</p> <p>Methods:</p> Name Description <code>from_directory </code> <p>Create MoleculeDatasets from a directory.</p> <code>get_num_fold_tasks </code> <p>Get the number of tasks in a specific fold.</p> <code>get_task_names </code> <p>Get the list of task names in a specific fold.</p> <code>load_datasets </code> <p>Load all datasets from specified folds.</p> <code>compute_all_features_with_deduplication </code> <p>Compute features for all datasets with global SMILES deduplication.</p> <code>get_distance_computation_ready_features </code> <p>Get features organized for efficient N\u00d7M distance matrix computation.</p> <code>get_global_cache_stats </code> <p>Get statistics about the global cache usage.</p> <p>Examples:</p>"},{"location":"api/data.html#themap.data.MoleculeDatasets--create-moleculedatasets-from-a-directory","title":"Create MoleculeDatasets from a directory:","text":"<p>molecule_datasets = MoleculeDatasets.from_directory(\"datasets/\")</p>"},{"location":"api/data.html#themap.data.MoleculeDatasets--get-the-number-of-tasks-in-the-train-fold","title":"Get the number of tasks in the train fold:","text":"<p>molecule_datasets.get_num_fold_tasks(DataFold.TRAIN)</p>"},{"location":"api/data.html#themap.data.MoleculeDatasets--get-the-list-of-task-names-in-the-validation-fold","title":"Get the list of task names in the validation fold:","text":"<p>molecule_datasets.get_task_names(DataFold.VALIDATION)</p>"},{"location":"api/data.html#themap.data.MoleculeDatasets--get-the-list-of-task-names-in-the-test-fold","title":"Get the list of task names in the test fold:","text":"<p>molecule_datasets.get_task_names(DataFold.TEST)</p>"},{"location":"api/data.html#themap.data.MoleculeDatasets.__init__","title":"__init__","text":"<pre><code>__init__(\n    train_data_paths: Optional[List[RichPath]] = None,\n    valid_data_paths: Optional[List[RichPath]] = None,\n    test_data_paths: Optional[List[RichPath]] = None,\n    num_workers: Optional[int] = None,\n    cache_dir: Optional[Union[str, Path]] = None,\n) -&gt; None\n</code></pre> <p>Initialize MoleculeDatasets.</p> <p>Parameters:</p> Name Type Description Default <code>train_data_paths</code> <code>List[RichPath]</code> <p>List of paths to training data files.</p> <code>None</code> <code>valid_data_paths</code> <code>List[RichPath]</code> <p>List of paths to validation data files.</p> <code>None</code> <code>test_data_paths</code> <code>List[RichPath]</code> <p>List of paths to test data files.</p> <code>None</code> <code>num_workers</code> <code>Optional[int]</code> <p>Number of workers for data loading.</p> <code>None</code> <code>cache_dir</code> <code>Optional[Union[str, Path]]</code> <p>Directory for persistent caching.</p> <code>None</code>"},{"location":"api/data.html#themap.data.MoleculeDatasets.get_num_fold_tasks","title":"get_num_fold_tasks","text":"<pre><code>get_num_fold_tasks(fold: DataFold) -&gt; int\n</code></pre> <p>Get number of tasks in a specific fold.</p> <p>Parameters:</p> Name Type Description Default <code>fold</code> <code>DataFold</code> <p>The fold to get number of tasks for.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of tasks in the fold.</p>"},{"location":"api/data.html#themap.data.MoleculeDatasets.from_directory","title":"from_directory  <code>staticmethod</code>","text":"<pre><code>from_directory(\n    directory: Union[str, RichPath],\n    task_list_file: Optional[Union[str, RichPath]] = None,\n    cache_dir: Optional[Union[str, Path]] = None,\n    **kwargs: Any,\n) -&gt; MoleculeDatasets\n</code></pre> <p>Create MoleculeDatasets from a directory.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>Union[str, RichPath]</code> <p>Directory containing train/valid/test subdirectories.</p> required <code>task_list_file</code> <code>Optional[Union[str, RichPath]]</code> <p>File containing list of tasks to include. Can be either a text file (one task per line) or JSON file with fold-specific task lists.</p> <code>None</code> <code>cache_dir</code> <code>Optional[Union[str, Path]]</code> <p>Directory for persistent caching.</p> <code>None</code> <code>**kwargs</code> <code>any</code> <p>Additional arguments to pass to MoleculeDatasets constructor.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>MoleculeDatasets</code> <code>MoleculeDatasets</code> <p>Created dataset.</p>"},{"location":"api/data.html#themap.data.MoleculeDatasets.get_task_names","title":"get_task_names","text":"<pre><code>get_task_names(data_fold: DataFold) -&gt; List[str]\n</code></pre> <p>Get list of task names in a specific fold.</p> <p>Parameters:</p> Name Type Description Default <code>data_fold</code> <code>DataFold</code> <p>The fold to get task names for.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of task names in the fold.</p>"},{"location":"api/data.html#themap.data.MoleculeDatasets.load_datasets","title":"load_datasets","text":"<pre><code>load_datasets(\n    folds: Optional[List[DataFold]] = None,\n) -&gt; Dict[str, MoleculeDataset]\n</code></pre> <p>Load all datasets from specified folds.</p> <p>Parameters:</p> Name Type Description Default <code>folds</code> <code>Optional[List[DataFold]]</code> <p>List of folds to load. If None, loads all folds.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, MoleculeDataset]</code> <p>Dictionary mapping dataset names to loaded datasets</p>"},{"location":"api/data.html#themap.data.MoleculeDatasets.compute_all_features_with_deduplication","title":"compute_all_features_with_deduplication","text":"<pre><code>compute_all_features_with_deduplication(\n    featurizer_name: str,\n    folds: Optional[List[DataFold]] = None,\n    batch_size: int = 1000,\n    n_jobs: int = -1,\n    force_recompute: bool = False,\n) -&gt; Dict[str, np.ndarray]\n</code></pre> <p>Compute features for all datasets with global SMILES deduplication.</p> <p>This method provides significant efficiency gains by: 1. Finding all unique SMILES across all datasets 2. Computing features only once per unique SMILES 3. Distributing computed features back to all datasets 4. Using persistent caching to avoid recomputation</p> <p>Parameters:</p> Name Type Description Default <code>featurizer_name</code> <code>str</code> <p>Name of featurizer to use</p> required <code>folds</code> <code>Optional[List[DataFold]]</code> <p>List of folds to process. If None, processes all folds</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>Batch size for feature computation</p> <code>1000</code> <code>n_jobs</code> <code>int</code> <p>Number of parallel jobs</p> <code>-1</code> <code>force_recompute</code> <code>bool</code> <p>Whether to force recomputation even if cached</p> <code>False</code> <p>Returns:</p> Type Description <code>Dict[str, ndarray]</code> <p>Dictionary mapping dataset names to computed features</p>"},{"location":"api/data.html#themap.data.MoleculeDatasets.get_distance_computation_ready_features","title":"get_distance_computation_ready_features","text":"<pre><code>get_distance_computation_ready_features(\n    featurizer_name: str,\n    source_fold: DataFold = DataFold.TRAIN,\n    target_folds: Optional[List[DataFold]] = None,\n) -&gt; Tuple[List[np.ndarray], List[np.ndarray], List[str], List[str]]\n</code></pre> <p>Get features organized for efficient N\u00d7M distance matrix computation.</p> <p>Parameters:</p> Name Type Description Default <code>featurizer_name</code> <code>str</code> <p>Name of featurizer to use</p> required <code>source_fold</code> <code>DataFold</code> <p>Fold to use as source datasets (N)</p> <code>TRAIN</code> <code>target_folds</code> <code>Optional[List[DataFold]]</code> <p>Folds to use as target datasets (M)</p> <code>None</code> <p>Returns:</p> Type Description <code>List[ndarray]</code> <p>Tuple containing:</p> <code>List[ndarray]</code> <ul> <li>source_features: List of feature arrays for source datasets</li> </ul> <code>List[str]</code> <ul> <li>target_features: List of feature arrays for target datasets</li> </ul> <code>List[str]</code> <ul> <li>source_names: List of source dataset names</li> </ul> <code>Tuple[List[ndarray], List[ndarray], List[str], List[str]]</code> <ul> <li>target_names: List of target dataset names</li> </ul> Notes <p>if you dont provide target_folds, it will use the validation and test folds as default target folds.</p>"},{"location":"api/data.html#themap.data.MoleculeDatasets.get_global_cache_stats","title":"get_global_cache_stats","text":"<pre><code>get_global_cache_stats() -&gt; Optional[Dict]\n</code></pre> <p>Get statistics about the global cache usage.</p> <p>Returns:</p> Type Description <code>Optional[Dict]</code> <p>Cache statistics if global cache is enabled, None otherwise</p>"},{"location":"api/data.html#themap.data.ProteinMetadataDataset","title":"ProteinMetadataDataset  <code>dataclass</code>","text":"<p>Single protein metadata dataset representing one task.</p> <p>Attributes:</p> Name Type Description <code>task_id</code> <code>str</code> <p>Unique identifier for the task (CHEMBL ID)</p> <code>uniprot_id</code> <code>str</code> <p>UniProt accession ID for the protein</p> <code>sequence</code> <code>str</code> <p>Protein amino acid sequence</p> <code>features</code> <code>Optional[NDArray[float32]]</code> <p>Optional pre-computed protein features</p> Properties <p>get_computed_features (Optional[NDArray[np.float32]]): Get computed protein features.</p> <p>Methods:</p> Name Description <code>get_features </code> <p>Get protein features using the specified featurizer</p>"},{"location":"api/data.html#themap.data.ProteinMetadataDataset.get_computed_features","title":"get_computed_features  <code>property</code>","text":"<pre><code>get_computed_features: Optional[NDArray[float32]]\n</code></pre> <p>Get computed protein features.</p>"},{"location":"api/data.html#themap.data.ProteinMetadataDataset.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__() -&gt; None\n</code></pre> <p>Validate initialization data.</p>"},{"location":"api/data.html#themap.data.ProteinMetadataDataset.get_features","title":"get_features","text":"<pre><code>get_features(\n    featurizer_name: str = \"esm3_sm_open_v1\", layer: Optional[int] = None\n) -&gt; NDArray[np.float32]\n</code></pre> <p>Get protein features using the specified featurizer.</p> <p>Parameters:</p> Name Type Description Default <code>featurizer_name</code> <code>str</code> <p>Name of the protein featurizer to use</p> <code>'esm3_sm_open_v1'</code> <code>layer</code> <code>Optional[int]</code> <p>Layer number for ESM models</p> <code>None</code> <p>Returns:</p> Type Description <code>NDArray[float32]</code> <p>Computed protein features</p>"},{"location":"api/data.html#themap.data.ProteinMetadataDatasets","title":"ProteinMetadataDatasets","text":"<p>Collection of protein datasets for different folds (train/validation/test).</p> <p>Similar to MoleculeDatasets but specifically designed for protein data management, including FASTA file downloading, caching, and feature computation.</p> <p>Attributes:</p> Name Type Description <code>_fold_to_data_paths</code> <code>Dict[DataFold, List[RichPath]]</code> <p>Dictionary mapping data folds to their respective data paths.</p> <code>_num_workers</code> <code>Optional[int]</code> <p>Number of workers for data loading.</p> <code>_cache_dir</code> <code>Optional[Union[str, Path]]</code> <p>Directory for persistent caching.</p> <code>_global_cache</code> <code>Optional[GlobalMoleculeCache]</code> <p>Global molecule cache.</p> <code>_loaded_datasets</code> <code>Dict[str, ProteinMetadataDataset]</code> <p>Dictionary mapping dataset names to their respective loaded datasets.</p> <code>uniprot_mapping_file</code> <code>Optional[Union[str, Path]]</code> <p>Path to CHEMBLID -&gt; UNIPROT mapping file.</p> Properties <p>uniprot_mapping (pd.DataFrame): Lazy loaded UniProt mapping dataframe. get_num_fold_tasks (int): Get the number of tasks in a specific fold. get_task_names (List[str]): Get the list of task names in a specific fold. load_datasets (Dict[str, ProteinMetadataDataset]): Load all datasets from specified folds. compute_all_features_with_deduplication (Dict[str, NDArray[np.float32]]): Compute features for all datasets with global SMILES deduplication. get_distance_computation_ready_features (Tuple[List[NDArray[np.float32]], List[NDArray[np.float32]], List[str], List[str]]): Get features organized for efficient N\u00d7M distance matrix computation. get_global_cache_stats (Optional[Dict[str, Any]]): Get statistics about the global cache usage.</p> <p>Methods:</p> Name Description <code>from_directory </code> <p>Create ProteinMetadataDatasets from a directory.</p> <code>get_num_fold_tasks </code> <p>Get the number of tasks in a specific fold.</p> <code>get_task_names </code> <p>Get the list of task names in a specific fold.</p> <code>load_datasets </code> <p>Load all datasets from specified folds.</p> <code>compute_all_features_with_deduplication </code> <p>Compute features for all datasets with global SMILES deduplication.</p> <code>get_distance_computation_ready_features </code> <p>Get features organized for efficient N\u00d7M distance matrix computation.</p> <code>get_global_cache_stats </code> <p>Get statistics about the global cache usage.</p>"},{"location":"api/data.html#themap.data.ProteinMetadataDatasets.uniprot_mapping","title":"uniprot_mapping  <code>property</code>","text":"<pre><code>uniprot_mapping: DataFrame\n</code></pre> <p>Lazy load UniProt mapping dataframe.</p>"},{"location":"api/data.html#themap.data.ProteinMetadataDatasets.__init__","title":"__init__","text":"<pre><code>__init__(\n    train_data_paths: Optional[List[RichPath]] = None,\n    valid_data_paths: Optional[List[RichPath]] = None,\n    test_data_paths: Optional[List[RichPath]] = None,\n    num_workers: Optional[int] = None,\n    cache_dir: Optional[Union[str, Path]] = None,\n    uniprot_mapping_file: Optional[Union[str, Path]] = None,\n) -&gt; None\n</code></pre> <p>Initialize ProteinMetadataDatasets.</p>"},{"location":"api/data.html#themap.data.ProteinMetadataDatasets.get_uniprot_id_from_chembl","title":"get_uniprot_id_from_chembl","text":"<pre><code>get_uniprot_id_from_chembl(chembl_id: str) -&gt; Optional[str]\n</code></pre> <p>Get UniProt ID from ChEMBL ID using mapping file.</p> <p>Parameters:</p> Name Type Description Default <code>chembl_id</code> <code>str</code> <p>ChEMBL task ID</p> required <p>Returns:</p> Type Description <code>Optional[str]</code> <p>UniProt accession ID if found, None otherwise</p>"},{"location":"api/data.html#themap.data.ProteinMetadataDatasets.download_fasta_for_task","title":"download_fasta_for_task","text":"<pre><code>download_fasta_for_task(chembl_id: str, output_path: Path) -&gt; bool\n</code></pre> <p>Download FASTA file for a single task.</p> <p>Parameters:</p> Name Type Description Default <code>chembl_id</code> <code>str</code> <p>ChEMBL task ID</p> required <code>output_path</code> <code>Path</code> <p>Path where to save the FASTA file</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if successful, False otherwise</p>"},{"location":"api/data.html#themap.data.ProteinMetadataDatasets.create_fasta_files_from_task_list","title":"create_fasta_files_from_task_list  <code>staticmethod</code>","text":"<pre><code>create_fasta_files_from_task_list(\n    task_list_file: Union[str, Path],\n    output_dir: Union[str, Path],\n    uniprot_mapping_file: Optional[Union[str, Path]] = None,\n) -&gt; ProteinMetadataDatasets\n</code></pre> <p>Create FASTA files from a task list and return ProteinMetadataDatasets.</p> <p>Parameters:</p> Name Type Description Default <code>task_list_file</code> <code>Union[str, Path]</code> <p>Path to JSON file containing fold-specific task lists</p> required <code>output_dir</code> <code>Union[str, Path]</code> <p>Base directory where to create train/test subdirectories</p> required <code>uniprot_mapping_file</code> <code>Optional[Union[str, Path]]</code> <p>Path to CHEMBLID -&gt; UNIPROT mapping file</p> <code>None</code> <p>Returns:</p> Type Description <code>ProteinMetadataDatasets</code> <p>ProteinMetadataDatasets instance with paths to created FASTA files</p>"},{"location":"api/data.html#themap.data.ProteinMetadataDatasets.from_directory","title":"from_directory  <code>staticmethod</code>","text":"<pre><code>from_directory(\n    directory: Union[str, RichPath],\n    task_list_file: Optional[Union[str, RichPath]] = None,\n    cache_dir: Optional[Union[str, Path]] = None,\n    uniprot_mapping_file: Optional[Union[str, Path]] = None,\n    **kwargs: Any,\n) -&gt; ProteinMetadataDatasets\n</code></pre> <p>Create ProteinMetadataDatasets from a directory containing FASTA files.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>Union[str, RichPath]</code> <p>Directory containing train/valid/test subdirectories with FASTA files</p> required <code>task_list_file</code> <code>Optional[Union[str, RichPath]]</code> <p>File containing list of tasks to include</p> <code>None</code> <code>cache_dir</code> <code>Optional[Union[str, Path]]</code> <p>Directory for persistent caching</p> <code>None</code> <code>uniprot_mapping_file</code> <code>Optional[Union[str, Path]]</code> <p>Path to CHEMBLID -&gt; UNIPROT mapping file</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments</p> <code>{}</code> <p>Returns:</p> Type Description <code>ProteinMetadataDatasets</code> <p>ProteinMetadataDatasets instance</p>"},{"location":"api/data.html#themap.data.ProteinMetadataDatasets.get_num_fold_tasks","title":"get_num_fold_tasks","text":"<pre><code>get_num_fold_tasks(fold: DataFold) -&gt; int\n</code></pre> <p>Get number of tasks in a specific fold.</p>"},{"location":"api/data.html#themap.data.ProteinMetadataDatasets.get_task_names","title":"get_task_names","text":"<pre><code>get_task_names(data_fold: DataFold) -&gt; List[str]\n</code></pre> <p>Get list of task names in a specific fold.</p>"},{"location":"api/data.html#themap.data.ProteinMetadataDatasets.load_datasets","title":"load_datasets","text":"<pre><code>load_datasets(\n    folds: Optional[List[DataFold]] = None,\n) -&gt; Dict[str, ProteinMetadataDataset]\n</code></pre> <p>Load all protein datasets from specified folds.</p> <p>Parameters:</p> Name Type Description Default <code>folds</code> <code>Optional[List[DataFold]]</code> <p>List of folds to load. If None, loads all folds.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, ProteinMetadataDataset]</code> <p>Dictionary mapping dataset names to loaded ProteinDataset objects</p>"},{"location":"api/data.html#themap.data.ProteinMetadataDatasets.compute_all_features_with_deduplication","title":"compute_all_features_with_deduplication","text":"<pre><code>compute_all_features_with_deduplication(\n    featurizer_name: str = \"esm3_sm_open_v1\",\n    layer: Optional[int] = None,\n    folds: Optional[List[DataFold]] = None,\n    batch_size: int = 100,\n    force_recompute: bool = False,\n) -&gt; Dict[str, NDArray[np.float32]]\n</code></pre> <p>Compute features for all protein datasets with UniProt ID deduplication.</p> <p>Parameters:</p> Name Type Description Default <code>featurizer_name</code> <code>str</code> <p>Name of protein featurizer to use</p> <code>'esm3_sm_open_v1'</code> <code>layer</code> <code>Optional[int]</code> <p>Layer number for ESM models</p> <code>None</code> <code>folds</code> <code>Optional[List[DataFold]]</code> <p>List of folds to process. If None, processes all folds</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>Batch size for feature computation</p> <code>100</code> <code>force_recompute</code> <code>bool</code> <p>Whether to force recomputation even if cached</p> <code>False</code> <p>Returns:</p> Type Description <code>Dict[str, NDArray[float32]]</code> <p>Dictionary mapping dataset names to computed features</p>"},{"location":"api/data.html#themap.data.ProteinMetadataDatasets.get_distance_computation_ready_features","title":"get_distance_computation_ready_features","text":"<pre><code>get_distance_computation_ready_features(\n    featurizer_name: str = \"esm3_sm_open_v1\",\n    layer: Optional[int] = None,\n    source_fold: DataFold = DataFold.TRAIN,\n    target_folds: Optional[List[DataFold]] = None,\n) -&gt; Tuple[\n    List[NDArray[np.float32]], List[NDArray[np.float32]], List[str], List[str]\n]\n</code></pre> <p>Get protein features organized for efficient N\u00d7M distance matrix computation.</p> <p>Parameters:</p> Name Type Description Default <code>featurizer_name</code> <code>str</code> <p>Name of protein featurizer to use</p> <code>'esm3_sm_open_v1'</code> <code>layer</code> <code>Optional[int]</code> <p>Layer number for ESM models</p> <code>None</code> <code>source_fold</code> <code>DataFold</code> <p>Fold to use as source datasets (N)</p> <code>TRAIN</code> <code>target_folds</code> <code>Optional[List[DataFold]]</code> <p>Folds to use as target datasets (M)</p> <code>None</code> <p>Returns:</p> Type Description <code>List[NDArray[float32]]</code> <p>Tuple containing:</p> <code>List[NDArray[float32]]</code> <ul> <li>source_features: List of feature arrays for source datasets</li> </ul> <code>List[str]</code> <ul> <li>target_features: List of feature arrays for target datasets</li> </ul> <code>List[str]</code> <ul> <li>source_names: List of source dataset names</li> </ul> <code>Tuple[List[NDArray[float32]], List[NDArray[float32]], List[str], List[str]]</code> <ul> <li>target_names: List of target dataset names</li> </ul>"},{"location":"api/data.html#themap.data.ProteinMetadataDatasets.save_features_to_file","title":"save_features_to_file","text":"<pre><code>save_features_to_file(\n    output_path: Union[str, Path],\n    featurizer_name: str = \"esm3_sm_open_v1\",\n    layer: Optional[int] = None,\n    folds: Optional[List[DataFold]] = None,\n) -&gt; None\n</code></pre> <p>Save computed features to a pickle file for efficient loading.</p> <p>Parameters:</p> Name Type Description Default <code>output_path</code> <code>Union[str, Path]</code> <p>Path where to save the features</p> required <code>featurizer_name</code> <code>str</code> <p>Name of protein featurizer used</p> <code>'esm3_sm_open_v1'</code> <code>layer</code> <code>Optional[int]</code> <p>Layer number for ESM models</p> <code>None</code> <code>folds</code> <code>Optional[List[DataFold]]</code> <p>List of folds to save. If None, saves all folds</p> <code>None</code>"},{"location":"api/data.html#themap.data.ProteinMetadataDatasets.load_features_from_file","title":"load_features_from_file  <code>staticmethod</code>","text":"<pre><code>load_features_from_file(\n    file_path: Union[str, Path],\n) -&gt; Dict[str, NDArray[np.float32]]\n</code></pre> <p>Load precomputed features from a pickle file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Union[str, Path]</code> <p>Path to the saved features file</p> required <p>Returns:</p> Type Description <code>Dict[str, NDArray[float32]]</code> <p>Dictionary mapping dataset names to features</p>"},{"location":"api/data.html#themap.data.ProteinMetadataDatasets.get_global_cache_stats","title":"get_global_cache_stats","text":"<pre><code>get_global_cache_stats() -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Get statistics about the global cache usage.</p>"},{"location":"api/data.html#themap.data.Tasks","title":"Tasks","text":"<p>Collection of tasks for molecular property prediction across different folds.</p> <p>This class manages multiple Task objects and provides unified access to molecular, protein, and metadata features across train/validation/test splits.</p>"},{"location":"api/data.html#themap.data.Tasks.__init__","title":"__init__","text":"<pre><code>__init__(\n    train_tasks: Optional[List[Task]] = None,\n    valid_tasks: Optional[List[Task]] = None,\n    test_tasks: Optional[List[Task]] = None,\n    cache_dir: Optional[Union[str, Path]] = None,\n) -&gt; None\n</code></pre> <p>Initialize Tasks collection.</p> <p>Parameters:</p> Name Type Description Default <code>train_tasks</code> <code>Optional[List[Task]]</code> <p>List of training tasks</p> <code>None</code> <code>valid_tasks</code> <code>Optional[List[Task]]</code> <p>List of validation tasks</p> <code>None</code> <code>test_tasks</code> <code>Optional[List[Task]]</code> <p>List of test tasks</p> <code>None</code> <code>cache_dir</code> <code>Optional[Union[str, Path]]</code> <p>Directory for persistent caching</p> <code>None</code>"},{"location":"api/data.html#themap.data.Tasks.from_directory","title":"from_directory  <code>staticmethod</code>","text":"<pre><code>from_directory(\n    directory: Union[str, RichPath],\n    task_list_file: Optional[Union[str, RichPath]] = None,\n    cache_dir: Optional[Union[str, Path]] = None,\n    load_molecules: bool = True,\n    load_proteins: bool = True,\n    load_metadata: bool = True,\n    metadata_types: Optional[List[str]] = None,\n    **kwargs: Any,\n) -&gt; Tasks\n</code></pre> <p>Create Tasks from a directory structure.</p> <p>Expected directory structure: directory/ \u251c\u2500\u2500 train/ \u2502   \u251c\u2500\u2500 CHEMBL123.jsonl.gz (molecules) \u2502   \u251c\u2500\u2500 CHEMBL123.fasta (proteins) \u2502   \u251c\u2500\u2500 CHEMBL123_assay.json (metadata) \u2502   \u2514\u2500\u2500 ... \u251c\u2500\u2500 valid/ \u2514\u2500\u2500 test/</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>Union[str, RichPath]</code> <p>Base directory containing task data</p> required <code>task_list_file</code> <code>Optional[Union[str, RichPath]]</code> <p>JSON file with fold-specific task lists</p> <code>None</code> <code>cache_dir</code> <code>Optional[Union[str, Path]]</code> <p>Directory for persistent caching</p> <code>None</code> <code>load_molecules</code> <code>bool</code> <p>Whether to load molecular data</p> <code>True</code> <code>load_proteins</code> <code>bool</code> <p>Whether to load protein data</p> <code>True</code> <code>load_metadata</code> <code>bool</code> <p>Whether to load metadata</p> <code>True</code> <code>metadata_types</code> <code>Optional[List[str]]</code> <p>List of metadata types to load</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tasks</code> <p>Tasks instance with loaded data</p>"},{"location":"api/data.html#themap.data.Tasks.get_num_fold_tasks","title":"get_num_fold_tasks","text":"<pre><code>get_num_fold_tasks(fold: DataFold) -&gt; int\n</code></pre> <p>Get number of tasks in a specific fold.</p>"},{"location":"api/data.html#themap.data.Tasks.get_task_ids","title":"get_task_ids","text":"<pre><code>get_task_ids(fold: DataFold) -&gt; List[str]\n</code></pre> <p>Get list of task IDs in a specific fold.</p>"},{"location":"api/data.html#themap.data.Tasks.get_tasks","title":"get_tasks","text":"<pre><code>get_tasks(fold: DataFold) -&gt; List[Task]\n</code></pre> <p>Get list of tasks in a specific fold.</p>"},{"location":"api/data.html#themap.data.Tasks.__len__","title":"__len__","text":"<pre><code>__len__() -&gt; int\n</code></pre> <p>Get number of tasks.</p>"},{"location":"api/data.html#themap.data.Tasks.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(index: int) -&gt; List[Task]\n</code></pre> <p>Get a task by index.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>int: index of the task</p> required <p>Returns:</p> Type Description <code>List[Task]</code> <p>List[Task]: list of tasks</p> Note <p>index 0: Train Tasks index 1: Validation Tasks index 2: Test Tasks</p> <p>Raises:</p> Type Description <code>IndexError</code> <p>if index is out of range</p>"},{"location":"api/data.html#themap.data.Tasks.get_task_by_id","title":"get_task_by_id","text":"<pre><code>get_task_by_id(task_id: str) -&gt; Optional[Task]\n</code></pre> <p>Get a specific task by its ID.</p>"},{"location":"api/data.html#themap.data.Tasks.compute_all_task_features","title":"compute_all_task_features","text":"<pre><code>compute_all_task_features(\n    molecule_featurizer: Optional[str] = None,\n    protein_featurizer: Optional[str] = None,\n    metadata_configs: Optional[Dict[str, Dict[str, Any]]] = None,\n    combination_method: str = \"concatenate\",\n    folds: Optional[List[DataFold]] = None,\n    force_recompute: bool = False,\n    **kwargs: Any,\n) -&gt; Dict[str, NDArray[np.float32]]\n</code></pre> <p>Compute combined features for all tasks.</p> <p>Parameters:</p> Name Type Description Default <code>molecule_featurizer</code> <code>Optional[str]</code> <p>Molecular featurizer name</p> <code>None</code> <code>protein_featurizer</code> <code>Optional[str]</code> <p>Protein featurizer name</p> <code>None</code> <code>metadata_configs</code> <code>Optional[Dict[str, Dict[str, Any]]]</code> <p>Metadata featurizer configurations</p> <code>None</code> <code>combination_method</code> <code>str</code> <p>How to combine features</p> <code>'concatenate'</code> <code>folds</code> <code>Optional[List[DataFold]]</code> <p>List of folds to process</p> <code>None</code> <code>force_recompute</code> <code>bool</code> <p>Whether to force recomputation</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dict[str, NDArray[float32]]</code> <p>Dictionary mapping task names to combined features</p>"},{"location":"api/data.html#themap.data.Tasks.get_distance_computation_ready_features","title":"get_distance_computation_ready_features","text":"<pre><code>get_distance_computation_ready_features(\n    molecule_featurizer: Optional[str] = None,\n    protein_featurizer: Optional[str] = None,\n    metadata_configs: Optional[Dict[str, Dict[str, Any]]] = None,\n    combination_method: str = \"concatenate\",\n    source_fold: DataFold = DataFold.TRAIN,\n    target_folds: Optional[List[DataFold]] = None,\n    **kwargs: Any,\n) -&gt; Tuple[\n    List[NDArray[np.float32]], List[NDArray[np.float32]], List[str], List[str]\n]\n</code></pre> <p>Get task features organized for efficient N\u00d7M distance matrix computation.</p> <p>Parameters:</p> Name Type Description Default <code>molecule_featurizer</code> <code>Optional[str]</code> <p>Molecular featurizer name</p> <code>None</code> <code>protein_featurizer</code> <code>Optional[str]</code> <p>Protein featurizer name</p> <code>None</code> <code>metadata_configs</code> <code>Optional[Dict[str, Dict[str, Any]]]</code> <p>Metadata featurizer configurations</p> <code>None</code> <code>combination_method</code> <code>str</code> <p>How to combine features</p> <code>'concatenate'</code> <code>source_fold</code> <code>DataFold</code> <p>Fold to use as source tasks (N)</p> <code>TRAIN</code> <code>target_folds</code> <code>Optional[List[DataFold]]</code> <p>Folds to use as target tasks (M)</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments</p> <code>{}</code> <p>Returns:</p> Type Description <code>List[NDArray[float32]]</code> <p>Tuple containing:</p> <code>List[NDArray[float32]]</code> <ul> <li>source_features: List of feature arrays for source tasks</li> </ul> <code>List[str]</code> <ul> <li>target_features: List of feature arrays for target tasks</li> </ul> <code>List[str]</code> <ul> <li>source_names: List of source task names</li> </ul> <code>Tuple[List[NDArray[float32]], List[NDArray[float32]], List[str], List[str]]</code> <ul> <li>target_names: List of target task names</li> </ul>"},{"location":"api/data.html#themap.data.Tasks.save_task_features_to_file","title":"save_task_features_to_file","text":"<pre><code>save_task_features_to_file(\n    output_path: Union[str, Path],\n    molecule_featurizer: Optional[str] = None,\n    protein_featurizer: Optional[str] = None,\n    metadata_configs: Optional[Dict[str, Dict[str, Any]]] = None,\n    combination_method: str = \"concatenate\",\n    folds: Optional[List[DataFold]] = None,\n    **kwargs: Any,\n) -&gt; None\n</code></pre> <p>Save computed task features to a pickle file for efficient loading.</p>"},{"location":"api/data.html#themap.data.Tasks.load_task_features_from_file","title":"load_task_features_from_file  <code>staticmethod</code>","text":"<pre><code>load_task_features_from_file(\n    file_path: Union[str, Path],\n) -&gt; Dict[str, NDArray[np.float32]]\n</code></pre> <p>Load precomputed task features from a pickle file.</p>"},{"location":"api/data.html#themap.data.Tasks.get_cache_stats","title":"get_cache_stats","text":"<pre><code>get_cache_stats() -&gt; Dict[str, Any]\n</code></pre> <p>Get statistics about feature caching.</p>"},{"location":"api/data.html#themap.data.TorchMoleculeDataset","title":"TorchMoleculeDataset","text":"<p>               Bases: <code>Dataset</code></p> <p>Enhanced PyTorch Dataset wrapper for molecular data.</p> <p>This class wraps a MoleculeDataset to provide PyTorch Dataset functionality while maintaining access to all original MoleculeDataset methods through delegation.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>MoleculeDataset</code> <p>MoleculeDataset object</p> required <code>transform</code> <code>callable</code> <p>Transform to apply to features</p> <code>None</code> <code>target_transform</code> <code>callable</code> <p>Transform to apply to labels</p> <code>None</code> <code>lazy_loading</code> <code>bool</code> <p>Whether to load data lazily. Defaults to False.</p> <code>False</code> Example <p>from themap.data import MoleculeDataset from themap.data.torch_dataset import TorchMoleculeDataset</p>"},{"location":"api/data.html#themap.data.TorchMoleculeDataset--load-molecular-dataset","title":"Load molecular dataset","text":"<p>mol_dataset = MoleculeDataset.load_from_file(\"data.jsonl.gz\")</p>"},{"location":"api/data.html#themap.data.TorchMoleculeDataset--create-pytorch-wrapper","title":"Create PyTorch wrapper","text":"<p>torch_dataset = TorchMoleculeDataset(mol_dataset)</p>"},{"location":"api/data.html#themap.data.TorchMoleculeDataset--use-as-pytorch-dataset","title":"Use as PyTorch Dataset","text":"<p>dataloader = torch.utils.data.DataLoader(torch_dataset, batch_size=32)</p>"},{"location":"api/data.html#themap.data.TorchMoleculeDataset--access-original-methods-through-delegation","title":"Access original methods through delegation","text":"<p>stats = torch_dataset.get_statistics() features = torch_dataset.get_features(\"ecfp\")</p>"},{"location":"api/data.html#themap.data.TorchMoleculeDataset.dataset","title":"dataset  <code>property</code>","text":"<pre><code>dataset: MoleculeDataset\n</code></pre> <p>Access to the underlying MoleculeDataset.</p> <p>Returns:</p> Name Type Description <code>MoleculeDataset</code> <code>MoleculeDataset</code> <p>The wrapped dataset</p>"},{"location":"api/data.html#themap.data.TorchMoleculeDataset.__init__","title":"__init__","text":"<pre><code>__init__(\n    data: MoleculeDataset,\n    transform: Optional[Callable] = None,\n    target_transform: Optional[Callable] = None,\n    lazy_loading: bool = False,\n) -&gt; None\n</code></pre> <p>Initialize TorchMoleculeDataset.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>MoleculeDataset</code> <p>Input molecular dataset</p> required <code>transform</code> <code>callable</code> <p>Transform to apply to features</p> <code>None</code> <code>target_transform</code> <code>callable</code> <p>Transform to apply to labels</p> <code>None</code> <code>lazy_loading</code> <code>bool</code> <p>Whether to load tensors lazily</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the dataset is empty or features/labels are invalid</p> <code>TypeError</code> <p>If data is not a MoleculeDataset instance</p>"},{"location":"api/data.html#themap.data.TorchMoleculeDataset.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(index: int) -&gt; tuple[torch.Tensor, torch.Tensor]\n</code></pre> <p>Get a data sample.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Index of the sample to get</p> required <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor]</code> <p>tuple[torch.Tensor, torch.Tensor]: Tuple of (features, label)</p> <p>Raises:</p> Type Description <code>IndexError</code> <p>If index is out of bounds</p> <code>RuntimeError</code> <p>If lazy loading fails</p>"},{"location":"api/data.html#themap.data.TorchMoleculeDataset.__len__","title":"__len__","text":"<pre><code>__len__() -&gt; int\n</code></pre> <p>Get the number of samples in the dataset.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of samples</p>"},{"location":"api/data.html#themap.data.TorchMoleculeDataset.__repr__","title":"__repr__","text":"<pre><code>__repr__() -&gt; str\n</code></pre> <p>String representation of the dataset.</p>"},{"location":"api/data.html#themap.data.TorchMoleculeDataset.__getattr__","title":"__getattr__","text":"<pre><code>__getattr__(name: str) -&gt; Any\n</code></pre> <p>Delegate attribute access to underlying MoleculeDataset.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Attribute name</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The attribute from the underlying dataset</p> <p>Raises:</p> Type Description <code>AttributeError</code> <p>If attribute doesn't exist in underlying dataset</p>"},{"location":"api/data.html#themap.data.TorchMoleculeDataset.get_smiles","title":"get_smiles","text":"<pre><code>get_smiles() -&gt; list[str]\n</code></pre> <p>Get SMILES strings for all molecules.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: List of SMILES strings</p>"},{"location":"api/data.html#themap.data.TorchMoleculeDataset.refresh_tensors","title":"refresh_tensors","text":"<pre><code>refresh_tensors() -&gt; None\n</code></pre> <p>Refresh cached tensors from the underlying dataset.</p> <p>Useful when the underlying dataset has been modified.</p>"},{"location":"api/data.html#themap.data.TorchMoleculeDataset.create_dataloader","title":"create_dataloader  <code>classmethod</code>","text":"<pre><code>create_dataloader(\n    data: MoleculeDataset,\n    batch_size: int = 64,\n    shuffle: bool = True,\n    transform: Optional[Callable] = None,\n    target_transform: Optional[Callable] = None,\n    lazy_loading: bool = False,\n    **kwargs: Any,\n) -&gt; torch.utils.data.DataLoader\n</code></pre> <p>Create PyTorch DataLoader with enhanced options.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>MoleculeDataset</code> <p>Input molecular dataset</p> required <code>batch_size</code> <code>int</code> <p>Batch size</p> <code>64</code> <code>shuffle</code> <code>bool</code> <p>Whether to shuffle data</p> <code>True</code> <code>transform</code> <code>Optional[Callable]</code> <p>Transform to apply to features</p> <code>None</code> <code>target_transform</code> <code>Optional[Callable]</code> <p>Transform to apply to labels</p> <code>None</code> <code>lazy_loading</code> <code>bool</code> <p>Whether to use lazy loading</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments for DataLoader</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>DataLoader</code> <code>DataLoader</code> <p>PyTorch data loader</p> Example <p>loader = TorchMoleculeDataset.create_dataloader( ...     dataset, ...     batch_size=32, ...     shuffle=True, ...     num_workers=4 ... )</p>"},{"location":"api/data.html#themap.data.TorchProteinMetadataDataset","title":"TorchProteinMetadataDataset","text":"<p>               Bases: <code>Dataset</code></p> <p>Enhanced PyTorch Dataset wrapper for protein data.</p> <p>This class wraps a ProteinMetadataDataset to provide PyTorch Dataset functionality while maintaining access to all original ProteinMetadataDataset methods through delegation.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ProteinMetadataDataset</code> <p>ProteinMetadataDataset object</p> required <code>transform</code> <code>callable</code> <p>Transform to apply to features</p> <code>None</code> <code>target_transform</code> <code>callable</code> <p>Transform to apply to labels</p> <code>None</code> <code>lazy_loading</code> <code>bool</code> <p>Whether to load data lazily. Defaults to False.</p> <code>False</code> <code>sequence_length</code> <code>int</code> <p>Fixed sequence length for padding/truncation</p> <code>None</code> Example <p>from themap.data import ProteinMetadataDataset from themap.data.torch_dataset import TorchProteinMetadataDataset</p>"},{"location":"api/data.html#themap.data.TorchProteinMetadataDataset--create-protein-dataset","title":"Create protein dataset","text":"<p>protein_dataset = ProteinMetadataDataset( ...     task_id=\"CHEMBL123\", ...     uniprot_id=\"P12345\", ...     sequence=\"MKLLVFSLCLLAFSSATAAF\" ... )</p>"},{"location":"api/data.html#themap.data.TorchProteinMetadataDataset--create-pytorch-wrapper","title":"Create PyTorch wrapper","text":"<p>torch_dataset = TorchProteinMetadataDataset(protein_dataset)</p>"},{"location":"api/data.html#themap.data.TorchProteinMetadataDataset--use-as-pytorch-dataset","title":"Use as PyTorch Dataset","text":"<p>dataloader = torch.utils.data.DataLoader(torch_dataset, batch_size=1)</p>"},{"location":"api/data.html#themap.data.TorchProteinMetadataDataset.dataset","title":"dataset  <code>property</code>","text":"<pre><code>dataset: ProteinMetadataDataset\n</code></pre> <p>Access to the underlying ProteinMetadataDataset.</p> <p>Returns:</p> Name Type Description <code>ProteinMetadataDataset</code> <code>ProteinMetadataDataset</code> <p>The wrapped dataset</p>"},{"location":"api/data.html#themap.data.TorchProteinMetadataDataset.__init__","title":"__init__","text":"<pre><code>__init__(\n    data: ProteinMetadataDataset,\n    transform: Optional[Callable] = None,\n    target_transform: Optional[Callable] = None,\n    lazy_loading: bool = False,\n    sequence_length: Optional[int] = None,\n) -&gt; None\n</code></pre> <p>Initialize TorchProteinMetadataDataset.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ProteinMetadataDataset</code> <p>Input protein dataset</p> required <code>transform</code> <code>callable</code> <p>Transform to apply to features</p> <code>None</code> <code>target_transform</code> <code>callable</code> <p>Transform to apply to targets</p> <code>None</code> <code>lazy_loading</code> <code>bool</code> <p>Whether to load tensors lazily</p> <code>False</code> <code>sequence_length</code> <code>int</code> <p>Fixed sequence length for padding/truncation</p> <code>None</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If data is not a ProteinMetadataDataset instance</p> <code>ValueError</code> <p>If the dataset is invalid</p>"},{"location":"api/data.html#themap.data.TorchProteinMetadataDataset.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(index: int) -&gt; tuple[torch.Tensor, torch.Tensor]\n</code></pre> <p>Get a protein data sample.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Index of the sample to get (should be 0 for single protein)</p> required <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor]</code> <p>tuple[torch.Tensor, torch.Tensor]: Tuple of (features, label)</p> <p>Raises:</p> Type Description <code>IndexError</code> <p>If index is out of bounds</p> <code>RuntimeError</code> <p>If lazy loading fails</p>"},{"location":"api/data.html#themap.data.TorchProteinMetadataDataset.__len__","title":"__len__","text":"<pre><code>__len__() -&gt; int\n</code></pre> <p>Get the number of samples in the dataset.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Always 1 for a single protein</p>"},{"location":"api/data.html#themap.data.TorchProteinMetadataDataset.__repr__","title":"__repr__","text":"<pre><code>__repr__() -&gt; str\n</code></pre> <p>String representation of the protein dataset.</p>"},{"location":"api/data.html#themap.data.TorchProteinMetadataDataset.__getattr__","title":"__getattr__","text":"<pre><code>__getattr__(name: str) -&gt; Any\n</code></pre> <p>Delegate attribute access to underlying ProteinMetadataDataset.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Attribute name</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The attribute from the underlying dataset</p> <p>Raises:</p> Type Description <code>AttributeError</code> <p>If attribute doesn't exist in underlying dataset</p>"},{"location":"api/data.html#themap.data.TorchProteinMetadataDataset.refresh_tensors","title":"refresh_tensors","text":"<pre><code>refresh_tensors() -&gt; None\n</code></pre> <p>Refresh cached tensors from the underlying dataset.</p> <p>Useful when the underlying dataset has been modified.</p>"},{"location":"api/data.html#themap.data.TorchProteinMetadataDataset.create_dataloader","title":"create_dataloader  <code>classmethod</code>","text":"<pre><code>create_dataloader(\n    data: ProteinMetadataDataset,\n    batch_size: int = 1,\n    shuffle: bool = False,\n    transform: Optional[Callable] = None,\n    target_transform: Optional[Callable] = None,\n    lazy_loading: bool = False,\n    sequence_length: Optional[int] = None,\n    **kwargs: Any,\n) -&gt; torch.utils.data.DataLoader\n</code></pre> <p>Create PyTorch DataLoader for protein data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ProteinMetadataDataset</code> <p>Input protein dataset</p> required <code>batch_size</code> <code>int</code> <p>Batch size (typically 1 for single proteins)</p> <code>1</code> <code>shuffle</code> <code>bool</code> <p>Whether to shuffle data (typically False for single protein)</p> <code>False</code> <code>transform</code> <code>Optional[Callable]</code> <p>Transform to apply to features</p> <code>None</code> <code>target_transform</code> <code>Optional[Callable]</code> <p>Transform to apply to labels</p> <code>None</code> <code>lazy_loading</code> <code>bool</code> <p>Whether to use lazy loading</p> <code>False</code> <code>sequence_length</code> <code>Optional[int]</code> <p>Fixed sequence length for padding/truncation</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments for DataLoader</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>DataLoader</code> <code>DataLoader</code> <p>PyTorch data loader</p>"},{"location":"api/data.html#themap.data.MoleculeDataloader","title":"MoleculeDataloader","text":"<pre><code>MoleculeDataloader(\n    data: MoleculeDataset,\n    batch_size: int = 64,\n    shuffle: bool = True,\n    transform: Optional[Callable] = None,\n    target_transform: Optional[Callable] = None,\n) -&gt; torch.utils.data.DataLoader\n</code></pre> <p>Load molecular data and create PyTorch dataloader.</p> <p>This function is kept for backward compatibility. Consider using TorchMoleculeDataset.create_dataloader() for new code.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>MoleculeDataset</code> <p>MoleculeDataset object</p> required <code>batch_size</code> <code>int</code> <p>batch size</p> <code>64</code> <code>shuffle</code> <code>bool</code> <p>whether to shuffle data</p> <code>True</code> <code>transform</code> <code>callable</code> <p>transform to apply to data</p> <code>None</code> <code>target_transform</code> <code>callable</code> <p>transform to apply to targets</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dataset_loader</code> <code>DataLoader</code> <p>PyTorch dataloader</p> Example <p>from themap.data.torch_dataset import MoleculeDataloader from themap.data.tasks import Tasks tasks = Tasks.from_directory(     directory=\"datasets/\",     task_list_file=\"datasets/sample_tasks_list.json\",     load_molecules=True,     load_proteins=False,     load_metadata=False,     cache_dir=\"./cache\" ) dataset_loader = MoleculeDataloader(tasks.get_task(\"TASK_ID\").molecule_dataset, batch_size=10, shuffle=True) for batch in dataset_loader:     print(batch)     break</p>"},{"location":"api/data.html#themap.data.ProteinDataloader","title":"ProteinDataloader","text":"<pre><code>ProteinDataloader(\n    data: ProteinMetadataDataset,\n    batch_size: int = 1,\n    shuffle: bool = False,\n    transform: Optional[Callable] = None,\n    target_transform: Optional[Callable] = None,\n    sequence_length: Optional[int] = None,\n) -&gt; torch.utils.data.DataLoader\n</code></pre> <p>Load protein data and create PyTorch dataloader.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ProteinMetadataDataset</code> <p>ProteinMetadataDataset object</p> required <code>batch_size</code> <code>int</code> <p>batch size (typically 1 for proteins)</p> <code>1</code> <code>shuffle</code> <code>bool</code> <p>whether to shuffle data</p> <code>False</code> <code>transform</code> <code>callable</code> <p>transform to apply to data</p> <code>None</code> <code>target_transform</code> <code>callable</code> <p>transform to apply to targets</p> <code>None</code> <code>sequence_length</code> <code>int</code> <p>Fixed sequence length for padding/truncation</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dataset_loader</code> <code>DataLoader</code> <p>PyTorch dataloader</p> Example <p>from themap.data.torch_dataset import ProteinDataloader from themap.data.protein_datasets import ProteinMetadataDataset</p> <p>protein_dataset = ProteinMetadataDataset( ...     task_id=\"CHEMBL123\", ...     uniprot_id=\"P12345\", ...     sequence=\"MKLLVFSLCLLAFSSATAAF\" ... ) dataset_loader = ProteinDataloader(protein_dataset) for batch in dataset_loader:     print(batch)     break</p>"},{"location":"api/distance.html","title":"Distance Computation API","text":"<p>The distance module provides comprehensive functionality for computing distances between molecular datasets, protein datasets, and tasks. This module supports various distance metrics and can handle both single dataset comparisons and batch comparisons across multiple datasets.</p>"},{"location":"api/distance.html#overview","title":"Overview","text":"<p>The distance computation system consists of three main classes:</p> <ul> <li><code>MoleculeDatasetDistance</code> - Computes distances between molecule datasets</li> <li><code>ProteinDatasetDistance</code> - Computes distances between protein datasets</li> <li><code>TaskDistance</code> - Unified interface for computing combined task distances</li> </ul>"},{"location":"api/distance.html#core-classes","title":"Core Classes","text":""},{"location":"api/distance.html#abstracttasksdistance","title":"AbstractTasksDistance","text":""},{"location":"api/distance.html#themap.distance.base.AbstractTasksDistance","title":"themap.distance.base.AbstractTasksDistance","text":"<p>Base class for computing distances between tasks.</p> <p>This abstract class defines the interface for task distance computation. It distinguishes between: - Dataset distances: Between sets of molecules (OTDD, set-based Euclidean/Cosine) - Metadata distances: Between single vectors per task (vector-based Euclidean/Cosine)</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>Optional[Tasks]</code> <p>Tasks collection for distance computation</p> <code>None</code> <code>dataset_method</code> <code>str</code> <p>Distance computation method for datasets (molecules) (default: \"euclidean\")</p> <code>'euclidean'</code> <code>metadata_method</code> <code>str</code> <p>Distance computation method for metadata including protein (default: \"euclidean\")</p> <code>'euclidean'</code> <code>molecule_method</code> <code>Optional[str]</code> <p>Deprecated alias for dataset_method</p> <code>None</code> <code>protein_method</code> <code>Optional[str]</code> <p>Deprecated - protein is metadata, use metadata_method</p> <code>None</code> <code>method</code> <code>Optional[str]</code> <p>Global method (for backward compatibility, overrides individual methods if provided)</p> <code>None</code>"},{"location":"api/distance.html#themap.distance.base.AbstractTasksDistance.get_num_tasks","title":"get_num_tasks","text":"<pre><code>get_num_tasks() -&gt; Tuple[int, int]\n</code></pre> <p>Get the number of source and target tasks.</p>"},{"location":"api/distance.html#themap.distance.base.AbstractTasksDistance.get_distance","title":"get_distance","text":"<pre><code>get_distance() -&gt; Dict[str, Dict[str, float]]\n</code></pre> <p>Compute the distance between datasets.</p> <p>Each of the subclasses should implement this method.</p> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, float]]</code> <p>Dictionary containing distance matrix between source and target datasets.</p> <code>Dict[str, Dict[str, float]]</code> <p>The outer dictionary is keyed by target task IDs, and the inner dictionary</p> <code>Dict[str, Dict[str, float]]</code> <p>is keyed by source task IDs with distance values.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If not implemented by subclass</p>"},{"location":"api/distance.html#themap.distance.base.AbstractTasksDistance.get_hopts","title":"get_hopts","text":"<pre><code>get_hopts(data_type: str = 'dataset') -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Get hyperparameters for distance computation.</p> <p>Each of the subclasses should implement this method.</p> <p>Parameters:</p> Name Type Description Default <code>data_type</code> <code>str</code> <p>Type of data (\"dataset\", \"metadata\")       Legacy: \"molecule\" (alias for \"dataset\"), \"protein\" (alias for \"metadata\")</p> <code>'dataset'</code> <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>Dictionary containing hyperparameters for the distance computation method</p> <code>Optional[Dict[str, Any]]</code> <p>or None if no hyperparameters are needed.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If not implemented by subclass</p>"},{"location":"api/distance.html#themap.distance.base.AbstractTasksDistance.get_supported_methods","title":"get_supported_methods","text":"<pre><code>get_supported_methods(data_type: str) -&gt; List[str]\n</code></pre> <p>Get list of supported methods for a specific data type.</p> <p>Parameters:</p> Name Type Description Default <code>data_type</code> <code>str</code> <p>Type of data (\"dataset\", \"metadata\")       Legacy: \"molecule\" (alias for \"dataset\"), \"protein\" (alias for \"metadata\")</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of supported method names for the data type</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If not implemented by subclass</p>"},{"location":"api/distance.html#themap.distance.base.AbstractTasksDistance.__call__","title":"__call__","text":"<pre><code>__call__(*args: Any, **kwds: Any) -&gt; Dict[str, Dict[str, float]]\n</code></pre> <p>Allow the class to be called as a function.</p> <p>Each of the subclasses should implement this method.</p> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, float]]</code> <p>The computed distance matrix.</p>"},{"location":"api/distance.html#moleculedatasetdistance","title":"MoleculeDatasetDistance","text":""},{"location":"api/distance.html#themap.distance.molecule_distance.MoleculeDatasetDistance","title":"themap.distance.molecule_distance.MoleculeDatasetDistance","text":"<p>               Bases: <code>AbstractTasksDistance</code></p> <p>Calculate distances between molecule datasets using various methods.</p> <p>This class implements distance computation between molecule datasets using: - Optimal Transport Dataset Distance (OTDD) - Euclidean distance - Cosine distance</p> <p>The class supports both single dataset comparisons and batch comparisons across multiple datasets.</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>Optional[Tasks]</code> <p>Tasks collection containing molecule datasets for distance computation</p> <code>None</code> <code>method</code> <code>Optional[str]</code> <p>Distance computation method ('otdd', 'euclidean', or 'cosine')</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments passed to the distance computation method</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the specified method is not supported for molecule datasets</p>"},{"location":"api/distance.html#themap.distance.molecule_distance.MoleculeDatasetDistance.get_hopts","title":"get_hopts","text":"<pre><code>get_hopts(data_type: str = 'molecule') -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Get hyperparameters for the distance computation method.</p> <p>Parameters:</p> Name Type Description Default <code>data_type</code> <code>str</code> <p>Type of data (\"molecule\", \"protein\", \"metadata\")</p> <code>'molecule'</code> <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>Dictionary of hyperparameters specific to the chosen distance method for the data type.</p>"},{"location":"api/distance.html#themap.distance.molecule_distance.MoleculeDatasetDistance.get_supported_methods","title":"get_supported_methods","text":"<pre><code>get_supported_methods(data_type: str) -&gt; List[str]\n</code></pre> <p>Get list of supported methods for a specific data type.</p> <p>Parameters:</p> Name Type Description Default <code>data_type</code> <code>str</code> <p>Type of data (\"molecule\", \"protein\", \"metadata\")</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of supported method names for the data type</p>"},{"location":"api/distance.html#themap.distance.molecule_distance.MoleculeDatasetDistance.otdd_distance","title":"otdd_distance","text":"<pre><code>otdd_distance() -&gt; Dict[str, Dict[str, float]]\n</code></pre> <p>Compute Optimal Transport Dataset Distance between molecule datasets.</p> <p>This method uses the OTDD implementation to compute distances between molecule datasets, which takes into account both the feature space and label space of the datasets.</p> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, float]]</code> <p>Dictionary containing OTDD distances between source and target datasets.</p> <code>Dict[str, Dict[str, float]]</code> <p>The outer dictionary is keyed by target task IDs, and the inner dictionary</p> <code>Dict[str, Dict[str, float]]</code> <p>is keyed by source task IDs with distance values.</p>"},{"location":"api/distance.html#themap.distance.molecule_distance.MoleculeDatasetDistance.euclidean_distance","title":"euclidean_distance","text":"<pre><code>euclidean_distance(\n    featurizer_name: str = \"ecfp\",\n) -&gt; Dict[str, Dict[str, float]]\n</code></pre> <p>Compute Euclidean distance between molecule datasets.</p> <p>This method computes the dataset-level Euclidean distance by comparing the prototypes of the datasets.</p> <p>Parameters:</p> Name Type Description Default <code>featurizer_name</code> <code>str</code> <p>Name of the molecular featurizer to use (e.g., \"ecfp\", \"maccs\", \"desc2D\")</p> <code>'ecfp'</code> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, float]]</code> <p>Dictionary containing Euclidean distances between source and target datasets.</p> <code>Dict[str, Dict[str, float]]</code> <p>The outer dictionary is keyed by target task IDs, and the inner dictionary</p> <code>Dict[str, Dict[str, float]]</code> <p>is keyed by source task IDs with distance values.</p> <p>Raises:</p> Type Description <code>DistanceComputationError</code> <p>If feature computation fails</p>"},{"location":"api/distance.html#themap.distance.molecule_distance.MoleculeDatasetDistance.cosine_distance","title":"cosine_distance","text":"<pre><code>cosine_distance(featurizer_name: str = 'ecfp') -&gt; Dict[str, Dict[str, float]]\n</code></pre> <p>Compute cosine distance between molecule datasets.</p> <p>This method computes the dataset-level cosine distance by comparing the prototypes of the datasets.</p> <p>Parameters:</p> Name Type Description Default <code>featurizer_name</code> <code>str</code> <p>Name of the molecular featurizer to use (e.g., \"ecfp\", \"maccs\", \"desc2D\")</p> <code>'ecfp'</code> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, float]]</code> <p>Dictionary containing cosine distances between source and target datasets.</p> <code>Dict[str, Dict[str, float]]</code> <p>The outer dictionary is keyed by target task IDs, and the inner dictionary</p> <code>Dict[str, Dict[str, float]]</code> <p>is keyed by source task IDs with distance values.</p>"},{"location":"api/distance.html#themap.distance.molecule_distance.MoleculeDatasetDistance.get_distance","title":"get_distance","text":"<pre><code>get_distance(featurizer_name: str = 'ecfp') -&gt; Dict[str, Dict[str, float]]\n</code></pre> <p>Compute the distance between molecule datasets using the specified method.</p> <p>Parameters:</p> Name Type Description Default <code>featurizer_name</code> <code>str</code> <p>Name of the molecular featurizer to use (e.g., \"ecfp\", \"maccs\", \"desc2D\")</p> <code>'ecfp'</code> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, float]]</code> <p>Dictionary containing distance matrix between source and target datasets.</p> <code>Dict[str, Dict[str, float]]</code> <p>The outer dictionary is keyed by target task IDs, and the inner dictionary</p> <code>Dict[str, Dict[str, float]]</code> <p>is keyed by source task IDs with distance values.</p>"},{"location":"api/distance.html#themap.distance.molecule_distance.MoleculeDatasetDistance.load_distance","title":"load_distance","text":"<pre><code>load_distance(path: str) -&gt; None\n</code></pre> <p>Load pre-computed distances from a file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the file containing pre-computed distances</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file doesn't exist</p> <code>ValueError</code> <p>If the file format is invalid</p>"},{"location":"api/distance.html#themap.distance.molecule_distance.MoleculeDatasetDistance.to_pandas","title":"to_pandas","text":"<pre><code>to_pandas() -&gt; pd.DataFrame\n</code></pre> <p>Convert the distance matrix to a pandas DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with source task IDs as index and target task IDs as columns,</p> <code>DataFrame</code> <p>containing the distance values.</p>"},{"location":"api/distance.html#themap.distance.molecule_distance.MoleculeDatasetDistance.__repr__","title":"__repr__","text":"<pre><code>__repr__() -&gt; str\n</code></pre> <p>Return a string representation of the MoleculeDatasetDistance instance.</p> <p>Returns:</p> Type Description <code>str</code> <p>String containing the class name and initialization parameters.</p>"},{"location":"api/distance.html#proteindatasetdistance","title":"ProteinDatasetDistance","text":""},{"location":"api/distance.html#themap.distance.protein_distance.ProteinDatasetDistance","title":"themap.distance.protein_distance.ProteinDatasetDistance","text":"<p>               Bases: <code>AbstractTasksDistance</code></p> <p>Calculate distances between protein datasets using various methods.</p> <p>This class implements distance computation between protein datasets using: - Euclidean distance - Cosine distance</p> <p>The class supports both single dataset comparisons and batch comparisons across multiple datasets.</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>Optional[Tasks]</code> <p>Tasks collection containing protein datasets for distance computation</p> <code>None</code> <code>method</code> <code>Optional[str]</code> <p>Distance computation method ('euclidean' or 'cosine')</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the specified method is not supported for protein datasets</p>"},{"location":"api/distance.html#themap.distance.protein_distance.ProteinDatasetDistance.get_hopts","title":"get_hopts","text":"<pre><code>get_hopts(data_type: str = 'protein') -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Get hyperparameters for the distance computation method.</p> <p>Parameters:</p> Name Type Description Default <code>data_type</code> <code>str</code> <p>Type of data (\"molecule\", \"protein\", \"metadata\")</p> <code>'protein'</code> <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>Dictionary of hyperparameters specific to the chosen distance method for the data type.</p>"},{"location":"api/distance.html#themap.distance.protein_distance.ProteinDatasetDistance.get_supported_methods","title":"get_supported_methods","text":"<pre><code>get_supported_methods(data_type: str) -&gt; List[str]\n</code></pre> <p>Get list of supported methods for a specific data type.</p> <p>Parameters:</p> Name Type Description Default <code>data_type</code> <code>str</code> <p>Type of data (\"molecule\", \"protein\", \"metadata\")</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of supported method names for the data type</p>"},{"location":"api/distance.html#themap.distance.protein_distance.ProteinDatasetDistance.euclidean_distance","title":"euclidean_distance","text":"<pre><code>euclidean_distance() -&gt; Dict[str, Dict[str, float]]\n</code></pre> <p>Compute Euclidean distance between protein datasets.</p> <p>This method calculates the pairwise Euclidean distances between protein feature vectors in the datasets.</p> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, float]]</code> <p>Dictionary containing Euclidean distances between source and target datasets.</p> <code>Dict[str, Dict[str, float]]</code> <p>The outer dictionary is keyed by target task IDs, and the inner dictionary</p> <code>Dict[str, Dict[str, float]]</code> <p>is keyed by source task IDs with distance values.</p>"},{"location":"api/distance.html#themap.distance.protein_distance.ProteinDatasetDistance.cosine_distance","title":"cosine_distance","text":"<pre><code>cosine_distance() -&gt; Dict[str, Dict[str, float]]\n</code></pre> <p>Compute cosine distance between protein datasets.</p> <p>This method calculates the pairwise cosine distances between protein feature vectors in the datasets.</p> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, float]]</code> <p>Dictionary containing cosine distances between source and target datasets.</p> <code>Dict[str, Dict[str, float]]</code> <p>The outer dictionary is keyed by target task IDs, and the inner dictionary</p> <code>Dict[str, Dict[str, float]]</code> <p>is keyed by source task IDs with distance values.</p>"},{"location":"api/distance.html#themap.distance.protein_distance.ProteinDatasetDistance.sequence_identity_distance","title":"sequence_identity_distance","text":"<pre><code>sequence_identity_distance() -&gt; Dict[str, Dict[str, float]]\n</code></pre> <p>Compute sequence identity-based distance between protein datasets.</p> <p>This method calculates distances based on protein sequence identity.</p> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, float]]</code> <p>Dictionary containing sequence identity-based distances between datasets.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This method is not yet implemented</p>"},{"location":"api/distance.html#themap.distance.protein_distance.ProteinDatasetDistance.get_distance","title":"get_distance","text":"<pre><code>get_distance() -&gt; Dict[str, Dict[str, float]]\n</code></pre> <p>Compute the distance between protein datasets using the specified method.</p> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, float]]</code> <p>Dictionary containing distance matrix between source and target datasets.</p> <code>Dict[str, Dict[str, float]]</code> <p>The outer dictionary is keyed by target task IDs, and the inner dictionary</p> <code>Dict[str, Dict[str, float]]</code> <p>is keyed by source task IDs with distance values.</p>"},{"location":"api/distance.html#themap.distance.protein_distance.ProteinDatasetDistance.load_distance","title":"load_distance","text":"<pre><code>load_distance(path: str) -&gt; None\n</code></pre> <p>Load pre-computed distances from a file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the file containing pre-computed distances</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file doesn't exist</p> <code>ValueError</code> <p>If the file format is invalid</p>"},{"location":"api/distance.html#themap.distance.protein_distance.ProteinDatasetDistance.to_pandas","title":"to_pandas","text":"<pre><code>to_pandas() -&gt; pd.DataFrame\n</code></pre> <p>Convert the distance matrix to a pandas DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with source task IDs as index and target task IDs as columns,</p> <code>DataFrame</code> <p>containing the distance values.</p>"},{"location":"api/distance.html#themap.distance.protein_distance.ProteinDatasetDistance.__repr__","title":"__repr__","text":"<pre><code>__repr__() -&gt; str\n</code></pre> <p>Return a string representation of the ProteinDatasetDistance instance.</p> <p>Returns:</p> Type Description <code>str</code> <p>String containing the class name and initialization parameters.</p>"},{"location":"api/distance.html#taskdistance","title":"TaskDistance","text":""},{"location":"api/distance.html#themap.distance.task_distance.TaskDistance","title":"themap.distance.task_distance.TaskDistance","text":"<p>               Bases: <code>AbstractTasksDistance</code></p> <p>Class for computing and managing distances between tasks.</p> <p>This class handles the computation and storage of distances between tasks, supporting both dataset distances (molecules) and metadata distances (protein, etc.). It can compute distances directly from Tasks collections or work with pre-computed matrices.</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>Optional[Tasks]</code> <p>Tasks collection for distance computation (optional)</p> <code>None</code> <code>molecule_method</code> <code>str</code> <p>Distance method for molecules (default: \"euclidean\")</p> <code>'euclidean'</code> <code>protein_method</code> <code>str</code> <p>Distance method for proteins (default: \"euclidean\") </p> <code>'euclidean'</code> <code>metadata_method</code> <code>str</code> <p>Distance method for metadata (default: \"euclidean\")</p> <code>'euclidean'</code> <code>method</code> <code>Optional[str]</code> <p>Default distance computation method (legacy, optional)</p> <code>None</code> <code>source_task_ids</code> <code>Optional[List[str]]</code> <p>List of task IDs for source tasks (legacy, optional)</p> <code>None</code> <code>target_task_ids</code> <code>Optional[List[str]]</code> <p>List of task IDs for target tasks (legacy, optional)</p> <code>None</code> <code>external_chemical_space</code> <code>Optional[ndarray]</code> <p>Pre-computed chemical space distance matrix (optional)</p> <code>None</code> <code>external_protein_space</code> <code>Optional[ndarray]</code> <p>Pre-computed protein space distance matrix (optional)</p> <code>None</code>"},{"location":"api/distance.html#themap.distance.task_distance.TaskDistance.shape","title":"shape  <code>property</code>","text":"<pre><code>shape: Tuple[int, int]\n</code></pre> <p>Get the shape of the distance matrix.</p> <p>Returns:</p> Type Description <code>Tuple[int, int]</code> <p>Tuple containing (number of source tasks, number of target tasks).</p>"},{"location":"api/distance.html#themap.distance.task_distance.TaskDistance.get_distance","title":"get_distance","text":"<pre><code>get_distance() -&gt; Dict[str, Dict[str, float]]\n</code></pre> <p>Compute and return the default distance between tasks.</p> <p>Uses the combined distance if both molecule and protein data are available, otherwise uses molecule distance, then protein distance as fallback.</p> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, float]]</code> <p>Dictionary containing distance matrix between source and target tasks.</p>"},{"location":"api/distance.html#themap.distance.task_distance.TaskDistance.get_hopts","title":"get_hopts","text":"<pre><code>get_hopts(data_type: str = 'dataset') -&gt; Optional[Dict[str, Any]]\n</code></pre> <p>Get hyperparameters for distance computation.</p> <p>Parameters:</p> Name Type Description Default <code>data_type</code> <code>str</code> <p>Type of data (\"dataset\", \"metadata\")       Legacy: \"molecule\" (alias for \"dataset\"), \"protein\" (alias for \"metadata\")</p> <code>'dataset'</code> <p>Returns:</p> Type Description <code>Optional[Dict[str, Any]]</code> <p>Dictionary of hyperparameters for the specified data type distance computation method.</p>"},{"location":"api/distance.html#themap.distance.task_distance.TaskDistance.get_supported_methods","title":"get_supported_methods","text":"<pre><code>get_supported_methods(data_type: str) -&gt; List[str]\n</code></pre> <p>Get list of supported methods for a specific data type.</p> <p>Parameters:</p> Name Type Description Default <code>data_type</code> <code>str</code> <p>Type of data (\"dataset\", \"metadata\")       Legacy: \"molecule\" (alias for \"dataset\"), \"protein\" (alias for \"metadata\")</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of supported method names for the data type</p>"},{"location":"api/distance.html#themap.distance.task_distance.TaskDistance.__repr__","title":"__repr__","text":"<pre><code>__repr__() -&gt; str\n</code></pre> <p>Return a string representation of the TaskDistance instance.</p> <p>Returns:</p> Type Description <code>str</code> <p>String containing the number of source and target tasks and the mode.</p>"},{"location":"api/distance.html#themap.distance.task_distance.TaskDistance.compute_molecule_distance","title":"compute_molecule_distance","text":"<pre><code>compute_molecule_distance(\n    method: Optional[str] = None, molecule_featurizer: str = \"ecfp\"\n) -&gt; Dict[str, Dict[str, float]]\n</code></pre> <p>Compute distances between tasks using molecule data.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>Optional[str]</code> <p>Distance computation method ('euclidean', 'cosine', or 'otdd').    If None, uses the molecule_method from initialization.</p> <code>None</code> <code>molecule_featurizer</code> <code>str</code> <p>Molecular featurizer to use</p> <code>'ecfp'</code> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, float]]</code> <p>Dictionary containing molecule-based distances between tasks.</p>"},{"location":"api/distance.html#themap.distance.task_distance.TaskDistance.compute_protein_distance","title":"compute_protein_distance","text":"<pre><code>compute_protein_distance(\n    method: Optional[str] = None,\n    protein_featurizer: str = \"esm2_t33_650M_UR50D\",\n) -&gt; Dict[str, Dict[str, float]]\n</code></pre> <p>Compute distances between tasks using protein data.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>Optional[str]</code> <p>Distance computation method ('euclidean' or 'cosine').    If None, uses the protein_method from initialization.</p> <code>None</code> <code>protein_featurizer</code> <code>str</code> <p>Protein featurizer to use</p> <code>'esm2_t33_650M_UR50D'</code> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, float]]</code> <p>Dictionary containing protein-based distances between tasks.</p>"},{"location":"api/distance.html#themap.distance.task_distance.TaskDistance.compute_combined_distance","title":"compute_combined_distance","text":"<pre><code>compute_combined_distance(\n    molecule_method: Optional[str] = None,\n    protein_method: Optional[str] = None,\n    combination_strategy: str = \"average\",\n    molecule_weight: float = 0.5,\n    protein_weight: float = 0.5,\n    molecule_featurizer: str = \"ecfp\",\n    protein_featurizer: str = \"esm2_t33_650M_UR50D\",\n) -&gt; Dict[str, Dict[str, float]]\n</code></pre> <p>Compute combined distances using both molecule and protein data.</p> <p>Parameters:</p> Name Type Description Default <code>molecule_method</code> <code>Optional[str]</code> <p>Method for molecule distance computation</p> <code>None</code> <code>protein_method</code> <code>Optional[str]</code> <p>Method for protein distance computation</p> <code>None</code> <code>combination_strategy</code> <code>str</code> <p>How to combine distances ('average', 'weighted_average', 'min', 'max')</p> <code>'average'</code> <code>molecule_weight</code> <code>float</code> <p>Weight for molecule distances (used with 'weighted_average')</p> <code>0.5</code> <code>protein_weight</code> <code>float</code> <p>Weight for protein distances (used with 'weighted_average')</p> <code>0.5</code> <code>molecule_featurizer</code> <code>str</code> <p>Molecular featurizer to use</p> <code>'ecfp'</code> <code>protein_featurizer</code> <code>str</code> <p>Protein featurizer to use</p> <code>'esm2_t33_650M_UR50D'</code> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, float]]</code> <p>Dictionary containing combined distances between tasks.</p>"},{"location":"api/distance.html#themap.distance.task_distance.TaskDistance.compute_all_distances","title":"compute_all_distances","text":"<pre><code>compute_all_distances(\n    molecule_method: Optional[str] = None,\n    protein_method: Optional[str] = None,\n    combination_strategy: str = \"average\",\n    molecule_weight: float = 0.5,\n    protein_weight: float = 0.5,\n    molecule_featurizer: str = \"ecfp\",\n    protein_featurizer: str = \"esm2_t33_650M_UR50D\",\n) -&gt; Dict[str, Dict[str, Dict[str, float]]]\n</code></pre> <p>Compute all distance types (molecule, protein, and combined).</p> <p>Parameters:</p> Name Type Description Default <code>molecule_method</code> <code>Optional[str]</code> <p>Method for molecule distance computation</p> <code>None</code> <code>protein_method</code> <code>Optional[str]</code> <p>Method for protein distance computation</p> <code>None</code> <code>combination_strategy</code> <code>str</code> <p>How to combine distances</p> <code>'average'</code> <code>molecule_weight</code> <code>float</code> <p>Weight for molecule distances</p> <code>0.5</code> <code>protein_weight</code> <code>float</code> <p>Weight for protein distances</p> <code>0.5</code> <code>molecule_featurizer</code> <code>str</code> <p>Molecular featurizer to use</p> <code>'ecfp'</code> <code>protein_featurizer</code> <code>str</code> <p>Protein featurizer to use</p> <code>'esm2_t33_650M_UR50D'</code> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, Dict[str, float]]]</code> <p>Dictionary with keys 'molecule', 'protein', 'combined' containing respective distance matrices.</p>"},{"location":"api/distance.html#themap.distance.task_distance.TaskDistance.compute_ext_chem_distance","title":"compute_ext_chem_distance","text":"<pre><code>compute_ext_chem_distance(method: str) -&gt; Dict[str, Dict[str, float]]\n</code></pre> <p>Compute chemical space distances between tasks using external matrices.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>Distance computation method to use</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, float]]</code> <p>Dictionary containing chemical space distances between tasks.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If external chemical space is not provided</p>"},{"location":"api/distance.html#themap.distance.task_distance.TaskDistance.compute_ext_prot_distance","title":"compute_ext_prot_distance","text":"<pre><code>compute_ext_prot_distance(method: str) -&gt; Dict[str, Dict[str, float]]\n</code></pre> <p>Compute protein space distances between tasks using external matrices.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>Distance computation method to use</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, float]]</code> <p>Dictionary containing protein space distances between tasks.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If external protein space is not provided</p>"},{"location":"api/distance.html#themap.distance.task_distance.TaskDistance.load_ext_chem_distance","title":"load_ext_chem_distance  <code>staticmethod</code>","text":"<pre><code>load_ext_chem_distance(path: str) -&gt; TaskDistance\n</code></pre> <p>Load pre-computed chemical space distances from a file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the file containing pre-computed chemical space distances</p> required <p>Returns:</p> Type Description <code>TaskDistance</code> <p>TaskDistance instance initialized with the loaded distances.</p> Note <p>The file should contain a dictionary with keys: - 'train_chembl_ids' or 'train_pubchem_ids' or 'source_task_ids' - 'test_chembl_ids' or 'test_pubchem_ids' or 'target_task_ids' - 'distance_matrices'</p>"},{"location":"api/distance.html#themap.distance.task_distance.TaskDistance.load_ext_prot_distance","title":"load_ext_prot_distance  <code>staticmethod</code>","text":"<pre><code>load_ext_prot_distance(path: str) -&gt; TaskDistance\n</code></pre> <p>Load pre-computed protein space distances from a file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the file containing pre-computed protein space distances</p> required <p>Returns:</p> Type Description <code>TaskDistance</code> <p>TaskDistance instance initialized with the loaded distances.</p> Note <p>The file should contain a dictionary with keys: - 'train_chembl_ids' or 'train_pubchem_ids' or 'source_task_ids' - 'test_chembl_ids' or 'test_pubchem_ids' or 'target_task_ids' - 'distance_matrices'</p>"},{"location":"api/distance.html#themap.distance.task_distance.TaskDistance.get_computed_distance","title":"get_computed_distance","text":"<pre><code>get_computed_distance(\n    distance_type: str = \"combined\",\n) -&gt; Optional[Dict[str, Dict[str, float]]]\n</code></pre> <p>Get computed distances of the specified type.</p> <p>Parameters:</p> Name Type Description Default <code>distance_type</code> <code>str</code> <p>Type of distance to return ('molecule', 'protein', 'combined')</p> <code>'combined'</code> <p>Returns:</p> Type Description <code>Optional[Dict[str, Dict[str, float]]]</code> <p>Dictionary containing the requested distances, or None if not computed.</p>"},{"location":"api/distance.html#themap.distance.task_distance.TaskDistance.to_pandas","title":"to_pandas","text":"<pre><code>to_pandas(distance_type: str = 'combined') -&gt; pd.DataFrame\n</code></pre> <p>Convert distance matrix to a pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>distance_type</code> <code>str</code> <p>Type of distance to convert ('molecule', 'protein', 'combined', 'external_chemical')</p> <code>'combined'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with source task IDs as index and target task IDs as columns,</p> <code>DataFrame</code> <p>containing the distance values.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no distances of the specified type are available</p>"},{"location":"api/distance.html#utility-functions","title":"Utility Functions","text":""},{"location":"api/distance.html#validation-functions","title":"Validation Functions","text":""},{"location":"api/distance.html#themap.distance.base._validate_and_extract_task_id","title":"themap.distance.base._validate_and_extract_task_id","text":"<pre><code>_validate_and_extract_task_id(task_name: str) -&gt; str\n</code></pre> <p>Safely extract task ID from task name with validation.</p> <p>Parameters:</p> Name Type Description Default <code>task_name</code> <code>str</code> <p>Task name in format 'fold_task_id'</p> required <p>Returns:</p> Type Description <code>str</code> <p>Extracted task ID</p> <p>Raises:</p> Type Description <code>DataValidationError</code> <p>If task name format is invalid</p>"},{"location":"api/distance.html#exception-classes","title":"Exception Classes","text":""},{"location":"api/distance.html#distancecomputationerror","title":"DistanceComputationError","text":""},{"location":"api/distance.html#themap.distance.exceptions.DistanceComputationError","title":"themap.distance.exceptions.DistanceComputationError","text":"<p>               Bases: <code>Exception</code></p> <p>Custom exception for distance computation errors.</p>"},{"location":"api/distance.html#datavalidationerror","title":"DataValidationError","text":""},{"location":"api/distance.html#themap.distance.exceptions.DataValidationError","title":"themap.distance.exceptions.DataValidationError","text":"<p>               Bases: <code>Exception</code></p> <p>Custom exception for data validation errors.</p>"},{"location":"api/distance.html#constants","title":"Constants","text":""},{"location":"api/distance.html#supported-methods","title":"Supported Methods","text":"<pre><code># Available distance methods for molecule datasets\nMOLECULE_DISTANCE_METHODS = [\"otdd\", \"euclidean\", \"cosine\"]\n\n# Available distance methods for protein datasets\nPROTEIN_DISTANCE_METHODS = [\"euclidean\", \"cosine\"]\n</code></pre>"},{"location":"api/distance.html#usage-examples","title":"Usage Examples","text":""},{"location":"api/distance.html#basic-molecule-distance-computation","title":"Basic Molecule Distance Computation","text":"<pre><code>from themap.data.tasks import Tasks\nfrom themap.distance import MoleculeDatasetDistance\n\n# Load tasks from directory\ntasks = Tasks.from_directory(\n    directory=\"datasets/\",\n    task_list_file=\"datasets/sample_tasks_list.json\",\n    load_molecules=True,\n    load_proteins=False\n)\n\n# Compute molecule distances using OTDD\nmol_distance = MoleculeDatasetDistance(\n    tasks=tasks,\n    molecule_method=\"otdd\"\n)\n\ndistances = mol_distance.get_distance()\nprint(distances)\n# {'target_task': {'source_task': 0.75, ...}}\n</code></pre>"},{"location":"api/distance.html#protein-distance-computation","title":"Protein Distance Computation","text":"<pre><code>from themap.distance import ProteinDatasetDistance\n\n# Compute protein distances using euclidean method\nprot_distance = ProteinDatasetDistance(\n    tasks=tasks,\n    protein_method=\"euclidean\"\n)\n\ndistances = prot_distance.get_distance()\n</code></pre>"},{"location":"api/distance.html#combined-task-distance","title":"Combined Task Distance","text":"<pre><code>from themap.distance import TaskDistance\n\n# Compute combined distances from multiple modalities\ntask_distance = TaskDistance(\n    tasks=tasks,\n    molecule_method=\"cosine\",\n    protein_method=\"euclidean\"\n)\n\n# Compute all distance types\nall_distances = task_distance.compute_all_distances(\n    combination_strategy=\"weighted_average\",\n    molecule_weight=0.7,\n    protein_weight=0.3\n)\n\n# Access specific distance types\nmolecule_distances = all_distances[\"molecule\"]\nprotein_distances = all_distances[\"protein\"]\ncombined_distances = all_distances[\"combined\"]\n</code></pre>"},{"location":"api/distance.html#working-with-external-distance-matrices","title":"Working with External Distance Matrices","text":"<pre><code>import numpy as np\n\n# Load pre-computed distances\ntask_distance = TaskDistance.load_ext_chem_distance(\"path/to/chemical_distances.pkl\")\n\n# Or initialize with external matrices\nexternal_chem = np.random.rand(10, 8)  # 10 source, 8 target tasks\ntask_distance = TaskDistance(\n    tasks=None,\n    source_task_ids=[\"task1\", \"task2\", ...],\n    target_task_ids=[\"test1\", \"test2\", ...],\n    external_chemical_space=external_chem\n)\n\n# Convert to pandas for analysis\ndf = task_distance.to_pandas(\"external_chemical\")\n</code></pre>"},{"location":"api/distance.html#error-handling","title":"Error Handling","text":"<pre><code>from themap.distance import DistanceComputationError, DataValidationError\n\ntry:\n    # This might fail if OTDD dependencies are missing\n    distances = mol_distance.otdd_distance()\nexcept ImportError as e:\n    print(f\"OTDD not available: {e}\")\n    # Fall back to euclidean distance\n    distances = mol_distance.euclidean_distance()\nexcept DistanceComputationError as e:\n    print(f\"Distance computation failed: {e}\")\nexcept DataValidationError as e:\n    print(f\"Data validation failed: {e}\")\n</code></pre>"},{"location":"api/distance.html#performance-considerations","title":"Performance Considerations","text":""},{"location":"api/distance.html#memory-usage","title":"Memory Usage","text":"<ul> <li>OTDD: Most memory-intensive, especially for large datasets</li> <li>Euclidean/Cosine: More memory-efficient, suitable for large-scale computations</li> <li>External matrices: Memory usage depends on matrix size</li> </ul>"},{"location":"api/distance.html#computational-complexity","title":"Computational Complexity","text":"<ul> <li>OTDD: O(n\u00b2m\u00b2) where n,m are dataset sizes</li> <li>Euclidean/Cosine: O(nm) for feature extraction + O(kl) for distance matrix where k,l are number of tasks</li> <li>Combined distances: Sum of individual method complexities</li> </ul>"},{"location":"api/distance.html#optimization-tips","title":"Optimization Tips","text":"<pre><code># 1. Use appropriate max_samples for OTDD\nhopts = {\"maxsamples\": 500}  # Reduce for faster computation\n\n# 2. Cache features for repeated computations\ntasks.save_task_features_to_file(\"cached_features.pkl\")\ncached_features = Tasks.load_task_features_from_file(\"cached_features.pkl\")\n\n# 3. Use appropriate distance method based on data size\nif num_molecules &gt; 10000:\n    method = \"euclidean\"  # Faster for large datasets\nelse:\n    method = \"otdd\"       # More accurate for smaller datasets\n</code></pre>"},{"location":"api/distance.html#configuration","title":"Configuration","text":""},{"location":"api/distance.html#distance-method-configuration","title":"Distance Method Configuration","text":"<p>Configuration files for distance methods are stored in <code>themap/models/distance_configures/</code>:</p> <pre><code>// otdd.json\n{\n    \"method\": \"otdd\",\n    \"maxsamples\": 1000,\n    \"device\": \"auto\",\n    \"parallel\": true\n}\n</code></pre>"},{"location":"api/distance.html#custom-configuration","title":"Custom Configuration","text":"<pre><code>from themap.utils.distance_utils import get_configure\n\n# Get default configuration\nconfig = get_configure(\"otdd\")\n\n# Modify configuration\nconfig[\"maxsamples\"] = 500\nconfig[\"device\"] = \"cpu\"\n\n# Use in distance computation\nmol_distance = MoleculeDatasetDistance(tasks=tasks, molecule_method=\"otdd\")\n# Configuration is automatically loaded and can be overridden\n</code></pre>"},{"location":"examples/index.html","title":"Examples","text":"<p>This section provides practical, runnable examples for common THEMAP use cases. Each example includes complete code, sample data, and explanations.</p>"},{"location":"examples/index.html#quick-examples","title":"Quick Examples","text":""},{"location":"examples/index.html#1-basic-molecular-distance","title":"1. Basic Molecular Distance","text":"<pre><code>\"\"\"\nCompute distance between two molecular datasets using OTDD.\n\"\"\"\nfrom themap.data import MoleculeDataset\nfrom themap.distance import MoleculeDatasetDistance\nfrom dpu_utils.utils.richpath import RichPath\n\n# Load datasets\nsource = MoleculeDataset.load_from_file(\n    RichPath.create(\"datasets/train/CHEMBL1023359.jsonl.gz\")\n)\ntarget = MoleculeDataset.load_from_file(\n    RichPath.create(\"datasets/test/CHEMBL2219358.jsonl.gz\")\n)\n\n# Compute OTDD distance\ndistance_calc = MoleculeDatasetDistance(\n    tasks=None,\n    molecule_method=\"otdd\"\n)\ndistance_calc.source_molecule_datasets = [source]\ndistance_calc.target_molecule_datasets = [target]\ndistance_calc.source_task_ids = [source.task_id]\ndistance_calc.target_task_ids = [target.task_id]\n\nresult = distance_calc.get_distance()\nprint(f\"OTDD distance: {result}\")\n</code></pre>"},{"location":"examples/index.html#2-protein-similarity-analysis","title":"2. Protein Similarity Analysis","text":"<pre><code>\"\"\"\nAnalyze protein similarity using sequence embeddings.\n\"\"\"\nfrom themap.data import ProteinMetadataDatasets\nfrom themap.distance import ProteinDatasetDistance\n\n# Load protein sequences\nproteins = ProteinMetadataDatasets.from_directory(\"datasets/train/\")\n\n# Compute pairwise distances\nprot_distance = ProteinDatasetDistance(\n    tasks=None,\n    protein_method=\"euclidean\"\n)\n\n# Set up for self-comparison\nprot_distance.source_protein_datasets = proteins\nprot_distance.target_protein_datasets = proteins\n\ndistances = prot_distance.get_distance()\nprint(\"Protein distance matrix:\")\nfor target_id, source_distances in distances.items():\n    print(f\"{target_id}: {source_distances}\")\n</code></pre>"},{"location":"examples/index.html#3-unified-task-system","title":"3. Unified Task System","text":"<pre><code>\"\"\"\nWork with the unified task system for multi-modal analysis.\n\"\"\"\nfrom themap.data.tasks import Tasks\nfrom themap.distance import TaskDistance\n\n# Load integrated tasks\ntasks = Tasks.from_directory(\n    directory=\"datasets/\",\n    task_list_file=\"datasets/sample_tasks_list.json\",\n    load_molecules=True,\n    load_proteins=True,\n    cache_dir=\"cache/\"\n)\n\n# Compute combined distances\ntask_distance = TaskDistance(\n    tasks=tasks,\n    molecule_method=\"cosine\",\n    protein_method=\"euclidean\"\n)\n\n# Get all distance types\nall_distances = task_distance.compute_all_distances(\n    combination_strategy=\"weighted_average\",\n    molecule_weight=0.7,\n    protein_weight=0.3\n)\n\nprint(\"Distance computation complete:\")\nprint(f\"Molecule distances: {len(all_distances['molecule'])} tasks\")\nprint(f\"Protein distances: {len(all_distances['protein'])} tasks\")\nprint(f\"Combined distances: {len(all_distances['combined'])} tasks\")\n</code></pre>"},{"location":"examples/index.html#complete-workflow-examples","title":"Complete Workflow Examples","text":""},{"location":"examples/index.html#transfer-learning-pipeline","title":"Transfer Learning Pipeline","text":"<pre><code>\"\"\"\nComplete transfer learning workflow with task hardness estimation.\n\"\"\"\nimport numpy as np\nimport pandas as pd\nfrom themap.data.tasks import Tasks\nfrom themap.distance import TaskDistance\nfrom themap.hardness import TaskHardness\n\ndef transfer_learning_pipeline(source_tasks_dir, target_tasks_dir):\n    \"\"\"\n    Complete pipeline for transfer learning task selection.\n    \"\"\"\n\n    # 1. Load source and target tasks\n    print(\"\ud83d\udcc2 Loading tasks...\")\n    source_tasks = Tasks.from_directory(\n        directory=source_tasks_dir,\n        load_molecules=True,\n        load_proteins=True\n    )\n\n    target_tasks = Tasks.from_directory(\n        directory=target_tasks_dir,\n        load_molecules=True,\n        load_proteins=True\n    )\n\n    print(f\"Source tasks: {len(source_tasks)}\")\n    print(f\"Target tasks: {len(target_tasks)}\")\n\n    # 2. Compute task distances\n    print(\"\ud83d\udccf Computing task distances...\")\n    task_distance = TaskDistance(\n        tasks=source_tasks + target_tasks,  # Combined for comparison\n        molecule_method=\"cosine\",\n        protein_method=\"euclidean\"\n    )\n\n    distances = task_distance.compute_all_distances()\n\n    # 3. Estimate task hardness\n    print(\"\ud83d\udcaa Estimating task hardness...\")\n    hardness_estimator = TaskHardness(\n        tasks=target_tasks,\n        method=\"combined_distance\"\n    )\n\n    hardness_scores = hardness_estimator.estimate_hardness(distances['combined'])\n\n    # 4. Create transferability matrix\n    print(\"\ud83d\uddfa\ufe0f Creating transferability map...\")\n    transfer_matrix = pd.DataFrame(distances['combined'])\n\n    # 5. Recommend source tasks for each target\n    recommendations = {}\n    for target_task in target_tasks.get_task_ids():\n        if target_task in transfer_matrix.index:\n            # Get closest source tasks\n            source_distances = transfer_matrix.loc[target_task]\n            top_sources = source_distances.nsmallest(3)\n\n            recommendations[target_task] = {\n                'recommended_sources': top_sources.index.tolist(),\n                'distances': top_sources.values.tolist(),\n                'estimated_hardness': hardness_scores.get(target_task, 'N/A')\n            }\n\n    return {\n        'transfer_matrix': transfer_matrix,\n        'hardness_scores': hardness_scores,\n        'recommendations': recommendations,\n        'distances': distances\n    }\n\n# Run pipeline\nif __name__ == \"__main__\":\n    results = transfer_learning_pipeline(\n        source_tasks_dir=\"datasets/train/\",\n        target_tasks_dir=\"datasets/test/\"\n    )\n\n    # Print recommendations\n    print(\"\\n\ud83c\udfaf Transfer Learning Recommendations:\")\n    for target, rec in results['recommendations'].items():\n        print(f\"\\nTarget: {target}\")\n        print(f\"Hardness: {rec['estimated_hardness']:.3f}\")\n        print(\"Best source tasks:\")\n        for source, dist in zip(rec['recommended_sources'], rec['distances']):\n            print(f\"  {source}: distance={dist:.3f}\")\n</code></pre>"},{"location":"examples/index.html#batch-processing-pipeline","title":"Batch Processing Pipeline","text":"<pre><code>\"\"\"\nProcess large numbers of datasets efficiently.\n\"\"\"\nimport os\nfrom pathlib import Path\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nfrom themap.distance import MoleculeDatasetDistance\nfrom themap.data import MoleculeDataset\n\ndef process_single_comparison(source_path, target_path, method=\"euclidean\"):\n    \"\"\"Process a single dataset comparison.\"\"\"\n    try:\n        # Load datasets\n        source = MoleculeDataset.load_from_file(source_path)\n        target = MoleculeDataset.load_from_file(target_path)\n\n        # Compute distance\n        distance_calc = MoleculeDatasetDistance(\n            tasks=None,\n            molecule_method=method\n        )\n        distance_calc.source_molecule_datasets = [source]\n        distance_calc.target_molecule_datasets = [target]\n        distance_calc.source_task_ids = [source.task_id]\n        distance_calc.target_task_ids = [target.task_id]\n\n        result = distance_calc.get_distance()\n\n        return {\n            'source': source.task_id,\n            'target': target.task_id,\n            'distance': list(result.values())[0][source.task_id],\n            'method': method,\n            'status': 'success'\n        }\n\n    except Exception as e:\n        return {\n            'source': Path(source_path).stem,\n            'target': Path(target_path).stem,\n            'distance': None,\n            'method': method,\n            'status': f'error: {str(e)}'\n        }\n\ndef batch_distance_computation(\n    source_dir,\n    target_dir,\n    method=\"euclidean\",\n    max_workers=4,\n    output_file=\"distance_results.csv\"\n):\n    \"\"\"\n    Compute distances between all source-target dataset pairs.\n    \"\"\"\n\n    # Find all dataset files\n    source_files = list(Path(source_dir).glob(\"*.jsonl.gz\"))\n    target_files = list(Path(target_dir).glob(\"*.jsonl.gz\"))\n\n    print(f\"Found {len(source_files)} source and {len(target_files)} target datasets\")\n\n    # Create all combinations\n    comparisons = [\n        (str(source), str(target))\n        for source in source_files\n        for target in target_files\n    ]\n\n    print(f\"Total comparisons: {len(comparisons)}\")\n\n    # Process in parallel\n    results = []\n    completed = 0\n\n    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n        # Submit all jobs\n        future_to_comparison = {\n            executor.submit(process_single_comparison, source, target, method): (source, target)\n            for source, target in comparisons\n        }\n\n        # Collect results\n        for future in as_completed(future_to_comparison):\n            result = future.result()\n            results.append(result)\n            completed += 1\n\n            if completed % 10 == 0:\n                print(f\"Completed: {completed}/{len(comparisons)}\")\n\n    # Save results\n    df_results = pd.DataFrame(results)\n    df_results.to_csv(output_file, index=False)\n\n    print(f\"\\n\u2705 Results saved to {output_file}\")\n    print(f\"Successful computations: {sum(1 for r in results if r['status'] == 'success')}\")\n    print(f\"Failed computations: {sum(1 for r in results if r['status'] != 'success')}\")\n\n    return df_results\n\n# Run batch processing\nif __name__ == \"__main__\":\n    results_df = batch_distance_computation(\n        source_dir=\"datasets/train/\",\n        target_dir=\"datasets/test/\",\n        method=\"euclidean\",\n        max_workers=4\n    )\n\n    # Basic analysis\n    successful_results = results_df[results_df['status'] == 'success']\n    if len(successful_results) &gt; 0:\n        print(f\"\\nDistance statistics:\")\n        print(f\"Mean distance: {successful_results['distance'].mean():.3f}\")\n        print(f\"Std distance: {successful_results['distance'].std():.3f}\")\n        print(f\"Min distance: {successful_results['distance'].min():.3f}\")\n        print(f\"Max distance: {successful_results['distance'].max():.3f}\")\n</code></pre>"},{"location":"examples/index.html#performance-benchmarking","title":"Performance Benchmarking","text":"<pre><code>\"\"\"\nBenchmark different distance methods for performance and accuracy.\n\"\"\"\nimport time\nimport psutil\nimport os\nfrom themap.distance import MoleculeDatasetDistance\nfrom themap.data.tasks import Tasks\n\ndef benchmark_distance_methods(tasks, methods=[\"euclidean\", \"cosine\", \"otdd\"]):\n    \"\"\"\n    Benchmark different distance computation methods.\n    \"\"\"\n\n    def get_memory_usage():\n        \"\"\"Get current memory usage in MB.\"\"\"\n        process = psutil.Process(os.getpid())\n        return process.memory_info().rss / 1024 / 1024\n\n    results = {}\n\n    for method in methods:\n        print(f\"\\n\ud83d\udd0d Benchmarking {method} method...\")\n\n        # Memory before\n        memory_before = get_memory_usage()\n\n        # Time the computation\n        start_time = time.time()\n\n        try:\n            # Create distance calculator\n            distance_calc = MoleculeDatasetDistance(\n                tasks=tasks,\n                molecule_method=method\n            )\n\n            # Compute distances\n            distances = distance_calc.get_distance()\n\n            end_time = time.time()\n            memory_after = get_memory_usage()\n\n            # Calculate metrics\n            computation_time = end_time - start_time\n            memory_usage = memory_after - memory_before\n\n            # Analyze results\n            if distances:\n                all_distances = [\n                    dist for target_dists in distances.values()\n                    for dist in target_dists.values()\n                ]\n                mean_distance = np.mean(all_distances)\n                std_distance = np.std(all_distances)\n            else:\n                mean_distance = None\n                std_distance = None\n\n            results[method] = {\n                'computation_time': computation_time,\n                'memory_usage': memory_usage,\n                'mean_distance': mean_distance,\n                'std_distance': std_distance,\n                'num_comparisons': sum(len(d) for d in distances.values()) if distances else 0,\n                'status': 'success'\n            }\n\n            print(f\"  \u2705 Time: {computation_time:.2f}s\")\n            print(f\"  \ud83d\udcbe Memory: {memory_usage:.1f}MB\")\n            if mean_distance is not None:\n                print(f\"  \ud83d\udcca Mean distance: {mean_distance:.3f}\")\n\n        except Exception as e:\n            end_time = time.time()\n            results[method] = {\n                'computation_time': end_time - start_time,\n                'memory_usage': None,\n                'mean_distance': None,\n                'std_distance': None,\n                'num_comparisons': 0,\n                'status': f'failed: {str(e)}'\n            }\n            print(f\"  \u274c Failed: {str(e)}\")\n\n    return results\n\ndef compare_methods(benchmark_results):\n    \"\"\"\n    Compare benchmark results across methods.\n    \"\"\"\n    print(\"\\n\ud83d\udcca Benchmark Comparison:\")\n    print(\"-\" * 80)\n    print(f\"{'Method':&lt;10} {'Time (s)':&lt;10} {'Memory (MB)':&lt;12} {'Mean Dist':&lt;10} {'Status':&lt;15}\")\n    print(\"-\" * 80)\n\n    for method, results in benchmark_results.items():\n        time_str = f\"{results['computation_time']:.2f}\" if results['computation_time'] else \"N/A\"\n        memory_str = f\"{results['memory_usage']:.1f}\" if results['memory_usage'] else \"N/A\"\n        dist_str = f\"{results['mean_distance']:.3f}\" if results['mean_distance'] else \"N/A\"\n\n        print(f\"{method:&lt;10} {time_str:&lt;10} {memory_str:&lt;12} {dist_str:&lt;10} {results['status']:&lt;15}\")\n\n    # Performance ranking\n    successful_methods = {\n        method: results for method, results in benchmark_results.items()\n        if results['status'] == 'success'\n    }\n\n    if successful_methods:\n        print(f\"\\n\ud83c\udfc6 Rankings:\")\n\n        # Speed ranking\n        speed_ranking = sorted(\n            successful_methods.items(),\n            key=lambda x: x[1]['computation_time']\n        )\n        print(f\"\u26a1 Fastest: {' &gt; '.join([method for method, _ in speed_ranking])}\")\n\n        # Memory ranking\n        memory_ranking = sorted(\n            successful_methods.items(),\n            key=lambda x: x[1]['memory_usage']\n        )\n        print(f\"\ud83d\udcbe Most memory efficient: {' &gt; '.join([method for method, _ in memory_ranking])}\")\n\n# Run benchmark\nif __name__ == \"__main__\":\n    # Load sample tasks\n    tasks = Tasks.from_directory(\n        directory=\"datasets/\",\n        task_list_file=\"datasets/sample_tasks_list.json\",\n        load_molecules=True\n    )\n\n    # Run benchmark\n    results = benchmark_distance_methods(\n        tasks=tasks,\n        methods=[\"euclidean\", \"cosine\", \"otdd\"]\n    )\n\n    # Compare results\n    compare_methods(results)\n</code></pre>"},{"location":"examples/index.html#visualization-examples","title":"Visualization Examples","text":""},{"location":"examples/index.html#distance-matrix-heatmap","title":"Distance Matrix Heatmap","text":"<pre><code>\"\"\"\nCreate publication-ready distance matrix visualizations.\n\"\"\"\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom themap.distance import TaskDistance\n\ndef plot_distance_matrix(distance_dict, title=\"Task Distance Matrix\", figsize=(10, 8)):\n    \"\"\"\n    Create a heatmap visualization of task distances.\n    \"\"\"\n    # Convert to DataFrame\n    df = pd.DataFrame(distance_dict)\n\n    # Create figure\n    plt.figure(figsize=figsize)\n\n    # Create heatmap\n    sns.heatmap(\n        df,\n        annot=True,\n        fmt='.3f',\n        cmap='viridis',\n        cbar_kws={'label': 'Distance'},\n        square=True\n    )\n\n    plt.title(title)\n    plt.xlabel('Source Tasks')\n    plt.ylabel('Target Tasks')\n    plt.xticks(rotation=45)\n    plt.yticks(rotation=0)\n    plt.tight_layout()\n\n    return plt.gcf()\n\ndef plot_distance_comparison(molecule_distances, protein_distances, combined_distances):\n    \"\"\"\n    Compare different distance types in a multi-panel plot.\n    \"\"\"\n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\n    distance_types = [\n        (molecule_distances, \"Molecule Distances\", axes[0]),\n        (protein_distances, \"Protein Distances\", axes[1]),\n        (combined_distances, \"Combined Distances\", axes[2])\n    ]\n\n    for distances, title, ax in distance_types:\n        df = pd.DataFrame(distances)\n\n        sns.heatmap(\n            df,\n            annot=True,\n            fmt='.2f',\n            cmap='viridis',\n            ax=ax,\n            cbar_kws={'label': 'Distance'}\n        )\n\n        ax.set_title(title)\n        ax.set_xlabel('Source Tasks')\n        ax.set_ylabel('Target Tasks')\n\n    plt.tight_layout()\n    return fig\n\n# Example usage\nif __name__ == \"__main__\":\n    # Load tasks and compute distances\n    tasks = Tasks.from_directory(\"datasets/\", load_molecules=True, load_proteins=True)\n\n    task_distance = TaskDistance(tasks=tasks)\n    all_distances = task_distance.compute_all_distances()\n\n    # Create visualizations\n    fig1 = plot_distance_matrix(\n        all_distances['molecule'],\n        title=\"Molecular Dataset Distances\"\n    )\n\n    fig2 = plot_distance_comparison(\n        all_distances['molecule'],\n        all_distances['protein'],\n        all_distances['combined']\n    )\n\n    # Save figures\n    fig1.savefig('molecule_distances.png', dpi=300, bbox_inches='tight')\n    fig2.savefig('distance_comparison.png', dpi=300, bbox_inches='tight')\n\n    plt.show()\n</code></pre>"},{"location":"examples/index.html#script-templates","title":"Script Templates","text":""},{"location":"examples/index.html#command-line-interface","title":"Command-Line Interface","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"\nCommand-line interface for THEMAP distance computation.\n\nUsage:\n    python distance_cli.py --source datasets/train/ --target datasets/test/ --method otdd\n\"\"\"\n\nimport argparse\nimport json\nfrom pathlib import Path\nfrom themap.data.tasks import Tasks\nfrom themap.distance import TaskDistance\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"THEMAP Distance Computation CLI\")\n\n    parser.add_argument(\"--source\", required=True, help=\"Source tasks directory\")\n    parser.add_argument(\"--target\", required=True, help=\"Target tasks directory\")\n    parser.add_argument(\"--method\", default=\"euclidean\",\n                       choices=[\"euclidean\", \"cosine\", \"otdd\"],\n                       help=\"Distance computation method\")\n    parser.add_argument(\"--output\", default=\"distances.json\",\n                       help=\"Output file for distances\")\n    parser.add_argument(\"--cache-dir\", default=\"cache/\",\n                       help=\"Cache directory for features\")\n    parser.add_argument(\"--molecule-featurizer\", default=\"ecfp\",\n                       help=\"Molecular featurizer to use\")\n    parser.add_argument(\"--protein-featurizer\", default=\"esm2_t33_650M_UR50D\",\n                       help=\"Protein featurizer to use\")\n\n    args = parser.parse_args()\n\n    print(f\"\ud83d\udd0d Computing {args.method} distances\")\n    print(f\"\ud83d\udcc2 Source: {args.source}\")\n    print(f\"\ud83c\udfaf Target: {args.target}\")\n\n    # Load tasks\n    source_tasks = Tasks.from_directory(\n        directory=args.source,\n        load_molecules=True,\n        load_proteins=True,\n        cache_dir=args.cache_dir\n    )\n\n    target_tasks = Tasks.from_directory(\n        directory=args.target,\n        load_molecules=True,\n        load_proteins=True,\n        cache_dir=args.cache_dir\n    )\n\n    print(f\"\ud83d\udcca Loaded {len(source_tasks)} source and {len(target_tasks)} target tasks\")\n\n    # Compute distances\n    all_tasks = source_tasks + target_tasks\n    task_distance = TaskDistance(\n        tasks=all_tasks,\n        molecule_method=args.method,\n        protein_method=args.method\n    )\n\n    distances = task_distance.get_distance()\n\n    # Save results\n    output_path = Path(args.output)\n    output_path.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(output_path, 'w') as f:\n        json.dump(distances, f, indent=2)\n\n    print(f\"\ud83d\udcbe Results saved to {output_path}\")\n    print(f\"\u2705 Computed {sum(len(d) for d in distances.values())} pairwise distances\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>These examples provide a solid foundation for working with THEMAP in various scenarios. Each example is self-contained and can be adapted to your specific use case. For more detailed explanations, see our tutorials.</p>"},{"location":"tutorials/index.html","title":"Tutorials","text":"<p>Welcome to the THEMAP tutorials! These step-by-step guides will help you master task hardness estimation and distance computation for molecular activity prediction.</p>"},{"location":"tutorials/index.html#tutorial-overview","title":"Tutorial Overview","text":""},{"location":"tutorials/index.html#beginner-tutorials","title":"\ud83d\ude80 Beginner Tutorials","text":"<ol> <li>Getting Started - Basic installation and first steps</li> </ol>"},{"location":"tutorials/index.html#interactive-notebooks","title":"Interactive Notebooks","text":"<p>All tutorials are available as interactive Jupyter notebooks that you can run locally:</p> <pre><code># Install notebook dependencies\npip install -e \".[dev]\"\n\n# Launch Jupyter Lab\njupyter lab docs/tutorials/\n</code></pre> <pre><code># Download tutorial data (if not included)\nfrom themap.utils import download_tutorial_data\n\ndownload_tutorial_data(\"tutorials/data/\")\n</code></pre>"},{"location":"tutorials/index.html#sample-datasets","title":"Sample Datasets","text":"<ul> <li>ChEMBL Bioactivity Data: 10 training + 3 test tasks</li> <li>Protein Sequences: Target protein sequences for each task</li> <li>Molecular Embeddings: Pre-computed molecular features</li> <li>Metadata: Assay descriptions and experimental conditions</li> </ul>"},{"location":"tutorials/index.html#prerequisites","title":"Prerequisites","text":""},{"location":"tutorials/index.html#python-knowledge","title":"Python Knowledge","text":"<ul> <li>Basic Python programming</li> <li>Familiarity with NumPy and Pandas</li> <li>Optional: Jupyter notebook experience</li> </ul>"},{"location":"tutorials/index.html#domain-knowledge","title":"Domain Knowledge","text":"<ul> <li>Basic understanding of molecular representations (SMILES, etc.)</li> <li>Familiarity with machine learning concepts</li> <li>Optional: Knowledge of protein sequences and drug discovery</li> </ul>"},{"location":"tutorials/index.html#computational-resources","title":"Computational Resources","text":"<p>Most tutorials can run on: - CPU: Standard laptop/desktop (8GB+ RAM recommended) - GPU: Optional, speeds up OTDD computations - Storage: ~1GB for tutorial data and caches</p>"},{"location":"tutorials/index.html#getting-help","title":"Getting Help","text":""},{"location":"tutorials/index.html#tutorial-support","title":"Tutorial Support","text":"<p>If you encounter issues with tutorials:</p> <ol> <li>Check Prerequisites: Ensure all dependencies are installed</li> <li>Verify Data: Confirm tutorial data is properly downloaded</li> <li>Read Error Messages: THEMAP provides detailed error information</li> <li>Ask Questions: Open an issue on GitHub</li> </ol>"},{"location":"tutorials/index.html#common-issues","title":"Common Issues","text":"<pre><code># Installation issues\npip install -e \".[all]\"  # Install all dependencies\n\n# Memory issues\n# Use smaller datasets or batch processing\n\n# GPU issues\nimport torch\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\n</code></pre>"},{"location":"tutorials/index.html#community","title":"Community","text":"<ul> <li>GitHub Discussions: Share experiences and ask questions</li> <li>Issues: Report bugs or request features</li> <li>Contributions: Submit improvements to tutorials</li> </ul>"},{"location":"tutorials/index.html#contributing-to-tutorials","title":"Contributing to Tutorials","text":"<p>We welcome contributions! To add or improve tutorials:</p> <ol> <li>Fork the repository</li> <li>Create tutorial content in Markdown and/or Jupyter format</li> <li>Test thoroughly with different environments</li> <li>Submit pull request with clear description</li> </ol>"},{"location":"tutorials/index.html#tutorial-guidelines","title":"Tutorial Guidelines","text":"<ul> <li>Clear objectives: State what readers will learn</li> <li>Step-by-step: Break complex tasks into manageable steps</li> <li>Code examples: Include runnable code snippets</li> <li>Error handling: Show how to handle common issues</li> <li>Real data: Use realistic examples when possible</li> </ul>"},{"location":"tutorials/index.html#whats-next","title":"What's Next?","text":"<p>Ready to get started? Here are recommended next steps:</p> <ul> <li>New to THEMAP? \u2192 Getting Started</li> </ul> <p>Happy learning! \ud83e\uddea\ud83d\udd2c\ud83d\udcca</p>"},{"location":"tutorials/Basics.html","title":"Importing Required Libraries","text":"In\u00a0[1]: Copied! <pre># import general packages\nimport os\nimport sys\n\nimport pandas as pd\nimport torch\nfrom dpu_utils.utils.richpath import RichPath\nfrom tqdm.notebook import tqdm\n\n# Setting up local details:\n# This should be the location of the checkout of the THEMAP repository:\nrepo_path = os.path.dirname(os.path.abspath(\"\"))\nCHECKOUT_PATH = repo_path\nDATASET_PATH = os.path.join(repo_path, \"datasets\")\n\nos.chdir(CHECKOUT_PATH)\nsys.path.insert(0, CHECKOUT_PATH)\n</pre> # import general packages import os import sys  import pandas as pd import torch from dpu_utils.utils.richpath import RichPath from tqdm.notebook import tqdm  # Setting up local details: # This should be the location of the checkout of the THEMAP repository: repo_path = os.path.dirname(os.path.abspath(\"\")) CHECKOUT_PATH = repo_path DATASET_PATH = os.path.join(repo_path, \"datasets\")  os.chdir(CHECKOUT_PATH) sys.path.insert(0, CHECKOUT_PATH) In\u00a0[2]: Copied! <pre>from third_party.otdd.otdd.pytorch.datasets import MolDataset, load_molecule_data\nfrom third_party.otdd.otdd.pytorch.distance import DatasetDistance\n</pre> from third_party.otdd.otdd.pytorch.datasets import MolDataset, load_molecule_data from third_party.otdd.otdd.pytorch.distance import DatasetDistance <pre>ot.gpu not found - coupling computation will be in cpu\n</pre> In\u00a0[3]: Copied! <pre># import visualization packages\n%matplotlib inline\n\nimport ipywidgets as widgets\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nfrom themap.data import MoleculeDataset, ProteinDataset\n\nlight_color = plt.get_cmap(\"plasma\").colors[170]\ndark_color = \"black\"\n\nmatplotlib.rcParams.update(\n    {\n        \"pgf.texsystem\": \"pdflatex\",\n        \"font.family\": \"serif\",\n        \"font.serif\": \"Computer Modern Roman\",\n        \"font.size\": 20,\n        \"text.usetex\": True,\n        \"pgf.rcfonts\": False,\n    }\n)\n</pre> # import visualization packages %matplotlib inline  import ipywidgets as widgets import matplotlib import matplotlib.pyplot as plt  from themap.data import MoleculeDataset, ProteinDataset  light_color = plt.get_cmap(\"plasma\").colors[170] dark_color = \"black\"  matplotlib.rcParams.update(     {         \"pgf.texsystem\": \"pdflatex\",         \"font.family\": \"serif\",         \"font.serif\": \"Computer Modern Roman\",         \"font.size\": 20,         \"text.usetex\": True,         \"pgf.rcfonts\": False,     } ) In\u00a0[4]: Copied! <pre>source_dataset_path = RichPath.create(os.path.join(DATASET_PATH, \"train\", \"CHEMBL1023359.jsonl.gz\"))\ntarget_dataset_path = RichPath.create(os.path.join(DATASET_PATH, \"test\", \"CHEMBL2219358.jsonl.gz\"))\n\nsource_dataset = MoleculeDataset.load_from_file(source_dataset_path)\ntarget_dataset = MoleculeDataset.load_from_file(target_dataset_path)\n</pre> source_dataset_path = RichPath.create(os.path.join(DATASET_PATH, \"train\", \"CHEMBL1023359.jsonl.gz\")) target_dataset_path = RichPath.create(os.path.join(DATASET_PATH, \"test\", \"CHEMBL2219358.jsonl.gz\"))  source_dataset = MoleculeDataset.load_from_file(source_dataset_path) target_dataset = MoleculeDataset.load_from_file(target_dataset_path) In\u00a0[5]: Copied! <pre>Molecule_Feaurizer = widgets.Dropdown(\n    options=[\"gin_supervised_infomax\", \"gin_supervised_masking\", \"gin_supervised_edgepred\"],\n    value=\"gin_supervised_infomax\",\n    description=\"Molecule Featurizer:\",\n    disabled=False,\n)\n</pre> Molecule_Feaurizer = widgets.Dropdown(     options=[\"gin_supervised_infomax\", \"gin_supervised_masking\", \"gin_supervised_edgepred\"],     value=\"gin_supervised_infomax\",     description=\"Molecule Featurizer:\",     disabled=False, ) In\u00a0[6]: Copied! <pre>Molecule_Feaurizer\n</pre> Molecule_Feaurizer Out[6]: <pre>Dropdown(description='Molecule Featurizer:', options=('gin_supervised_infomax', 'gin_supervised_masking', 'gin\u2026</pre> In\u00a0[7]: Copied! <pre>## compute and load the embeddings\nmolecule_feaurizer = Molecule_Feaurizer.value\nsource_features = source_dataset.get_features(molecule_feaurizer)\ntarget_features = target_dataset.get_features(molecule_feaurizer)\nassert source_features.shape[1] == target_features.shape[1]\n</pre> ## compute and load the embeddings molecule_feaurizer = Molecule_Feaurizer.value source_features = source_dataset.get_features(molecule_feaurizer) target_features = target_dataset.get_features(molecule_feaurizer) assert source_features.shape[1] == target_features.shape[1] In\u00a0[8]: Copied! <pre>source_dataset_otdd = MolDataset(source_dataset)\ntarget_dataset_otdd = MolDataset(target_dataset)\n</pre> source_dataset_otdd = MolDataset(source_dataset) target_dataset_otdd = MolDataset(target_dataset) In\u00a0[9]: Copied! <pre>source_dataset_loader = load_molecule_data(source_dataset)\ntarget_dataset_loader = load_molecule_data(target_dataset)\n</pre> source_dataset_loader = load_molecule_data(source_dataset) target_dataset_loader = load_molecule_data(target_dataset) In\u00a0[\u00a0]: Copied! <pre># Instantiate distance\ndist = DatasetDistance(\n    source_dataset_loader,\n    target_dataset_loader,\n    inner_ot_method=\"exact\",\n    debiased_loss=True,\n    p=2,\n    entreg=1e-1,\n    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n)\n\nd = dist.distance(maxsamples=1000)\nprint(f\"OTDD(src,tgt)={d}\")\n</pre> # Instantiate distance dist = DatasetDistance(     source_dataset_loader,     target_dataset_loader,     inner_ot_method=\"exact\",     debiased_loss=True,     p=2,     entreg=1e-1,     device=\"cuda\" if torch.cuda.is_available() else \"cpu\", )  d = dist.distance(maxsamples=1000) print(f\"OTDD(src,tgt)={d}\") In\u00a0[\u00a0]: Copied! <pre>import glob\n\nsource_datasets_path = glob.glob(os.path.join(DATASET_PATH, \"train\", \"CHEMBL*\"))\ntarget_datasets_path = glob.glob(os.path.join(DATASET_PATH, \"test\", \"CHEMBL*\"))\nchem_distances = {}\nfor target_path in tqdm(target_datasets_path):\n    chem_distance = {}\n    target_dataset_path = RichPath.create(target_path)\n    target_dataset = MoleculeDataset.load_from_file(target_dataset_path)\n    target_features = target_dataset.get_features(molecule_feaurizer)\n    target_dataset_otdd = MolDataset(target_dataset)\n    target_dataset_loader = load_molecule_data(target_dataset)\n    for source_path in source_datasets_path:\n        source_dataset_path = RichPath.create(source_path)\n        source_dataset = MoleculeDataset.load_from_file(source_dataset_path)\n        source_features = source_dataset.get_features(molecule_feaurizer)\n        source_dataset_otdd = MolDataset(source_dataset)\n        source_dataset_loader = load_molecule_data(source_dataset)\n\n        dist = DatasetDistance(\n            source_dataset_loader,\n            target_dataset_loader,\n            inner_ot_method=\"exact\",\n            debiased_loss=True,\n            p=2,\n            entreg=1e-1,\n            device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n        )\n\n        d = dist.distance(maxsamples=1000)\n        print(f\"OTDD({source_dataset.task_id},{target_dataset.task_id})= {d}\")\n        chem_distance[source_dataset.task_id] = d.cpu().item()\n    chem_distances[target_dataset.task_id] = chem_distance\n</pre> import glob  source_datasets_path = glob.glob(os.path.join(DATASET_PATH, \"train\", \"CHEMBL*\")) target_datasets_path = glob.glob(os.path.join(DATASET_PATH, \"test\", \"CHEMBL*\")) chem_distances = {} for target_path in tqdm(target_datasets_path):     chem_distance = {}     target_dataset_path = RichPath.create(target_path)     target_dataset = MoleculeDataset.load_from_file(target_dataset_path)     target_features = target_dataset.get_features(molecule_feaurizer)     target_dataset_otdd = MolDataset(target_dataset)     target_dataset_loader = load_molecule_data(target_dataset)     for source_path in source_datasets_path:         source_dataset_path = RichPath.create(source_path)         source_dataset = MoleculeDataset.load_from_file(source_dataset_path)         source_features = source_dataset.get_features(molecule_feaurizer)         source_dataset_otdd = MolDataset(source_dataset)         source_dataset_loader = load_molecule_data(source_dataset)          dist = DatasetDistance(             source_dataset_loader,             target_dataset_loader,             inner_ot_method=\"exact\",             debiased_loss=True,             p=2,             entreg=1e-1,             device=\"cuda\" if torch.cuda.is_available() else \"cpu\",         )          d = dist.distance(maxsamples=1000)         print(f\"OTDD({source_dataset.task_id},{target_dataset.task_id})= {d}\")         chem_distance[source_dataset.task_id] = d.cpu().item()     chem_distances[target_dataset.task_id] = chem_distance In\u00a0[12]: Copied! <pre>## Choose your target from chem_distances.keys()\nyour_tasks = \"CHEMBL2219236\"\nchem_dist = chem_distances[your_tasks]\nfig = plt.figure(figsize=(12, 5))\nplt.bar(chem_dist.keys(), chem_dist.values())\nplt.xlabel(\"Source datasets\")\nplt.ylabel(\"OTDD\")\nplt.title(f\"OTDD between source datasets and target {your_tasks}\")\nplt.xticks(rotation=90)\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=1.0)\nplt.show()\n</pre> ## Choose your target from chem_distances.keys() your_tasks = \"CHEMBL2219236\" chem_dist = chem_distances[your_tasks] fig = plt.figure(figsize=(12, 5)) plt.bar(chem_dist.keys(), chem_dist.values()) plt.xlabel(\"Source datasets\") plt.ylabel(\"OTDD\") plt.title(f\"OTDD between source datasets and target {your_tasks}\") plt.xticks(rotation=90) plt.grid(axis=\"y\", linestyle=\"--\", alpha=1.0) plt.show() In\u00a0[15]: Copied! <pre>chem_distances.keys()\n</pre> chem_distances.keys() Out[15]: <pre>dict_keys(['CHEMBL2219236', 'CHEMBL1963831', 'CHEMBL2219358'])</pre> In\u00a0[13]: Copied! <pre>Protein_Feaurizer = widgets.Dropdown(\n    options=[\n        \"esm2_t6_8M_UR50D\",\n        \"esm2_t12_35M_UR50D\",\n        \"esm2_t30_150M_UR50D\",\n        \"esm2_t33_650M_UR50D\",\n        \"esm2_t36_3B_UR50D\",\n    ],\n    value=\"esm2_t33_650M_UR50D\",\n    description=\"Protein Featurizer:\",\n    disabled=False,\n)\n</pre> Protein_Feaurizer = widgets.Dropdown(     options=[         \"esm2_t6_8M_UR50D\",         \"esm2_t12_35M_UR50D\",         \"esm2_t30_150M_UR50D\",         \"esm2_t33_650M_UR50D\",         \"esm2_t36_3B_UR50D\",     ],     value=\"esm2_t33_650M_UR50D\",     description=\"Protein Featurizer:\",     disabled=False, ) In\u00a0[14]: Copied! <pre>Protein_Feaurizer\n</pre> Protein_Feaurizer Out[14]: <pre>Dropdown(description='Protein Featurizer:', index=3, options=('esm2_t6_8M_UR50D', 'esm2_t12_35M_UR50D', 'esm2_\u2026</pre> In\u00a0[15]: Copied! <pre>source_protein = ProteinDataset.load_from_file(\"datasets/train/train_proteins.fasta\")\ntarget_protein = ProteinDataset.load_from_file(\"datasets/test/test_proteins.fasta\")\n</pre> source_protein = ProteinDataset.load_from_file(\"datasets/train/train_proteins.fasta\") target_protein = ProteinDataset.load_from_file(\"datasets/test/test_proteins.fasta\") In\u00a0[16]: Copied! <pre>protein_featurizer = Protein_Feaurizer.value\nsource_protein_features = source_protein.get_features(protein_featurizer)\ntarget_protein_features = target_protein.get_features(protein_featurizer)\n</pre> protein_featurizer = Protein_Feaurizer.value source_protein_features = source_protein.get_features(protein_featurizer) target_protein_features = target_protein.get_features(protein_featurizer) In\u00a0[17]: Copied! <pre>from scipy.spatial.distance import cdist\n\ndist = cdist(source_protein.features, target_protein.features)\n</pre> from scipy.spatial.distance import cdist  dist = cdist(source_protein.features, target_protein.features) In\u00a0[18]: Copied! <pre>prot_distances = {}\nfor i, target_prot in enumerate(target_protein.task_id):\n    prot_distance = {}\n    for j, source_prot in enumerate(source_protein.task_id):\n        prot_distance[source_prot] = dist[j, i]\n    prot_distances[target_prot] = prot_distance\n</pre> prot_distances = {} for i, target_prot in enumerate(target_protein.task_id):     prot_distance = {}     for j, source_prot in enumerate(source_protein.task_id):         prot_distance[source_prot] = dist[j, i]     prot_distances[target_prot] = prot_distance In\u00a0[24]: Copied! <pre>## Choose your target from chem_distances.keys()\nyour_tasks = \"CHEMBL2219236\"\nprot_dist = prot_distances[your_tasks]\nfig = plt.figure(figsize=(12, 5))\nplt.bar(prot_dist.keys(), prot_dist.values())\nplt.xlabel(\"Source datasets\")\nplt.ylabel(\"Protein Distance\")\nplt.title(f\"Protein Distance between source datasets and target {your_tasks}\")\nplt.xticks(rotation=90)\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=1.0)\nplt.show()\n</pre> ## Choose your target from chem_distances.keys() your_tasks = \"CHEMBL2219236\" prot_dist = prot_distances[your_tasks] fig = plt.figure(figsize=(12, 5)) plt.bar(prot_dist.keys(), prot_dist.values()) plt.xlabel(\"Source datasets\") plt.ylabel(\"Protein Distance\") plt.title(f\"Protein Distance between source datasets and target {your_tasks}\") plt.xticks(rotation=90) plt.grid(axis=\"y\", linestyle=\"--\", alpha=1.0) plt.show() <p>Now, we can answer to the following questions:</p> <ul> <li>Given a target task, what is the closest source task in terms of chemical and protein distances?</li> <li>Given the source tasks, which target task is hardest to transfer to in terms of chemical and protein space?</li> <li>Given a target task and source tasks, how to pick the k nearset source tasks fo transfer learning?</li> </ul> <p>So, let's answer to this questions in the following sections.</p> In\u00a0[42]: Copied! <pre>chem_df = pd.DataFrame.from_dict(chem_distances)\nprot_df = pd.DataFrame.from_dict(prot_distances)\n</pre> chem_df = pd.DataFrame.from_dict(chem_distances) prot_df = pd.DataFrame.from_dict(prot_distances) In\u00a0[69]: Copied! <pre>## Given a target task, what is the closest source task in terms of chemical and protein distances?\nyour_task = \"CHEMBL2219236\"\n\nchem_distance = chem_df[your_task]\nprot_distance = prot_df[your_task]\n\nnormalized_chem_distance = (chem_distance - chem_distance.min()) / (chem_distance.max() - chem_distance.min())\nnormalized_prot_distance = (prot_distance - prot_distance.min()) / (prot_distance.max() - prot_distance.min())\nnormalized_prot_distance = normalized_prot_distance.reindex(normalized_chem_distance.index)\nnormalized_comb_distance = (normalized_chem_distance + normalized_prot_distance) / 2\n\n\nprint(f\"Closest source task in terms of chemical distance: {chem_distance.idxmin()}\")\nprint(f\"Closest source task in terms of protein distance: {prot_distance.idxmin()}\")\nprint(\n    f\"Closest source task in terms of combination of chemical and protein distance: {normalized_comb_distance.idxmin()}\"\n)\n</pre> ## Given a target task, what is the closest source task in terms of chemical and protein distances? your_task = \"CHEMBL2219236\"  chem_distance = chem_df[your_task] prot_distance = prot_df[your_task]  normalized_chem_distance = (chem_distance - chem_distance.min()) / (chem_distance.max() - chem_distance.min()) normalized_prot_distance = (prot_distance - prot_distance.min()) / (prot_distance.max() - prot_distance.min()) normalized_prot_distance = normalized_prot_distance.reindex(normalized_chem_distance.index) normalized_comb_distance = (normalized_chem_distance + normalized_prot_distance) / 2   print(f\"Closest source task in terms of chemical distance: {chem_distance.idxmin()}\") print(f\"Closest source task in terms of protein distance: {prot_distance.idxmin()}\") print(     f\"Closest source task in terms of combination of chemical and protein distance: {normalized_comb_distance.idxmin()}\" ) <pre>Closest source task in terms of chemical distance: CHEMBL2218944\nClosest source task in terms of protein distance: CHEMBL2219012\nClosest source task in terms of combination of chemical and protein distance: CHEMBL2219012\n</pre> In\u00a0[91]: Copied! <pre>## Given the source tasks, which target task is hardest to transfer to in terms of chemical and protein space?\n## Answering this question require to define hardness, which we consider here as the average of k-nearest source tasks.\nk = 3\n\ntarget_tasks = chem_df.columns\nsource_tasks = chem_df.index\n\nhardness_all = {}\nfor target_task in target_tasks:\n    hardness = {}\n    chem_distance = chem_df[target_task]\n    prot_distance = prot_df[target_task]\n\n    chem_distance = chem_distance.sort_values()\n    prot_distance = prot_distance.sort_values()\n\n    hardness[\"EXT_CHEM\"] = chem_distance[:k].sum() / k\n    hardness[\"EXT_PROT\"] = prot_distance[:k].sum() / k\n\n    hardness_all[target_task] = hardness\n\nhardness_df = pd.DataFrame.from_dict(hardness_all).T\nhardness_df[\"all\"] = (hardness_df[\"EXT_CHEM\"] + hardness_df[\"EXT_PROT\"]) / 2\n\nprint(f\"Easiest target task in terms of chemical distance: {hardness_df['EXT_CHEM'].idxmin()}\")\nprint(f\"Easiest target task in terms of protein distance: {hardness_df['EXT_PROT'].idxmin()}\")\nprint(\n    f\"Easiest target task in terms of combination of chemical and protein distance: {hardness_df['all'].idxmin()}\"\n)\n</pre> ## Given the source tasks, which target task is hardest to transfer to in terms of chemical and protein space? ## Answering this question require to define hardness, which we consider here as the average of k-nearest source tasks. k = 3  target_tasks = chem_df.columns source_tasks = chem_df.index  hardness_all = {} for target_task in target_tasks:     hardness = {}     chem_distance = chem_df[target_task]     prot_distance = prot_df[target_task]      chem_distance = chem_distance.sort_values()     prot_distance = prot_distance.sort_values()      hardness[\"EXT_CHEM\"] = chem_distance[:k].sum() / k     hardness[\"EXT_PROT\"] = prot_distance[:k].sum() / k      hardness_all[target_task] = hardness  hardness_df = pd.DataFrame.from_dict(hardness_all).T hardness_df[\"all\"] = (hardness_df[\"EXT_CHEM\"] + hardness_df[\"EXT_PROT\"]) / 2  print(f\"Easiest target task in terms of chemical distance: {hardness_df['EXT_CHEM'].idxmin()}\") print(f\"Easiest target task in terms of protein distance: {hardness_df['EXT_PROT'].idxmin()}\") print(     f\"Easiest target task in terms of combination of chemical and protein distance: {hardness_df['all'].idxmin()}\" ) <pre>Easiest target task in terms of chemical distance: CHEMBL2219236\nEasiest target task in terms of protein distance: CHEMBL2219358\nEasiest target task in terms of combination of chemical and protein distance: CHEMBL2219358\n</pre> In\u00a0[93]: Copied! <pre>plt.figure(figsize=(12, 5))\nplt.bar(hardness_df.index, hardness_df[\"all\"])\nplt.xlabel(\"Target datasets\")\nplt.ylabel(\"Hardness\")\nplt.title(\"Hardness of target datasets\")\nplt.xticks(rotation=90)\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=1.0)\nplt.show()\n</pre> plt.figure(figsize=(12, 5)) plt.bar(hardness_df.index, hardness_df[\"all\"]) plt.xlabel(\"Target datasets\") plt.ylabel(\"Hardness\") plt.title(\"Hardness of target datasets\") plt.xticks(rotation=90) plt.grid(axis=\"y\", linestyle=\"--\", alpha=1.0) plt.show() In\u00a0[103]: Copied! <pre>## Given a target task and source tasks, how to pick the k nearset source tasks fo transfer learning?\n## Given the source tasks, which target task is hardest to transfer to in terms of chemical and protein space?\n## Answering this question require to define hardness, which we consider here as the average of k-nearest source tasks.\nk = 3\n\ntarget_tasks = chem_df.columns\nsource_tasks = chem_df.index\n\nclosest_tasks = {}\nfor target_task in target_tasks:\n    closest = {}\n    chem_distance = chem_df[target_task]\n    prot_distance = prot_df[target_task]\n\n    chem_distance = chem_distance.sort_values()\n    prot_distance = prot_distance.sort_values()\n\n    closest[\"EXT_CHEM\"] = chem_distance[:k].index.to_list()\n    closest[\"EXT_PROT\"] = prot_distance[:k].index.to_list()\n\n    closest_tasks[target_task] = closest\n\nclosest_df = pd.DataFrame.from_dict(closest_tasks).T\n</pre> ## Given a target task and source tasks, how to pick the k nearset source tasks fo transfer learning? ## Given the source tasks, which target task is hardest to transfer to in terms of chemical and protein space? ## Answering this question require to define hardness, which we consider here as the average of k-nearest source tasks. k = 3  target_tasks = chem_df.columns source_tasks = chem_df.index  closest_tasks = {} for target_task in target_tasks:     closest = {}     chem_distance = chem_df[target_task]     prot_distance = prot_df[target_task]      chem_distance = chem_distance.sort_values()     prot_distance = prot_distance.sort_values()      closest[\"EXT_CHEM\"] = chem_distance[:k].index.to_list()     closest[\"EXT_PROT\"] = prot_distance[:k].index.to_list()      closest_tasks[target_task] = closest  closest_df = pd.DataFrame.from_dict(closest_tasks).T"},{"location":"tutorials/Basics.html#importing-required-libraries","title":"Importing Required Libraries\u00b6","text":"<p>First, we are importing the libraries and modules that are required for running this notebook.</p>"},{"location":"tutorials/Basics.html#create-source-and-target-datasets-data","title":"Create source and target datasets (Data)\u00b6","text":""},{"location":"tutorials/Basics.html#calculate-chemcial-distance-between-target-datasets-with-all-the-source-datasets","title":"Calculate chemcial distance between target datasets with all the source datasets\u00b6","text":""},{"location":"tutorials/Basics.html#calculate-protein-distance-between-target-datasets-with-all-the-source-datasets","title":"Calculate protein distance between target datasets with all the source datasets\u00b6","text":""},{"location":"tutorials/Basics.html#combine-two-distances","title":"Combine Two Distances\u00b6","text":""},{"location":"tutorials/basic-distance-computation.html","title":"Basic Distance Computation","text":"<p>This tutorial covers the fundamentals of computing distances between molecular and protein datasets using THEMAP.</p>"},{"location":"tutorials/basic-distance-computation.html#overview","title":"Overview","text":"<p>Distance computation is at the core of THEMAP's functionality. This tutorial will show you how to:</p> <ol> <li>Choose appropriate distance metrics</li> <li>Configure distance calculations</li> <li>Handle different data types</li> <li>Optimize performance</li> </ol>"},{"location":"tutorials/basic-distance-computation.html#distance-methods-comparison","title":"Distance Methods Comparison","text":""},{"location":"tutorials/basic-distance-computation.html#euclidean-distance","title":"Euclidean Distance","text":"<ul> <li>Fast and memory-efficient</li> <li>Good for initial exploration</li> <li>Works with any embedding</li> </ul> <pre><code>from themap.distance import MoleculeDatasetDistance\n\ndistance_calc = MoleculeDatasetDistance(\n    tasks=None,\n    molecule_method=\"euclidean\"\n)\n</code></pre>"},{"location":"tutorials/basic-distance-computation.html#cosine-distance","title":"Cosine Distance","text":"<ul> <li>Focuses on feature orientation</li> <li>Good for high-dimensional embeddings</li> <li>Normalized by vector magnitude</li> </ul> <pre><code>distance_calc = MoleculeDatasetDistance(\n    tasks=None,\n    molecule_method=\"cosine\"\n)\n</code></pre>"},{"location":"tutorials/basic-distance-computation.html#otdd-optimal-transport-dataset-distance","title":"OTDD (Optimal Transport Dataset Distance)","text":"<ul> <li>Most comprehensive but computationally expensive</li> <li>Considers both features and labels</li> <li>Best for detailed analysis</li> </ul> <pre><code>distance_calc = MoleculeDatasetDistance(\n    tasks=None,\n    molecule_method=\"otdd\"\n)\n</code></pre>"},{"location":"tutorials/basic-distance-computation.html#working-with-different-data-types","title":"Working with Different Data Types","text":""},{"location":"tutorials/basic-distance-computation.html#molecular-datasets","title":"Molecular Datasets","text":"<pre><code>from themap.data import MoleculeDataset\nfrom themap.distance import MoleculeDatasetDistance\n\n# Load datasets\ndatasets = [\n    MoleculeDataset.load_from_file(f\"datasets/train/{task_id}.jsonl.gz\")\n    for task_id in [\"CHEMBL1023359\", \"CHEMBL1613776\"]\n]\n\n# Compute all pairwise distances\ndistance_calc = MoleculeDatasetDistance(\n    tasks=None,\n    molecule_method=\"cosine\"\n)\n\n# Set up for pairwise comparison\ndistance_calc.source_molecule_datasets = datasets\ndistance_calc.target_molecule_datasets = datasets\ndistance_calc.source_task_ids = [d.task_id for d in datasets]\ndistance_calc.target_task_ids = [d.task_id for d in datasets]\n\ndistances = distance_calc.get_distance()\n</code></pre>"},{"location":"tutorials/basic-distance-computation.html#protein-datasets","title":"Protein Datasets","text":"<pre><code>from themap.data import ProteinMetadataDatasets\nfrom themap.distance import ProteinDatasetDistance\n\n# Load protein sequences\nproteins = ProteinMetadataDatasets.from_directory(\"datasets/train/\")\n\n# Compute protein distances\nprotein_distance = ProteinDatasetDistance(\n    tasks=None,\n    protein_method=\"euclidean\"\n)\n\nprotein_distance.source_protein_datasets = proteins\nprotein_distance.target_protein_datasets = proteins\n\nprotein_distances = protein_distance.get_distance()\n</code></pre>"},{"location":"tutorials/basic-distance-computation.html#batch-processing","title":"Batch Processing","text":"<p>For multiple datasets:</p> <pre><code>import os\nfrom pathlib import Path\n\ndef compute_all_distances(data_dir, method=\"euclidean\"):\n    \"\"\"Compute distances between all datasets in a directory.\"\"\"\n\n    # Find all dataset files\n    dataset_files = list(Path(data_dir).glob(\"*.jsonl.gz\"))\n\n    # Load all datasets\n    datasets = []\n    for file_path in dataset_files:\n        try:\n            dataset = MoleculeDataset.load_from_file(str(file_path))\n            datasets.append(dataset)\n        except Exception as e:\n            print(f\"Failed to load {file_path}: {e}\")\n\n    # Compute distances\n    if datasets:\n        distance_calc = MoleculeDatasetDistance(\n            tasks=None,\n            molecule_method=method\n        )\n\n        distance_calc.source_molecule_datasets = datasets\n        distance_calc.target_molecule_datasets = datasets\n        distance_calc.source_task_ids = [d.task_id for d in datasets]\n        distance_calc.target_task_ids = [d.task_id for d in datasets]\n\n        return distance_calc.get_distance()\n\n    return {}\n\n# Example usage\ndistances = compute_all_distances(\"datasets/train/\")\n</code></pre>"},{"location":"tutorials/basic-distance-computation.html#performance-optimization","title":"Performance Optimization","text":""},{"location":"tutorials/basic-distance-computation.html#memory-management","title":"Memory Management","text":"<pre><code># For large datasets, use euclidean instead of OTDD\ndistance_calc = MoleculeDatasetDistance(\n    tasks=None,\n    molecule_method=\"euclidean\"  # Much faster than OTDD\n)\n</code></pre>"},{"location":"tutorials/basic-distance-computation.html#otdd-configuration","title":"OTDD Configuration","text":"<pre><code># Limit samples for OTDD to reduce computation time\ndistance_calc = MoleculeDatasetDistance(\n    tasks=None,\n    molecule_method=\"otdd\"\n)\n\n# OTDD parameters are handled internally\n# but you can monitor progress\n</code></pre>"},{"location":"tutorials/basic-distance-computation.html#interpreting-results","title":"Interpreting Results","text":"<p>Distance results are returned as nested dictionaries:</p> <pre><code># Result structure: {target_id: {source_id: distance}}\ndistances = distance_calc.get_distance()\n\nfor target_id, source_distances in distances.items():\n    print(f\"Target: {target_id}\")\n    for source_id, distance in source_distances.items():\n        print(f\"  From {source_id}: {distance:.4f}\")\n</code></pre>"},{"location":"tutorials/basic-distance-computation.html#distance-interpretation","title":"Distance Interpretation","text":"<ul> <li>0.0: Identical datasets</li> <li>Low values (&lt; 1.0): Very similar datasets</li> <li>Medium values (1.0-10.0): Moderately similar</li> <li>High values (&gt; 10.0): Very different datasets</li> </ul> <p>Note: Actual ranges depend on the distance method and data characteristics.</p>"},{"location":"tutorials/basic-distance-computation.html#common-patterns","title":"Common Patterns","text":""},{"location":"tutorials/basic-distance-computation.html#finding-most-similar-datasets","title":"Finding Most Similar Datasets","text":"<pre><code>def find_most_similar(distances, target_task_id, top_k=3):\n    \"\"\"Find the most similar source tasks for a target task.\"\"\"\n\n    if target_task_id not in distances:\n        return []\n\n    source_distances = distances[target_task_id]\n\n    # Sort by distance (ascending = most similar first)\n    sorted_sources = sorted(\n        source_distances.items(),\n        key=lambda x: x[1]\n    )\n\n    return sorted_sources[:top_k]\n\n# Example usage\nsimilar_tasks = find_most_similar(distances, \"CHEMBL2219358\", top_k=3)\nfor source_id, distance in similar_tasks:\n    print(f\"Similar task: {source_id} (distance: {distance:.3f})\")\n</code></pre>"},{"location":"tutorials/basic-distance-computation.html#creating-distance-matrix","title":"Creating Distance Matrix","text":"<pre><code>import pandas as pd\n\ndef create_distance_matrix(distances):\n    \"\"\"Convert nested distance dict to pandas DataFrame.\"\"\"\n\n    # Get all unique task IDs\n    all_tasks = set()\n    for target_id, source_dict in distances.items():\n        all_tasks.add(target_id)\n        all_tasks.update(source_dict.keys())\n\n    all_tasks = sorted(list(all_tasks))\n\n    # Create matrix\n    matrix = pd.DataFrame(index=all_tasks, columns=all_tasks)\n\n    for target_id, source_dict in distances.items():\n        for source_id, distance in source_dict.items():\n            matrix.loc[target_id, source_id] = distance\n\n    return matrix\n\n# Create and display matrix\ndistance_matrix = create_distance_matrix(distances)\nprint(distance_matrix)\n</code></pre>"},{"location":"tutorials/basic-distance-computation.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/basic-distance-computation.html#common-errors","title":"Common Errors","text":"<ol> <li>Memory Error: Use euclidean distance or reduce dataset size</li> <li>Import Error: Install required dependencies</li> <li>File Not Found: Check file paths and data structure</li> </ol>"},{"location":"tutorials/basic-distance-computation.html#performance-tips","title":"Performance Tips","text":"<ol> <li>Start with euclidean distance for exploration</li> <li>Use OTDD only for final analysis</li> <li>Cache results for repeated computations</li> <li>Process in batches for large datasets</li> </ol>"},{"location":"tutorials/basic-distance-computation.html#next-steps","title":"Next Steps","text":"<ul> <li>Learn about working with tasks</li> <li>Explore performance optimization</li> <li>Try the unified task system</li> </ul>"},{"location":"tutorials/getting-started.html","title":"Getting Started Tutorial","text":"<p>This tutorial will walk you through the basic concepts and usage of THEMAP for task hardness estimation and distance computation.</p>"},{"location":"tutorials/getting-started.html#prerequisites","title":"Prerequisites","text":"<ul> <li>THEMAP installed with basic dependencies</li> <li>Python 3.10+</li> <li>Basic knowledge of molecular datasets</li> </ul>"},{"location":"tutorials/getting-started.html#tutorial-overview","title":"Tutorial Overview","text":"<p>In this tutorial, you will learn how to:</p> <ol> <li>Load molecular and protein datasets</li> <li>Compute basic distances between datasets</li> <li>Work with the unified task system</li> <li>Interpret distance results</li> </ol>"},{"location":"tutorials/getting-started.html#step-1-loading-your-first-dataset","title":"Step 1: Loading Your First Dataset","text":"<pre><code>from themap.data import MoleculeDataset\nfrom dpu_utils.utils.richpath import RichPath\n\n# Load a molecular dataset\ndataset_path = RichPath.create(\"datasets/train/CHEMBL1023359.jsonl.gz\")\ndataset = MoleculeDataset.load_from_file(dataset_path)\n\nprint(f\"Loaded dataset with {len(dataset)} molecules\")\nprint(f\"Task ID: {dataset.task_id}\")\nprint(f\"Sample molecule: {dataset[0].smiles}\")\n</code></pre>"},{"location":"tutorials/getting-started.html#step-2-computing-simple-distances","title":"Step 2: Computing Simple Distances","text":"<pre><code>from themap.distance import MoleculeDatasetDistance\n\n# Load two datasets to compare\nsource_dataset = MoleculeDataset.load_from_file(\n    RichPath.create(\"datasets/train/CHEMBL1023359.jsonl.gz\")\n)\ntarget_dataset = MoleculeDataset.load_from_file(\n    RichPath.create(\"datasets/test/CHEMBL2219358.jsonl.gz\")\n)\n\n# Create distance calculator\ndistance_calc = MoleculeDatasetDistance(\n    tasks=None,\n    molecule_method=\"euclidean\"  # Start with fastest method\n)\n\n# Set up the comparison\ndistance_calc.source_molecule_datasets = [source_dataset]\ndistance_calc.target_molecule_datasets = [target_dataset]\ndistance_calc.source_task_ids = [source_dataset.task_id]\ndistance_calc.target_task_ids = [target_dataset.task_id]\n\n# Compute distance\nresult = distance_calc.get_distance()\nprint(f\"Distance: {result}\")\n</code></pre>"},{"location":"tutorials/getting-started.html#step-3-working-with-protein-data","title":"Step 3: Working with Protein Data","text":"<pre><code>from themap.data import ProteinMetadataDatasets\nfrom themap.distance import ProteinDatasetDistance\n\n# Load protein sequences\nproteins = ProteinMetadataDatasets.from_directory(\"datasets/train/\")\nprint(f\"Loaded {len(proteins)} protein sequences\")\n\n# Compute protein similarities\nprotein_distance = ProteinDatasetDistance(\n    tasks=None,\n    protein_method=\"euclidean\"\n)\n\nprotein_distance.source_protein_datasets = proteins\nprotein_distance.target_protein_datasets = proteins\n\ndistances = protein_distance.get_distance()\nprint(\"Protein distance matrix computed\")\n</code></pre>"},{"location":"tutorials/getting-started.html#step-4-understanding-results","title":"Step 4: Understanding Results","text":"<p>Distance values have the following interpretations:</p> <ul> <li>Lower values: More similar datasets</li> <li>Higher values: More different datasets</li> <li>Scale: Depends on the method used</li> </ul> <pre><code># Analyze distance results\nfor target_id, source_distances in result.items():\n    print(f\"Target task: {target_id}\")\n    for source_id, distance in source_distances.items():\n        print(f\"  Distance from {source_id}: {distance:.3f}\")\n</code></pre>"},{"location":"tutorials/getting-started.html#next-steps","title":"Next Steps","text":"<p>Now that you understand the basics:</p> <ol> <li>Try different distance methods (<code>cosine</code>, <code>otdd</code>)</li> <li>Explore the unified task system</li> <li>Learn about task hardness estimation</li> <li>Check out the advanced examples</li> </ol>"},{"location":"tutorials/getting-started.html#common-issues","title":"Common Issues","text":""},{"location":"tutorials/getting-started.html#import-errors","title":"Import Errors","text":"<p>Make sure all dependencies are installed: <pre><code>pip install -e \".[ml]\"\n</code></pre></p>"},{"location":"tutorials/getting-started.html#memory-issues","title":"Memory Issues","text":"<p>Use euclidean distance for large datasets instead of OTDD.</p>"},{"location":"tutorials/getting-started.html#file-not-found","title":"File Not Found","text":"<p>Ensure your data files are in the correct directory structure.</p>"},{"location":"tutorials/performance-optimization.html","title":"Performance Optimization","text":"<p>This tutorial covers best practices for optimizing THEMAP performance when working with large datasets and complex distance computations.</p>"},{"location":"tutorials/performance-optimization.html#overview","title":"Overview","text":"<p>THEMAP offers several strategies to optimize performance:</p> <ol> <li>Method selection: Choose appropriate distance metrics</li> <li>Caching: Leverage feature caching for repeated computations</li> <li>Memory management: Handle large datasets efficiently</li> <li>Parallel processing: Utilize multiple cores when possible</li> <li>Data preprocessing: Optimize data loading and storage</li> </ol>"},{"location":"tutorials/performance-optimization.html#distance-method-performance","title":"Distance Method Performance","text":""},{"location":"tutorials/performance-optimization.html#speed-comparison","title":"Speed Comparison","text":"Method Speed Memory Accuracy Best For Euclidean \u26a1\u26a1\u26a1 \ud83d\udcbe \u2b50\u2b50 Initial exploration, large datasets Cosine \u26a1\u26a1\u26a1 \ud83d\udcbe \u2b50\u2b50\u2b50 High-dimensional features OTDD \u26a1 \ud83d\udcbe\ud83d\udcbe\ud83d\udcbe \u2b50\u2b50\u2b50\u2b50\u2b50 Detailed analysis, small-medium datasets"},{"location":"tutorials/performance-optimization.html#choosing-the-right-method","title":"Choosing the Right Method","text":"<pre><code>import time\nfrom themap.distance import MoleculeDatasetDistance\nfrom themap.data import MoleculeDataset\n\ndef benchmark_methods(datasets, methods=[\"euclidean\", \"cosine\", \"otdd\"]):\n    \"\"\"Benchmark different distance methods.\"\"\"\n\n    results = {}\n\n    for method in methods:\n        print(f\"Benchmarking {method}...\")\n\n        start_time = time.time()\n\n        try:\n            distance_calc = MoleculeDatasetDistance(\n                tasks=None,\n                molecule_method=method\n            )\n\n            distance_calc.source_molecule_datasets = datasets[:2]\n            distance_calc.target_molecule_datasets = datasets[:2]\n            distance_calc.source_task_ids = [d.task_id for d in datasets[:2]]\n            distance_calc.target_task_ids = [d.task_id for d in datasets[:2]]\n\n            distances = distance_calc.get_distance()\n\n            elapsed = time.time() - start_time\n            results[method] = {\n                'time': elapsed,\n                'success': True,\n                'distances': distances\n            }\n\n            print(f\"  \u2705 {method}: {elapsed:.2f}s\")\n\n        except Exception as e:\n            elapsed = time.time() - start_time\n            results[method] = {\n                'time': elapsed,\n                'success': False,\n                'error': str(e)\n            }\n            print(f\"  \u274c {method}: Failed after {elapsed:.2f}s\")\n\n    return results\n\n# Load sample datasets\ndatasets = [\n    MoleculeDataset.load_from_file(f\"datasets/train/{task_id}.jsonl.gz\")\n    for task_id in [\"CHEMBL1023359\", \"CHEMBL1613776\"]\n]\n\n# Run benchmark\nbenchmark_results = benchmark_methods(datasets)\n</code></pre>"},{"location":"tutorials/performance-optimization.html#caching-strategies","title":"Caching Strategies","text":""},{"location":"tutorials/performance-optimization.html#feature-caching","title":"Feature Caching","text":"<pre><code>from themap.data.tasks import Tasks\n\n# Enable comprehensive caching\ntasks = Tasks.from_directory(\n    directory=\"datasets/\",\n    task_list_file=\"datasets/sample_tasks_list.json\",\n    load_molecules=True,\n    load_proteins=True,\n    cache_dir=\"cache/\",  # All computed features cached here\n    force_reload=False   # Use existing cache when available\n)\n\nprint(\"Features will be cached for future use\")\n</code></pre>"},{"location":"tutorials/performance-optimization.html#custom-cache-management","title":"Custom Cache Management","text":"<pre><code>import os\nimport shutil\nfrom pathlib import Path\n\ndef manage_cache(cache_dir=\"cache/\"):\n    \"\"\"Manage THEMAP cache directory.\"\"\"\n\n    cache_path = Path(cache_dir)\n\n    if cache_path.exists():\n        # Get cache size\n        total_size = sum(\n            f.stat().st_size for f in cache_path.rglob('*') if f.is_file()\n        )\n\n        print(f\"Cache directory: {cache_dir}\")\n        print(f\"Cache size: {total_size / (1024**3):.2f} GB\")\n        print(f\"Cached files: {len(list(cache_path.rglob('*')))}\")\n\n        # List cache contents\n        for subdir in cache_path.iterdir():\n            if subdir.is_dir():\n                n_files = len(list(subdir.rglob('*')))\n                print(f\"  {subdir.name}: {n_files} files\")\n    else:\n        print(f\"Cache directory {cache_dir} does not exist\")\n\ndef clear_cache(cache_dir=\"cache/\", confirm=True):\n    \"\"\"Clear the cache directory.\"\"\"\n\n    if confirm:\n        response = input(f\"Clear cache directory {cache_dir}? (y/N): \")\n        if response.lower() != 'y':\n            return\n\n    cache_path = Path(cache_dir)\n    if cache_path.exists():\n        shutil.rmtree(cache_path)\n        print(f\"Cache cleared: {cache_dir}\")\n    else:\n        print(f\"Cache directory {cache_dir} does not exist\")\n\n# Example usage\nmanage_cache()\n</code></pre>"},{"location":"tutorials/performance-optimization.html#memory-management","title":"Memory Management","text":""},{"location":"tutorials/performance-optimization.html#large-dataset-handling","title":"Large Dataset Handling","text":"<pre><code>def process_large_datasets(dataset_dir, batch_size=5, method=\"euclidean\"):\n    \"\"\"Process large numbers of datasets in batches.\"\"\"\n\n    from pathlib import Path\n    import gc\n\n    # Find all dataset files\n    dataset_files = list(Path(dataset_dir).glob(\"*.jsonl.gz\"))\n    print(f\"Found {len(dataset_files)} datasets\")\n\n    # Process in batches\n    all_results = {}\n\n    for i in range(0, len(dataset_files), batch_size):\n        batch_files = dataset_files[i:i + batch_size]\n        print(f\"Processing batch {i//batch_size + 1}: {len(batch_files)} files\")\n\n        # Load batch\n        batch_datasets = []\n        for file_path in batch_files:\n            try:\n                dataset = MoleculeDataset.load_from_file(str(file_path))\n                batch_datasets.append(dataset)\n            except Exception as e:\n                print(f\"Failed to load {file_path}: {e}\")\n\n        if len(batch_datasets) &lt; 2:\n            continue\n\n        # Compute distances for this batch\n        try:\n            distance_calc = MoleculeDatasetDistance(\n                tasks=None,\n                molecule_method=method\n            )\n\n            distance_calc.source_molecule_datasets = batch_datasets\n            distance_calc.target_molecule_datasets = batch_datasets\n            distance_calc.source_task_ids = [d.task_id for d in batch_datasets]\n            distance_calc.target_task_ids = [d.task_id for d in batch_datasets]\n\n            batch_results = distance_calc.get_distance()\n            all_results.update(batch_results)\n\n            print(f\"  \u2705 Computed {len(batch_results)} distances\")\n\n        except Exception as e:\n            print(f\"  \u274c Batch failed: {e}\")\n\n        # Clean up memory\n        del batch_datasets\n        gc.collect()\n\n    return all_results\n\n# Process large dataset directory\nresults = process_large_datasets(\"datasets/train/\", batch_size=3)\n</code></pre>"},{"location":"tutorials/performance-optimization.html#memory-monitoring","title":"Memory Monitoring","text":"<pre><code>import psutil\nimport os\n\ndef monitor_memory():\n    \"\"\"Monitor current memory usage.\"\"\"\n\n    process = psutil.Process(os.getpid())\n    memory_info = process.memory_info()\n\n    print(f\"RSS Memory: {memory_info.rss / (1024**3):.2f} GB\")\n    print(f\"VMS Memory: {memory_info.vms / (1024**3):.2f} GB\")\n\n    # System memory\n    system_memory = psutil.virtual_memory()\n    print(f\"System Memory: {system_memory.percent}% used\")\n\n    return memory_info\n\ndef memory_efficient_processing(tasks, max_memory_gb=8):\n    \"\"\"Process tasks with memory monitoring.\"\"\"\n\n    initial_memory = monitor_memory()\n\n    # Estimate memory per task\n    sample_memory = initial_memory.rss / (1024**3)\n\n    # Calculate safe batch size\n    available_memory = max_memory_gb - sample_memory\n    estimated_memory_per_task = 0.1  # GB, adjust based on your data\n    safe_batch_size = max(1, int(available_memory / estimated_memory_per_task))\n\n    print(f\"Using batch size: {safe_batch_size}\")\n\n    # Process in safe batches\n    task_ids = tasks.get_task_ids()\n\n    for i in range(0, len(task_ids), safe_batch_size):\n        batch_ids = task_ids[i:i + safe_batch_size]\n\n        print(f\"Processing batch {i//safe_batch_size + 1}\")\n        monitor_memory()\n\n        # Process batch here\n        # ... your processing code ...\n\n        # Force garbage collection\n        import gc\n        gc.collect()\n\n# Example usage\n# memory_efficient_processing(tasks, max_memory_gb=16)\n</code></pre>"},{"location":"tutorials/performance-optimization.html#parallel-processing","title":"Parallel Processing","text":""},{"location":"tutorials/performance-optimization.html#multi-processing-for-distance-computation","title":"Multi-Processing for Distance Computation","text":"<pre><code>from concurrent.futures import ProcessPoolExecutor, as_completed\nimport multiprocessing as mp\n\ndef compute_single_distance(args):\n    \"\"\"Compute distance between two datasets (for multiprocessing).\"\"\"\n\n    source_path, target_path, method = args\n\n    try:\n        # Load datasets\n        source = MoleculeDataset.load_from_file(source_path)\n        target = MoleculeDataset.load_from_file(target_path)\n\n        # Compute distance\n        distance_calc = MoleculeDatasetDistance(\n            tasks=None,\n            molecule_method=method\n        )\n\n        distance_calc.source_molecule_datasets = [source]\n        distance_calc.target_molecule_datasets = [target]\n        distance_calc.source_task_ids = [source.task_id]\n        distance_calc.target_task_ids = [target.task_id]\n\n        result = distance_calc.get_distance()\n\n        return {\n            'source': source.task_id,\n            'target': target.task_id,\n            'distance': list(result.values())[0][source.task_id],\n            'status': 'success'\n        }\n\n    except Exception as e:\n        return {\n            'source': str(source_path),\n            'target': str(target_path),\n            'distance': None,\n            'status': f'error: {str(e)}'\n        }\n\ndef parallel_distance_computation(\n    source_files,\n    target_files,\n    method=\"euclidean\",\n    max_workers=None\n):\n    \"\"\"Compute distances in parallel.\"\"\"\n\n    if max_workers is None:\n        max_workers = min(mp.cpu_count(), 8)  # Don't use all cores\n\n    # Create all combinations\n    tasks = [\n        (source, target, method)\n        for source in source_files\n        for target in target_files\n    ]\n\n    print(f\"Computing {len(tasks)} distances using {max_workers} workers\")\n\n    results = []\n    completed = 0\n\n    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n        # Submit all tasks\n        future_to_task = {\n            executor.submit(compute_single_distance, task): task\n            for task in tasks\n        }\n\n        # Collect results\n        for future in as_completed(future_to_task):\n            result = future.result()\n            results.append(result)\n            completed += 1\n\n            if completed % 10 == 0:\n                print(f\"Completed: {completed}/{len(tasks)}\")\n\n    return results\n\n# Example usage\nsource_files = [\"datasets/train/CHEMBL1023359.jsonl.gz\"]\ntarget_files = [\"datasets/test/CHEMBL2219358.jsonl.gz\", \"datasets/test/CHEMBL1963831.jsonl.gz\"]\n\nparallel_results = parallel_distance_computation(\n    source_files,\n    target_files,\n    method=\"euclidean\",\n    max_workers=4\n)\n</code></pre>"},{"location":"tutorials/performance-optimization.html#data-preprocessing-optimization","title":"Data Preprocessing Optimization","text":""},{"location":"tutorials/performance-optimization.html#efficient-data-loading","title":"Efficient Data Loading","text":"<pre><code>def optimize_data_loading(data_dir, cache_dir=\"cache/\"):\n    \"\"\"Optimize data loading with preprocessing.\"\"\"\n\n    from pathlib import Path\n    import pickle\n\n    cache_path = Path(cache_dir)\n    cache_path.mkdir(exist_ok=True)\n\n    # Check for preprocessed data\n    preprocessed_file = cache_path / \"preprocessed_datasets.pkl\"\n\n    if preprocessed_file.exists():\n        print(\"Loading preprocessed datasets...\")\n        with open(preprocessed_file, 'rb') as f:\n            return pickle.load(f)\n\n    print(\"Preprocessing datasets...\")\n\n    # Load and preprocess all datasets\n    datasets = {}\n    dataset_files = list(Path(data_dir).glob(\"*.jsonl.gz\"))\n\n    for i, file_path in enumerate(dataset_files):\n        try:\n            dataset = MoleculeDataset.load_from_file(str(file_path))\n\n            # Precompute features if needed\n            # This could include molecular descriptors, embeddings, etc.\n\n            datasets[dataset.task_id] = dataset\n\n            if (i + 1) % 10 == 0:\n                print(f\"Processed {i + 1}/{len(dataset_files)} datasets\")\n\n        except Exception as e:\n            print(f\"Failed to load {file_path}: {e}\")\n\n    # Cache preprocessed data\n    with open(preprocessed_file, 'wb') as f:\n        pickle.dump(datasets, f)\n\n    print(f\"Preprocessed {len(datasets)} datasets\")\n    return datasets\n\n# Load optimized datasets\ndatasets = optimize_data_loading(\"datasets/train/\")\n</code></pre>"},{"location":"tutorials/performance-optimization.html#feature-pre-computation","title":"Feature Pre-computation","text":"<pre><code>def precompute_features(tasks, force_recompute=False):\n    \"\"\"Precompute and cache molecular/protein features.\"\"\"\n\n    print(\"Precomputing features...\")\n\n    # This will trigger feature computation and caching\n    task_distance = TaskDistance(\n        tasks=tasks,\n        molecule_method=\"euclidean\",  # Fast method for precomputation\n        protein_method=\"euclidean\"\n    )\n\n    # Force feature computation by attempting distance calculation\n    try:\n        # This will compute and cache all features\n        sample_distances = task_distance.get_molecule_distances()\n        print(\"\u2705 Molecular features precomputed\")\n\n        sample_distances = task_distance.get_protein_distances()\n        print(\"\u2705 Protein features precomputed\")\n\n    except Exception as e:\n        print(f\"\u26a0\ufe0f Feature precomputation failed: {e}\")\n\n    print(\"Feature precomputation complete\")\n\n# Precompute features for faster subsequent operations\n# precompute_features(tasks)\n</code></pre>"},{"location":"tutorials/performance-optimization.html#otdd-optimization","title":"OTDD Optimization","text":""},{"location":"tutorials/performance-optimization.html#otdd-parameter-tuning","title":"OTDD Parameter Tuning","text":"<pre><code>def optimize_otdd_parameters(datasets, max_samples_range=[100, 500, 1000]):\n    \"\"\"Find optimal OTDD parameters for your datasets.\"\"\"\n\n    import time\n\n    results = {}\n\n    for max_samples in max_samples_range:\n        print(f\"Testing OTDD with max_samples={max_samples}\")\n\n        start_time = time.time()\n\n        try:\n            distance_calc = MoleculeDatasetDistance(\n                tasks=None,\n                molecule_method=\"otdd\"\n            )\n\n            # OTDD parameters are handled internally\n            # But you can influence performance by dataset size\n\n            distance_calc.source_molecule_datasets = datasets[:2]\n            distance_calc.target_molecule_datasets = datasets[:2]\n            distance_calc.source_task_ids = [d.task_id for d in datasets[:2]]\n            distance_calc.target_task_ids = [d.task_id for d in datasets[:2]]\n\n            distances = distance_calc.get_distance()\n\n            elapsed = time.time() - start_time\n\n            results[max_samples] = {\n                'time': elapsed,\n                'success': True,\n                'distances': distances\n            }\n\n            print(f\"  \u2705 Completed in {elapsed:.2f}s\")\n\n        except Exception as e:\n            elapsed = time.time() - start_time\n            results[max_samples] = {\n                'time': elapsed,\n                'success': False,\n                'error': str(e)\n            }\n            print(f\"  \u274c Failed after {elapsed:.2f}s: {e}\")\n\n    return results\n\n# Find optimal parameters\n# otdd_results = optimize_otdd_parameters(datasets)\n</code></pre>"},{"location":"tutorials/performance-optimization.html#performance-monitoring","title":"Performance Monitoring","text":""},{"location":"tutorials/performance-optimization.html#benchmarking-suite","title":"Benchmarking Suite","text":"<pre><code>import time\nimport psutil\nimport os\n\nclass PerformanceBenchmark:\n    \"\"\"Comprehensive performance benchmarking for THEMAP operations.\"\"\"\n\n    def __init__(self):\n        self.results = {}\n\n    def benchmark_distance_methods(self, datasets, methods=None):\n        \"\"\"Benchmark different distance methods.\"\"\"\n\n        if methods is None:\n            methods = [\"euclidean\", \"cosine\"]  # Skip OTDD for speed\n\n        for method in methods:\n            print(f\"\\n\ud83d\udd0d Benchmarking {method}...\")\n\n            # Memory before\n            memory_before = self._get_memory_usage()\n            start_time = time.time()\n\n            try:\n                distance_calc = MoleculeDatasetDistance(\n                    tasks=None,\n                    molecule_method=method\n                )\n\n                distance_calc.source_molecule_datasets = datasets\n                distance_calc.target_molecule_datasets = datasets\n                distance_calc.source_task_ids = [d.task_id for d in datasets]\n                distance_calc.target_task_ids = [d.task_id for d in datasets]\n\n                distances = distance_calc.get_distance()\n\n                # Calculate metrics\n                elapsed = time.time() - start_time\n                memory_after = self._get_memory_usage()\n                memory_used = memory_after - memory_before\n\n                n_comparisons = sum(len(d) for d in distances.values())\n\n                self.results[method] = {\n                    'time': elapsed,\n                    'memory_mb': memory_used,\n                    'comparisons': n_comparisons,\n                    'comparisons_per_second': n_comparisons / elapsed,\n                    'status': 'success'\n                }\n\n                print(f\"  \u2705 Time: {elapsed:.2f}s\")\n                print(f\"  \ud83d\udcbe Memory: {memory_used:.1f}MB\")\n                print(f\"  \ud83d\udcca {n_comparisons} comparisons ({n_comparisons/elapsed:.1f}/s)\")\n\n            except Exception as e:\n                elapsed = time.time() - start_time\n                self.results[method] = {\n                    'time': elapsed,\n                    'memory_mb': 0,\n                    'comparisons': 0,\n                    'comparisons_per_second': 0,\n                    'status': f'failed: {str(e)}'\n                }\n                print(f\"  \u274c Failed: {e}\")\n\n    def _get_memory_usage(self):\n        \"\"\"Get current memory usage in MB.\"\"\"\n        process = psutil.Process(os.getpid())\n        return process.memory_info().rss / (1024 * 1024)\n\n    def print_summary(self):\n        \"\"\"Print benchmark summary.\"\"\"\n\n        print(\"\\n\ud83d\udcca Benchmark Summary:\")\n        print(\"-\" * 80)\n        print(f\"{'Method':&lt;12} {'Time (s)':&lt;10} {'Memory (MB)':&lt;12} {'Comp/sec':&lt;10} {'Status'}\")\n        print(\"-\" * 80)\n\n        for method, results in self.results.items():\n            print(f\"{method:&lt;12} {results['time']:&lt;10.2f} {results['memory_mb']:&lt;12.1f} \"\n                  f\"{results['comparisons_per_second']:&lt;10.1f} {results['status']}\")\n\n        # Recommendations\n        successful = {k: v for k, v in self.results.items() if v['status'] == 'success'}\n\n        if successful:\n            fastest = min(successful.items(), key=lambda x: x[1]['time'])\n            most_efficient = min(successful.items(), key=lambda x: x[1]['memory_mb'])\n\n            print(f\"\\n\ud83c\udfc6 Recommendations:\")\n            print(f\"\u26a1 Fastest: {fastest[0]} ({fastest[1]['time']:.2f}s)\")\n            print(f\"\ud83d\udcbe Most memory efficient: {most_efficient[0]} ({most_efficient[1]['memory_mb']:.1f}MB)\")\n\n# Run comprehensive benchmark\nbenchmark = PerformanceBenchmark()\n# benchmark.benchmark_distance_methods(datasets[:3])  # Test with 3 datasets\n# benchmark.print_summary()\n</code></pre>"},{"location":"tutorials/performance-optimization.html#best-practices-summary","title":"Best Practices Summary","text":""},{"location":"tutorials/performance-optimization.html#quick-optimization-checklist","title":"Quick Optimization Checklist","text":"<ol> <li>\u2705 Use caching: Always specify a cache directory</li> <li>\u2705 Choose appropriate methods: Start with euclidean for exploration</li> <li>\u2705 Process in batches: Handle large datasets in smaller chunks</li> <li>\u2705 Monitor memory: Keep track of memory usage during processing</li> <li>\u2705 Parallel processing: Use multiple cores for independent computations</li> <li>\u2705 Precompute features: Cache expensive feature computations</li> <li>\u2705 Profile your workflow: Identify bottlenecks with benchmarking</li> </ol>"},{"location":"tutorials/performance-optimization.html#method-selection-guidelines","title":"Method Selection Guidelines","text":"<pre><code>def choose_distance_method(n_datasets, dataset_sizes, time_budget_minutes=60):\n    \"\"\"Helper function to choose appropriate distance method.\"\"\"\n\n    total_comparisons = n_datasets * (n_datasets - 1) // 2\n    avg_dataset_size = sum(dataset_sizes) / len(dataset_sizes)\n\n    print(f\"Analysis: {total_comparisons} comparisons, avg {avg_dataset_size:.0f} molecules/dataset\")\n\n    if total_comparisons &gt; 100 or avg_dataset_size &gt; 1000:\n        recommendation = \"euclidean\"\n        reason = \"Large number of comparisons or large datasets\"\n    elif total_comparisons &gt; 50:\n        recommendation = \"cosine\"\n        reason = \"Moderate number of comparisons\"\n    elif time_budget_minutes &gt; 30:\n        recommendation = \"otdd\"\n        reason = \"High accuracy needed and sufficient time budget\"\n    else:\n        recommendation = \"euclidean\"\n        reason = \"Limited time budget\"\n\n    print(f\"Recommended method: {recommendation}\")\n    print(f\"Reason: {reason}\")\n\n    return recommendation\n\n# Example usage\n# method = choose_distance_method(\n#     n_datasets=10,\n#     dataset_sizes=[250, 180, 500, 300],\n#     time_budget_minutes=30\n# )\n</code></pre> <p>This comprehensive guide should help you optimize THEMAP performance for your specific use case. Start with the basic optimizations and gradually apply more advanced techniques as needed.</p>"},{"location":"tutorials/working-with-tasks.html","title":"Working with Tasks","text":"<p>This tutorial covers THEMAP's unified task system that integrates molecular data, protein data, and metadata for comprehensive analysis.</p>"},{"location":"tutorials/working-with-tasks.html#understanding-the-task-system","title":"Understanding the Task System","text":"<p>The Task system in THEMAP provides a unified interface for working with multi-modal bioactivity prediction data:</p> <ul> <li>Tasks: Individual prediction problems (e.g., CHEMBL1023359)</li> <li>Data modalities: Molecules, proteins, metadata</li> <li>Splits: Train/test/validation divisions</li> <li>Caching: Efficient feature storage and retrieval</li> </ul>"},{"location":"tutorials/working-with-tasks.html#loading-tasks","title":"Loading Tasks","text":""},{"location":"tutorials/working-with-tasks.html#basic-task-loading","title":"Basic Task Loading","text":"<pre><code>from themap.data.tasks import Tasks\n\n# Load tasks from a directory structure\ntasks = Tasks.from_directory(\n    directory=\"datasets/\",\n    task_list_file=\"datasets/sample_tasks_list.json\",\n    load_molecules=True,\n    load_proteins=True,\n    load_metadata=True,\n    cache_dir=\"cache/\"\n)\n\nprint(f\"Loaded {len(tasks)} tasks\")\n</code></pre>"},{"location":"tutorials/working-with-tasks.html#task-configuration-file","title":"Task Configuration File","text":"<p>The <code>sample_tasks_list.json</code> file defines which tasks belong to which split:</p> <pre><code>{\n  \"train\": [\"CHEMBL1023359\", \"CHEMBL1613776\", \"CHEMBL4078627\"],\n  \"test\": [\"CHEMBL2219358\", \"CHEMBL1963831\"],\n  \"valid\": [\"CHEMBL2219236\"]\n}\n</code></pre>"},{"location":"tutorials/working-with-tasks.html#directory-structure","title":"Directory Structure","text":"<pre><code>datasets/\n\u251c\u2500\u2500 train/\n\u2502   \u251c\u2500\u2500 CHEMBL1023359.jsonl.gz    # Molecular data\n\u2502   \u251c\u2500\u2500 CHEMBL1023359.fasta       # Protein sequences\n\u2502   \u2514\u2500\u2500 CHEMBL1023359_metadata.json\n\u251c\u2500\u2500 test/\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 valid/\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 sample_tasks_list.json\n</code></pre>"},{"location":"tutorials/working-with-tasks.html#exploring-tasks","title":"Exploring Tasks","text":""},{"location":"tutorials/working-with-tasks.html#basic-task-information","title":"Basic Task Information","text":"<pre><code># Get task statistics\nprint(f\"Total tasks: {len(tasks)}\")\nprint(f\"Train tasks: {tasks.get_num_fold_tasks('TRAIN')}\")\nprint(f\"Test tasks: {tasks.get_num_fold_tasks('TEST')}\")\nprint(f\"Valid tasks: {tasks.get_num_fold_tasks('VALID')}\")\n\n# Get task IDs\ntrain_task_ids = tasks.get_task_ids(fold='TRAIN')\nprint(f\"Training task IDs: {train_task_ids}\")\n\n# Access individual tasks\ntask = tasks.get_task(\"CHEMBL1023359\")\nprint(f\"Task {task.task_id} has {len(task.molecules)} molecules\")\n</code></pre>"},{"location":"tutorials/working-with-tasks.html#data-modality-access","title":"Data Modality Access","text":"<pre><code># Access different data types\nfor task_id in tasks.get_task_ids()[:3]:  # First 3 tasks\n    task = tasks.get_task(task_id)\n\n    print(f\"\\nTask: {task_id}\")\n\n    # Molecular data\n    if hasattr(task, 'molecules') and task.molecules:\n        print(f\"  Molecules: {len(task.molecules)}\")\n        print(f\"  Sample SMILES: {task.molecules[0].smiles}\")\n\n    # Protein data\n    if hasattr(task, 'proteins') and task.proteins:\n        print(f\"  Proteins: {len(task.proteins)}\")\n        print(f\"  Sample protein length: {len(task.proteins[0].sequence)}\")\n\n    # Metadata\n    if hasattr(task, 'metadata') and task.metadata:\n        print(f\"  Metadata keys: {list(task.metadata.keys())}\")\n</code></pre>"},{"location":"tutorials/working-with-tasks.html#task-based-distance-computation","title":"Task-Based Distance Computation","text":""},{"location":"tutorials/working-with-tasks.html#unified-distance-calculation","title":"Unified Distance Calculation","text":"<pre><code>from themap.distance import TaskDistance\n\n# Create task distance calculator\ntask_distance = TaskDistance(\n    tasks=tasks,\n    molecule_method=\"cosine\",\n    protein_method=\"euclidean\"\n)\n\n# Compute all distance types\nall_distances = task_distance.compute_all_distances(\n    combination_strategy=\"weighted_average\",\n    molecule_weight=0.7,\n    protein_weight=0.3\n)\n\nprint(\"Distance types computed:\")\nprint(f\"  Molecule distances: {len(all_distances['molecule'])} tasks\")\nprint(f\"  Protein distances: {len(all_distances['protein'])} tasks\")\nprint(f\"  Combined distances: {len(all_distances['combined'])} tasks\")\n</code></pre>"},{"location":"tutorials/working-with-tasks.html#specific-distance-types","title":"Specific Distance Types","text":"<pre><code># Compute only molecular distances\nmolecule_distances = task_distance.get_molecule_distances()\n\n# Compute only protein distances\nprotein_distances = task_distance.get_protein_distances()\n\n# Compute combined distances with custom weights\ncombined_distances = task_distance.get_combined_distances(\n    molecule_weight=0.6,\n    protein_weight=0.4\n)\n</code></pre>"},{"location":"tutorials/working-with-tasks.html#working-with-folds","title":"Working with Folds","text":""},{"location":"tutorials/working-with-tasks.html#train-test-analysis","title":"Train-Test Analysis","text":"<pre><code>def analyze_train_test_distances(tasks, distance_type=\"molecule\"):\n    \"\"\"Analyze distances between train and test tasks.\"\"\"\n\n    # Get task IDs by fold\n    train_ids = set(tasks.get_task_ids(fold='TRAIN'))\n    test_ids = set(tasks.get_task_ids(fold='TEST'))\n\n    # Compute distances\n    task_distance = TaskDistance(tasks=tasks)\n    distances = task_distance.compute_all_distances()[distance_type]\n\n    # Extract train-test distances\n    train_test_distances = []\n\n    for test_id in test_ids:\n        if test_id in distances:\n            for train_id in train_ids:\n                if train_id in distances[test_id]:\n                    train_test_distances.append({\n                        'test_task': test_id,\n                        'train_task': train_id,\n                        'distance': distances[test_id][train_id]\n                    })\n\n    return train_test_distances\n\n# Analyze train-test relationships\ntt_distances = analyze_train_test_distances(tasks, \"molecule\")\nprint(f\"Found {len(tt_distances)} train-test pairs\")\n\n# Find closest training tasks for each test task\nimport pandas as pd\n\ndf = pd.DataFrame(tt_distances)\nfor test_task in df['test_task'].unique():\n    task_distances = df[df['test_task'] == test_task]\n    closest = task_distances.nsmallest(3, 'distance')\n\n    print(f\"\\nTest task {test_task} - closest training tasks:\")\n    for _, row in closest.iterrows():\n        print(f\"  {row['train_task']}: {row['distance']:.3f}\")\n</code></pre>"},{"location":"tutorials/working-with-tasks.html#cross-validation-support","title":"Cross-Validation Support","text":"<pre><code>def create_cv_folds(tasks, n_folds=5):\n    \"\"\"Create cross-validation folds from tasks.\"\"\"\n\n    all_task_ids = tasks.get_task_ids()\n    random.shuffle(all_task_ids)  # Randomize\n\n    fold_size = len(all_task_ids) // n_folds\n    folds = []\n\n    for i in range(n_folds):\n        start_idx = i * fold_size\n        end_idx = start_idx + fold_size if i &lt; n_folds - 1 else len(all_task_ids)\n\n        test_tasks = all_task_ids[start_idx:end_idx]\n        train_tasks = [tid for tid in all_task_ids if tid not in test_tasks]\n\n        folds.append({\n            'fold': i,\n            'train': train_tasks,\n            'test': test_tasks\n        })\n\n    return folds\n\n# Create CV folds\ncv_folds = create_cv_folds(tasks, n_folds=5)\nprint(f\"Created {len(cv_folds)} CV folds\")\n</code></pre>"},{"location":"tutorials/working-with-tasks.html#caching-and-performance","title":"Caching and Performance","text":""},{"location":"tutorials/working-with-tasks.html#feature-caching","title":"Feature Caching","text":"<pre><code># Tasks automatically cache computed features\ntasks_with_cache = Tasks.from_directory(\n    directory=\"datasets/\",\n    task_list_file=\"datasets/sample_tasks_list.json\",\n    load_molecules=True,\n    load_proteins=True,\n    cache_dir=\"cache/\",  # Features will be cached here\n    force_reload=False   # Use cached features if available\n)\n\n# Check cache status\nprint(f\"Cache directory: {tasks_with_cache.cache_dir}\")\n</code></pre>"},{"location":"tutorials/working-with-tasks.html#selective-loading","title":"Selective Loading","text":"<pre><code># Load only specific data types for better performance\nmolecule_only_tasks = Tasks.from_directory(\n    directory=\"datasets/\",\n    task_list_file=\"datasets/sample_tasks_list.json\",\n    load_molecules=True,\n    load_proteins=False,  # Skip protein loading\n    load_metadata=False   # Skip metadata loading\n)\n\nprint(\"Loaded molecular data only for faster processing\")\n</code></pre>"},{"location":"tutorials/working-with-tasks.html#advanced-task-operations","title":"Advanced Task Operations","text":""},{"location":"tutorials/working-with-tasks.html#task-filtering","title":"Task Filtering","text":"<pre><code>def filter_tasks_by_size(tasks, min_molecules=10, max_molecules=1000):\n    \"\"\"Filter tasks by number of molecules.\"\"\"\n\n    filtered_task_ids = []\n\n    for task_id in tasks.get_task_ids():\n        task = tasks.get_task(task_id)\n        if hasattr(task, 'molecules') and task.molecules:\n            n_molecules = len(task.molecules)\n            if min_molecules &lt;= n_molecules &lt;= max_molecules:\n                filtered_task_ids.append(task_id)\n\n    return filtered_task_ids\n\n# Filter tasks\ngood_tasks = filter_tasks_by_size(tasks, min_molecules=20, max_molecules=500)\nprint(f\"Found {len(good_tasks)} tasks with appropriate size\")\n</code></pre>"},{"location":"tutorials/working-with-tasks.html#task-metadata-analysis","title":"Task Metadata Analysis","text":"<pre><code>def analyze_task_metadata(tasks):\n    \"\"\"Analyze metadata across all tasks.\"\"\"\n\n    metadata_summary = {}\n\n    for task_id in tasks.get_task_ids():\n        task = tasks.get_task(task_id)\n\n        if hasattr(task, 'metadata') and task.metadata:\n            for key, value in task.metadata.items():\n                if key not in metadata_summary:\n                    metadata_summary[key] = []\n                metadata_summary[key].append(value)\n\n    # Print summary\n    for key, values in metadata_summary.items():\n        unique_values = len(set(str(v) for v in values))\n        print(f\"Metadata '{key}': {len(values)} tasks, {unique_values} unique values\")\n\n    return metadata_summary\n\n# Analyze metadata\nmetadata = analyze_task_metadata(tasks)\n</code></pre>"},{"location":"tutorials/working-with-tasks.html#integration-with-external-tools","title":"Integration with External Tools","text":""},{"location":"tutorials/working-with-tasks.html#export-for-analysis","title":"Export for Analysis","text":"<pre><code>def export_task_summary(tasks, output_file=\"task_summary.csv\"):\n    \"\"\"Export task information to CSV for external analysis.\"\"\"\n\n    import pandas as pd\n\n    summary_data = []\n\n    for task_id in tasks.get_task_ids():\n        task = tasks.get_task(task_id)\n\n        row = {'task_id': task_id}\n\n        # Add molecule info\n        if hasattr(task, 'molecules') and task.molecules:\n            row['n_molecules'] = len(task.molecules)\n        else:\n            row['n_molecules'] = 0\n\n        # Add protein info\n        if hasattr(task, 'proteins') and task.proteins:\n            row['n_proteins'] = len(task.proteins)\n            row['avg_protein_length'] = sum(len(p.sequence) for p in task.proteins) / len(task.proteins)\n        else:\n            row['n_proteins'] = 0\n            row['avg_protein_length'] = 0\n\n        # Add metadata\n        if hasattr(task, 'metadata') and task.metadata:\n            for key, value in task.metadata.items():\n                row[f'metadata_{key}'] = value\n\n        summary_data.append(row)\n\n    df = pd.DataFrame(summary_data)\n    df.to_csv(output_file, index=False)\n    print(f\"Task summary exported to {output_file}\")\n\n    return df\n\n# Export summary\ntask_df = export_task_summary(tasks)\n</code></pre>"},{"location":"tutorials/working-with-tasks.html#best-practices","title":"Best Practices","text":""},{"location":"tutorials/working-with-tasks.html#performance-tips","title":"Performance Tips","text":"<ol> <li>Use caching: Always specify a cache directory</li> <li>Load selectively: Only load needed data types</li> <li>Filter early: Remove unsuitable tasks before distance computation</li> <li>Batch processing: Process tasks in groups for large datasets</li> </ol>"},{"location":"tutorials/working-with-tasks.html#memory-management","title":"Memory Management","text":"<pre><code># For large task sets, process in batches\ndef process_tasks_in_batches(tasks, batch_size=10):\n    \"\"\"Process tasks in smaller batches to manage memory.\"\"\"\n\n    task_ids = tasks.get_task_ids()\n\n    for i in range(0, len(task_ids), batch_size):\n        batch_ids = task_ids[i:i + batch_size]\n\n        # Create subset tasks\n        batch_tasks = Tasks()\n        for task_id in batch_ids:\n            batch_tasks.add_task(tasks.get_task(task_id))\n\n        # Process batch\n        yield batch_tasks\n\n# Example usage\nfor batch_tasks in process_tasks_in_batches(tasks, batch_size=5):\n    print(f\"Processing batch with {len(batch_tasks)} tasks\")\n    # Perform distance computation on batch\n</code></pre>"},{"location":"tutorials/working-with-tasks.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/working-with-tasks.html#common-issues","title":"Common Issues","text":"<ol> <li>Missing files: Ensure all task files exist in expected directories</li> <li>Cache conflicts: Use <code>force_reload=True</code> to refresh cached features</li> <li>Memory errors: Reduce batch size or load fewer data modalities</li> <li>Inconsistent data: Validate that all tasks have required data types</li> </ol>"},{"location":"tutorials/working-with-tasks.html#validation","title":"Validation","text":"<pre><code>def validate_tasks(tasks):\n    \"\"\"Validate task data consistency.\"\"\"\n\n    issues = []\n\n    for task_id in tasks.get_task_ids():\n        task = tasks.get_task(task_id)\n\n        # Check for required data\n        if not hasattr(task, 'molecules') or not task.molecules:\n            issues.append(f\"Task {task_id}: No molecular data\")\n\n        if not hasattr(task, 'proteins') or not task.proteins:\n            issues.append(f\"Task {task_id}: No protein data\")\n\n    if issues:\n        print(\"Validation issues found:\")\n        for issue in issues:\n            print(f\"  - {issue}\")\n    else:\n        print(\"All tasks validated successfully\")\n\n    return issues\n\n# Validate loaded tasks\nvalidation_issues = validate_tasks(tasks)\n</code></pre>"},{"location":"tutorials/working-with-tasks.html#next-steps","title":"Next Steps","text":"<ul> <li>Explore performance optimization</li> <li>Learn about task hardness estimation</li> <li>Try advanced distance combination strategies</li> <li>Integrate with your machine learning pipeline</li> </ul>"},{"location":"user-guide/distance-computation.html","title":"Distance Computation Guide","text":"<p>This guide provides comprehensive information about computing distances between datasets, tasks, and molecular/protein spaces in THEMAP.</p>"},{"location":"user-guide/distance-computation.html#overview","title":"Overview","text":"<p>Distance computation is central to THEMAP's functionality, enabling:</p> <ul> <li>Dataset similarity assessment: Compare chemical spaces between datasets</li> <li>Transfer learning guidance: Identify similar tasks for knowledge transfer</li> <li>Task hardness estimation: Quantify prediction difficulty</li> <li>Multi-modal analysis: Combine molecular, protein, and metadata information</li> </ul>"},{"location":"user-guide/distance-computation.html#distance-types","title":"Distance Types","text":""},{"location":"user-guide/distance-computation.html#1-molecular-dataset-distances","title":"1. Molecular Dataset Distances","text":""},{"location":"user-guide/distance-computation.html#otdd-optimal-transport-dataset-distance","title":"OTDD (Optimal Transport Dataset Distance)","text":"<p>OTDD provides the most comprehensive comparison by considering both feature distributions and label relationships.</p> <pre><code>from themap.distance import MoleculeDatasetDistance\n\n# Initialize with OTDD\nmol_distance = MoleculeDatasetDistance(\n    tasks=tasks,\n    molecule_method=\"otdd\"\n)\n\n# Compute distances\ndistances = mol_distance.get_distance()\n</code></pre> <p>When to use OTDD: - \u2705 High accuracy requirements - \u2705 Moderate dataset sizes (&lt; 10,000 molecules) - \u2705 Both features and labels are important - \u274c Large-scale computations (memory intensive)</p> <p>Configuration options: <pre><code># Customize OTDD parameters\nhopts = mol_distance.get_hopts(\"molecule\")\nprint(hopts)\n# {'maxsamples': 1000, 'device': 'auto', ...}\n\n# Modify parameters through configuration file\n# themap/models/distance_configures/otdd.json\n</code></pre></p>"},{"location":"user-guide/distance-computation.html#euclidean-distance","title":"Euclidean Distance","text":"<p>Fast and interpretable distance based on feature vector similarity.</p> <pre><code>mol_distance = MoleculeDatasetDistance(\n    tasks=tasks,\n    molecule_method=\"euclidean\"\n)\n\ndistances = mol_distance.get_distance()\n</code></pre> <p>When to use Euclidean: - \u2705 Large datasets (&gt; 10,000 molecules) - \u2705 Fast computation requirements - \u2705 Feature magnitude is important - \u274c High-dimensional sparse features</p>"},{"location":"user-guide/distance-computation.html#cosine-distance","title":"Cosine Distance","text":"<p>Measures angular similarity, good for high-dimensional feature spaces.</p> <pre><code>mol_distance = MoleculeDatasetDistance(\n    tasks=tasks,\n    molecule_method=\"cosine\"\n)\n\ndistances = mol_distance.get_distance()\n</code></pre> <p>When to use Cosine: - \u2705 High-dimensional features - \u2705 Sparse feature vectors - \u2705 Feature orientation matters more than magnitude - \u274c When magnitude differences are important</p>"},{"location":"user-guide/distance-computation.html#2-protein-dataset-distances","title":"2. Protein Dataset Distances","text":"<p>Protein distances focus on sequence and structural similarity.</p> <pre><code>from themap.distance import ProteinDatasetDistance\n\n# Euclidean distance for protein features\nprot_distance = ProteinDatasetDistance(\n    tasks=tasks,\n    protein_method=\"euclidean\"\n)\n\ndistances = prot_distance.get_distance()\n</code></pre> <p>Available methods: - <code>\"euclidean\"</code>: Standard L2 distance - <code>\"cosine\"</code>: Angular similarity - <code>\"sequence_identity\"</code>: (Future) Direct sequence comparison</p>"},{"location":"user-guide/distance-computation.html#3-combined-task-distances","title":"3. Combined Task Distances","text":"<p>Integrate multiple data modalities for comprehensive task comparison.</p> <pre><code>from themap.distance import TaskDistance\n\n# Initialize with multiple methods\ntask_distance = TaskDistance(\n    tasks=tasks,\n    molecule_method=\"cosine\",\n    protein_method=\"euclidean\",\n    metadata_method=\"jaccard\"\n)\n\n# Compute all distance types\nall_distances = task_distance.compute_all_distances(\n    combination_strategy=\"weighted_average\",\n    molecule_weight=0.5,\n    protein_weight=0.3,\n    metadata_weight=0.2\n)\n</code></pre> <p>Combination strategies:</p> Strategy Description Use Case <code>\"average\"</code> Simple arithmetic mean Equal importance of modalities <code>\"weighted_average\"</code> Weighted combination Different modality importance <code>\"min\"</code> Minimum distance Conservative similarity <code>\"max\"</code> Maximum distance Liberal dissimilarity"},{"location":"user-guide/distance-computation.html#working-with-features","title":"Working with Features","text":""},{"location":"user-guide/distance-computation.html#feature-computation","title":"Feature Computation","text":"<p>THEMAP provides unified feature extraction across data modalities:</p> <pre><code># Molecular features\nmol_features = tasks.compute_all_task_features(\n    molecule_featurizer=\"ecfp\",\n    combination_method=\"concatenate\",\n    folds=[\"TRAIN\", \"TEST\"]\n)\n\n# Protein features\nprot_features = tasks.compute_all_task_features(\n    protein_featurizer=\"esm2_t33_650M_UR50D\",\n    combination_method=\"concatenate\"\n)\n\n# Combined multi-modal features\ncombined_features = tasks.compute_all_task_features(\n    molecule_featurizer=\"morgan\",\n    protein_featurizer=\"esm2_t33_650M_UR50D\",\n    metadata_configs={\n        \"assay_description\": {\"featurizer_name\": \"sentence-transformers\"},\n        \"bioactivity\": {\"featurizer_name\": \"standardize\"}\n    },\n    combination_method=\"concatenate\"\n)\n</code></pre>"},{"location":"user-guide/distance-computation.html#feature-caching","title":"Feature Caching","text":"<p>Expensive feature computations can be cached for reuse:</p> <pre><code># Save computed features\ntasks.save_task_features_to_file(\n    output_path=\"cache/task_features.pkl\",\n    molecule_featurizer=\"ecfp\",\n    protein_featurizer=\"esm2_t33_650M_UR50D\"\n)\n\n# Load cached features\ncached_features = Tasks.load_task_features_from_file(\"cache/task_features.pkl\")\n</code></pre>"},{"location":"user-guide/distance-computation.html#distance-matrix-organization","title":"Distance Matrix Organization","text":"<p>THEMAP organizes distance computations for N\u00d7M comparisons:</p> <pre><code># Get features ready for distance computation\nsource_features, target_features, source_names, target_names = (\n    tasks.get_distance_computation_ready_features(\n        molecule_featurizer=\"ecfp\",\n        protein_featurizer=\"esm2_t33_650M_UR50D\",\n        combination_method=\"concatenate\",\n        source_fold=\"TRAIN\",      # N source tasks\n        target_folds=[\"TEST\"]     # M target tasks\n    )\n)\n\nprint(f\"Computing {len(source_features)}\u00d7{len(target_features)} distance matrix\")\n</code></pre>"},{"location":"user-guide/distance-computation.html#external-distance-matrices","title":"External Distance Matrices","text":"<p>Work with pre-computed distance matrices from external sources:</p>"},{"location":"user-guide/distance-computation.html#loading-external-matrices","title":"Loading External Matrices","text":"<pre><code># Load chemical space distances\nchem_distances = TaskDistance.load_ext_chem_distance(\"external_chem_dist.pkl\")\n\n# Load protein space distances\nprot_distances = TaskDistance.load_ext_prot_distance(\"external_prot_dist.pkl\")\n\n# Initialize with external matrices\nimport numpy as np\n\nexternal_matrix = np.random.rand(10, 8)  # 10 source \u00d7 8 target\ntask_distance = TaskDistance(\n    tasks=None,\n    source_task_ids=[\"train_1\", \"train_2\", ...],\n    target_task_ids=[\"test_1\", \"test_2\", ...],\n    external_chemical_space=external_matrix\n)\n</code></pre>"},{"location":"user-guide/distance-computation.html#expected-file-format","title":"Expected File Format","text":"<p>External distance files should contain:</p> <pre><code>{\n    \"source_task_ids\": [\"CHEMBL001\", \"CHEMBL002\", ...],    # or train_chembl_ids\n    \"target_task_ids\": [\"CHEMBL100\", \"CHEMBL101\", ...],    # or test_chembl_ids\n    \"distance_matrices\": numpy_array_or_tensor              # Shape: (n_targets, n_sources)\n}\n</code></pre>"},{"location":"user-guide/distance-computation.html#performance-optimization","title":"Performance Optimization","text":""},{"location":"user-guide/distance-computation.html#memory-management","title":"Memory Management","text":"<pre><code># Monitor memory usage\nimport psutil\nimport os\n\ndef check_memory():\n    process = psutil.Process(os.getpid())\n    memory_mb = process.memory_info().rss / 1024 / 1024\n    print(f\"Memory usage: {memory_mb:.1f} MB\")\n\ncheck_memory()\n\n# Compute distances in batches for large datasets\ndef compute_batched_distances(tasks, batch_size=100):\n    results = {}\n\n    for i in range(0, len(tasks), batch_size):\n        batch_tasks = tasks[i:i+batch_size]\n        batch_distance = MoleculeDatasetDistance(\n            tasks=batch_tasks,\n            molecule_method=\"euclidean\"  # Faster method\n        )\n        batch_results = batch_distance.get_distance()\n        results.update(batch_results)\n\n    return results\n</code></pre>"},{"location":"user-guide/distance-computation.html#computational-efficiency","title":"Computational Efficiency","text":"<pre><code># Choose methods based on dataset size\ndef choose_distance_method(num_molecules):\n    if num_molecules &lt; 1000:\n        return \"otdd\"           # Most accurate\n    elif num_molecules &lt; 10000:\n        return \"cosine\"         # Good balance\n    else:\n        return \"euclidean\"      # Fastest\n\n# Parallel computation for independent distances\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef compute_parallel_distances(task_pairs):\n    def compute_single_distance(task_pair):\n        source_task, target_task = task_pair\n        distance_calc = MoleculeDatasetDistance(\n            tasks=[source_task, target_task],\n            molecule_method=\"euclidean\"\n        )\n        return distance_calc.get_distance()\n\n    with ProcessPoolExecutor() as executor:\n        results = list(executor.map(compute_single_distance, task_pairs))\n\n    return results\n</code></pre>"},{"location":"user-guide/distance-computation.html#gpu-acceleration","title":"GPU Acceleration","text":"<p>For OTDD computations with GPU support:</p> <pre><code>import torch\n\n# Check GPU availability\nif torch.cuda.is_available():\n    print(f\"GPU available: {torch.cuda.get_device_name()}\")\n\n    # OTDD will automatically use GPU if available\n    mol_distance = MoleculeDatasetDistance(\n        tasks=tasks,\n        molecule_method=\"otdd\"\n    )\n\n    # Monitor GPU memory\n    print(f\"GPU memory: {torch.cuda.memory_allocated() / 1024**2:.1f} MB\")\nelse:\n    print(\"Using CPU computation\")\n</code></pre>"},{"location":"user-guide/distance-computation.html#error-handling-and-debugging","title":"Error Handling and Debugging","text":""},{"location":"user-guide/distance-computation.html#common-issues-and-solutions","title":"Common Issues and Solutions","text":"<pre><code>from themap.distance import DistanceComputationError, DataValidationError\n\ntry:\n    distances = mol_distance.get_distance()\nexcept ImportError as e:\n    print(f\"Missing dependencies: {e}\")\n    print(\"Install with: pip install -e '.[otdd]'\")\n\nexcept DistanceComputationError as e:\n    print(f\"Distance computation failed: {e}\")\n    # Fallback to simpler method\n    mol_distance.molecule_method = \"euclidean\"\n    distances = mol_distance.get_distance()\n\nexcept DataValidationError as e:\n    print(f\"Data validation failed: {e}\")\n    # Check data format and task IDs\n\nexcept torch.cuda.OutOfMemoryError:\n    print(\"GPU out of memory, falling back to CPU\")\n    torch.cuda.empty_cache()\n    # Reduce batch size or use CPU\n</code></pre>"},{"location":"user-guide/distance-computation.html#debugging-distance-computations","title":"Debugging Distance Computations","text":"<pre><code># Enable detailed logging\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n\n# Validate input data\ndef validate_distance_inputs(tasks):\n    print(f\"Number of tasks: {len(tasks)}\")\n\n    for i, task in enumerate(tasks[:3]):  # Check first 3 tasks\n        print(f\"Task {i}: {task.task_id}\")\n        if task.molecule_dataset:\n            print(f\"  Molecules: {len(task.molecule_dataset)}\")\n        if task.protein_dataset:\n            print(f\"  Proteins: {len(task.protein_dataset)}\")\n\n# Check feature computation\nsource_features, target_features, source_names, target_names = (\n    tasks.get_distance_computation_ready_features(\n        molecule_featurizer=\"ecfp\",\n        combination_method=\"concatenate\",\n        source_fold=\"TRAIN\",\n        target_folds=[\"TEST\"]\n    )\n)\n\nprint(f\"Source features: {len(source_features)} \u00d7 {len(source_features[0]) if source_features else 0}\")\nprint(f\"Target features: {len(target_features)} \u00d7 {len(target_features[0]) if target_features else 0}\")\nprint(f\"Source names: {source_names}\")\nprint(f\"Target names: {target_names}\")\n</code></pre>"},{"location":"user-guide/distance-computation.html#analysis-and-visualization","title":"Analysis and Visualization","text":""},{"location":"user-guide/distance-computation.html#converting-to-analysis-ready-formats","title":"Converting to Analysis-Ready Formats","text":"<pre><code># Convert to pandas DataFrame\ndf_distances = task_distance.to_pandas(\"molecule\")\nprint(df_distances.head())\n\n# Statistical analysis\nprint(f\"Mean distance: {df_distances.values.mean():.3f}\")\nprint(f\"Distance std: {df_distances.values.std():.3f}\")\n\n# Find most similar tasks\nmin_distance_idx = df_distances.values.argmin()\nrow, col = np.unravel_index(min_distance_idx, df_distances.shape)\nprint(f\"Most similar: {df_distances.index[row]} \u2194 {df_distances.columns[col]}\")\n</code></pre>"},{"location":"user-guide/distance-computation.html#visualization-examples","title":"Visualization Examples","text":"<pre><code>import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Distance matrix heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(df_distances, annot=True, cmap='viridis', fmt='.2f')\nplt.title('Task Distance Matrix')\nplt.show()\n\n# Distance distribution\nplt.figure(figsize=(8, 6))\ndistances_flat = df_distances.values.flatten()\nplt.hist(distances_flat, bins=20, alpha=0.7)\nplt.xlabel('Distance')\nplt.ylabel('Frequency')\nplt.title('Distance Distribution')\nplt.show()\n\n# Hierarchical clustering\nfrom scipy.cluster.hierarchy import dendrogram, linkage\nfrom scipy.spatial.distance import squareform\n\n# Convert to condensed distance matrix\ncondensed_distances = squareform(df_distances.values)\nlinkage_matrix = linkage(condensed_distances, method='ward')\n\nplt.figure(figsize=(12, 8))\ndendrogram(linkage_matrix, labels=df_distances.index, orientation='top')\nplt.title('Task Similarity Dendrogram')\nplt.xticks(rotation=45)\nplt.show()\n</code></pre> <p>This comprehensive guide covers all aspects of distance computation in THEMAP. For specific use cases and advanced examples, see our tutorials and API documentation.</p>"},{"location":"user-guide/getting-started.html","title":"Getting Started","text":"<p>Welcome to THEMAP! This guide will help you get up and running with task hardness estimation for molecular activity prediction.</p>"},{"location":"user-guide/getting-started.html#what-is-themap","title":"What is THEMAP?","text":"<p>THEMAP (Task Hardness Estimation for Molecular Activity Prediction) is a Python library designed to aid drug discovery by providing powerful methods for estimating the difficulty of bioactivity prediction tasks. It enables researchers to:</p> <ul> <li>Compute distances between molecular datasets using various metrics (OTDD, Euclidean, Cosine)</li> <li>Analyze protein similarity through sequence and structural features</li> <li>Estimate task hardness for transfer learning scenarios</li> <li>Build transferability maps for bioactivity prediction tasks</li> <li>Integrate multi-modal data (molecules, proteins, metadata)</li> </ul>"},{"location":"user-guide/getting-started.html#installation","title":"Installation","text":""},{"location":"user-guide/getting-started.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or higher</li> <li>conda (recommended) or pip</li> </ul>"},{"location":"user-guide/getting-started.html#basic-installation","title":"Basic Installation","text":"<pre><code># Clone the repository\ngit clone https://github.com/HFooladi/THEMAP.git\ncd THEMAP\n\n# Create and activate conda environment\nconda env create -f environment.yml\nconda activate themap\n\n# Install THEMAP\npip install --no-deps -e .\n</code></pre>"},{"location":"user-guide/getting-started.html#installation-with-optional-dependencies","title":"Installation with Optional Dependencies","text":"<p>THEMAP has several optional dependency groups for different functionality:</p> <pre><code># For basic molecular analysis\npip install -e \".[ml]\"\n\n# For protein analysis\npip install -e \".[protein]\"\n\n# For OTDD distance computation\npip install -e \".[otdd]\"\n\n# For all features\npip install -e \".[all]\"\n\n# For development\npip install -e \".[dev,test]\"\n</code></pre>"},{"location":"user-guide/getting-started.html#verify-installation","title":"Verify Installation","text":"<pre><code>import themap\nprint(f\"THEMAP version: {themap.__version__}\")\n\n# Test basic functionality\nfrom themap.data import MoleculeDataset\nfrom themap.distance import MoleculeDatasetDistance\nprint(\"\u2705 Installation successful!\")\n</code></pre>"},{"location":"user-guide/getting-started.html#quick-start","title":"Quick Start","text":""},{"location":"user-guide/getting-started.html#1-molecular-dataset-distance","title":"1. Molecular Dataset Distance","text":"<p>Compute distances between molecular datasets to understand chemical space similarity:</p> <pre><code>import os\nfrom dpu_utils.utils.richpath import RichPath\nfrom themap.data import MoleculeDataset\nfrom themap.distance import MoleculeDatasetDistance\n\n# Load datasets\nsource_path = RichPath.create(\"datasets/train/CHEMBL1023359.jsonl.gz\")\ntarget_path = RichPath.create(\"datasets/test/CHEMBL2219358.jsonl.gz\")\n\nsource_dataset = MoleculeDataset.load_from_file(source_path)\ntarget_dataset = MoleculeDataset.load_from_file(target_path)\n\n# Compute distance using OTDD\ndistance_calc = MoleculeDatasetDistance(\n    tasks=None,  # Will be auto-extracted from datasets\n    molecule_method=\"otdd\"\n)\n\ndistances = distance_calc.get_distance()\nprint(distances)\n# Output: {'CHEMBL2219358': {'CHEMBL1023359': 7.074298858642578}}\n</code></pre>"},{"location":"user-guide/getting-started.html#2-protein-dataset-distance","title":"2. Protein Dataset Distance","text":"<p>Analyze protein similarity using sequence features:</p> <pre><code>from themap.data import ProteinMetadataDatasets\nfrom themap.distance import ProteinDatasetDistance\n\n# Load protein datasets\nsource_proteins = ProteinMetadataDatasets.from_directory(\"datasets/train/\")\ntarget_proteins = ProteinMetadataDatasets.from_directory(\"datasets/test/\")\n\n# Compute euclidean distance between protein features\nprotein_distance = ProteinDatasetDistance(\n    tasks=None,  # Will be auto-extracted\n    protein_method=\"euclidean\"\n)\n\ndistances = protein_distance.get_distance()\nprint(distances)\n</code></pre>"},{"location":"user-guide/getting-started.html#3-unified-task-analysis","title":"3. Unified Task Analysis","text":"<p>Work with the unified task system that integrates multiple data modalities:</p> <pre><code>from themap.data.tasks import Tasks\nfrom themap.distance import TaskDistance\n\n# Load integrated tasks\ntasks = Tasks.from_directory(\n    directory=\"datasets/\",\n    task_list_file=\"datasets/sample_tasks_list.json\",\n    load_molecules=True,\n    load_proteins=True,\n    load_metadata=True,\n    cache_dir=\"cache/\"\n)\n\nprint(f\"Loaded {len(tasks)} tasks\")\nprint(f\"Train tasks: {tasks.get_num_fold_tasks('TRAIN')}\")\nprint(f\"Test tasks: {tasks.get_num_fold_tasks('TEST')}\")\n\n# Compute combined distances\ntask_distance = TaskDistance(\n    tasks=tasks,\n    molecule_method=\"cosine\",\n    protein_method=\"euclidean\"\n)\n\n# Get all distance types\nall_distances = task_distance.compute_all_distances()\n</code></pre>"},{"location":"user-guide/getting-started.html#core-concepts","title":"Core Concepts","text":""},{"location":"user-guide/getting-started.html#tasks-and-data-modalities","title":"Tasks and Data Modalities","text":"<p>THEMAP organizes data around the concept of Tasks - individual bioactivity prediction problems that can contain:</p> <ul> <li>Molecular data: SMILES strings, molecular descriptors, embeddings</li> <li>Protein data: Sequences, structural features, embeddings</li> <li>Metadata: Assay descriptions, experimental conditions, bioactivity values</li> </ul>"},{"location":"user-guide/getting-started.html#distance-metrics","title":"Distance Metrics","text":"<p>Different distance metrics are optimized for different scenarios:</p> Method Use Case Pros Cons OTDD Comprehensive dataset comparison Most accurate, considers both features and labels Computationally expensive Euclidean Fast similarity estimation Fast, interpretable May miss complex relationships Cosine Feature orientation comparison Good for high-dimensional data Ignores magnitude differences"},{"location":"user-guide/getting-started.html#task-hardness","title":"Task Hardness","text":"<p>Task hardness quantifies how difficult a prediction task is, which helps in:</p> <ul> <li>Transfer learning: Identify similar tasks for knowledge transfer</li> <li>Model selection: Choose appropriate models based on task complexity</li> <li>Resource allocation: Prioritize difficult tasks for more computational resources</li> </ul>"},{"location":"user-guide/getting-started.html#directory-structure","title":"Directory Structure","text":"<p>Understanding the expected directory structure helps organize your data:</p> <pre><code>your_project/\n\u251c\u2500\u2500 datasets/\n\u2502   \u251c\u2500\u2500 train/\n\u2502   \u2502   \u251c\u2500\u2500 CHEMBL123.jsonl.gz    # Molecular data\n\u2502   \u2502   \u251c\u2500\u2500 CHEMBL123.fasta       # Protein sequences\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 test/\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 valid/\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 sample_tasks_list.json    # Task configuration\n\u251c\u2500\u2500 cache/                        # Feature caching\n\u2514\u2500\u2500 results/                      # Output analyses\n</code></pre>"},{"location":"user-guide/getting-started.html#sample-task-list-format","title":"Sample Task List Format","text":"<pre><code>{\n  \"train\": [\"CHEMBL1023359\", \"CHEMBL1613776\", ...],\n  \"test\": [\"CHEMBL2219358\", \"CHEMBL1963831\", ...],\n  \"valid\": [\"CHEMBL2219236\", ...]\n}\n</code></pre>"},{"location":"user-guide/getting-started.html#next-steps","title":"Next Steps","text":"<p>Now that you have the basics:</p> <ol> <li>Explore the tutorials: Check out detailed tutorials for step-by-step examples</li> <li>Explore the code: Understand the codebase structure for advanced usage</li> <li>Run the examples: Execute the provided example scripts</li> <li>Join the community: Contribute to the project on GitHub</li> </ol>"},{"location":"user-guide/getting-started.html#common-issues","title":"Common Issues","text":""},{"location":"user-guide/getting-started.html#import-errors","title":"Import Errors","text":"<p>If you encounter import errors:</p> <pre><code># Check if optional dependencies are installed\ntry:\n    from themap.distance import MoleculeDatasetDistance\n    print(\"\u2705 Distance module available\")\nexcept ImportError as e:\n    print(f\"\u274c Missing dependencies: {e}\")\n    print(\"Install with: pip install -e '.[otdd]'\")\n</code></pre>"},{"location":"user-guide/getting-started.html#memory-issues","title":"Memory Issues","text":"<p>For large datasets:</p> <pre><code># Reduce memory usage\ndistance_calc = MoleculeDatasetDistance(\n    tasks=tasks,\n    molecule_method=\"euclidean\"  # Use instead of OTDD for large datasets\n)\n\n# Or limit OTDD samples\nhopts = {\"maxsamples\": 500}  # Default is 1000\n</code></pre>"},{"location":"user-guide/getting-started.html#data-format-issues","title":"Data Format Issues","text":"<p>Ensure your data follows the expected format:</p> <pre><code># Validate molecular data\ndataset = MoleculeDataset.load_from_file(\"your_data.jsonl.gz\")\nprint(f\"Dataset contains {len(dataset)} molecules\")\nprint(f\"Sample molecule: {dataset[0].smiles}\")\n\n# Validate protein data\nproteins = ProteinMetadataDatasets.from_directory(\"proteins/\")\nprint(f\"Loaded {len(proteins)} protein sequences\")\n</code></pre> <p>Ready to dive deeper? Continue with our comprehensive tutorials!</p>"}]}